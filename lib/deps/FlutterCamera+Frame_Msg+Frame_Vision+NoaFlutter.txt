===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_flutter_camera-main\lib\main.dart =====
----- Class: MainApp -----
import 'dart:async';
import 'dart:typed_data';

import 'package:flutter/material.dart';
import 'package:logging/logging.dart';
import 'package:share_plus/share_plus.dart';
import 'package:simple_frame_app/frame_vision_app.dart';
import 'package:simple_frame_app/simple_frame_app.dart';
import 'package:frame_msg/tx/plain_text.dart';

void main() => runApp(const MainApp());

final _log = Logger("MainApp");

class MainApp extends StatefulWidget {
  const MainApp({super.key});

  @override
  MainAppState createState() => MainAppState();
}

class MainAppState extends State<MainApp> with SimpleFrameAppState, FrameVisionAppState {
  // main state of photo request/processing on/off
  bool _processing = false;

  // the list of images to show in the scolling list view
  final List<Image> _imageList = [];
  final List<ImageMetadata> _imageMeta = [];
  final List<Uint8List> _jpegBytes = [];

  MainAppState() {
    Logger.root.level = Level.INFO;
    Logger.root.onRecord.listen((record) {
      debugPrint('${record.level.name}: ${record.time}: ${record.message}');
    });
  }

  @override
  void initState() {
    super.initState();

    // if possible, connect right away and load files on Frame
    // note: camera app wouldn't necessarily run on start
    tryScanAndConnectAndStart(andRun: true);
  }

  @override
  Future<void> onRun() async {
    // initial message to display when running
    var msg = TxPlainText(text: '2-Tap: take photo');
    await frame!.sendMessage(0x0a, msg.pack());
  }

  @override
  Future<void> onCancel() async {
    // no app-specific cleanup required here
  }

  @override
  Future<void> onTap(int taps) async {
    switch (taps) {
      case 2:
        // check if there's processing in progress already and drop the request if so
        if (!_processing) {
          _processing = true;
          // synchronously call the capture and processing (just display) of the photo
          await capture().then(process);
        }
        break;
      default:
    }
  }

  /// The vision pipeline to run when a photo is captured
  /// Which in this case is just displaying
  FutureOr<void> process((Uint8List, ImageMetadata) photo) async {
    var imageData = photo.$1;
    var meta = photo.$2;

    // update the image reel
    setState(() {
      _imageList.insert(0, Image.memory(imageData, gaplessPlayback: true,));
      _imageMeta.insert(0, meta);
      _jpegBytes.insert(0, imageData);
    });

    _processing = false;
  }

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Frame Camera',
      theme: ThemeData.dark(),
      home: Scaffold(
        appBar: AppBar(
          title: const Text("Frame Camera"),
          actions: [getBatteryWidget()]
        ),
        drawer: getCameraDrawer(),
        onDrawerChanged: (isOpened) {
          if (!isOpened) {
            // if the user closes the camera settings, send the updated settings to Frame
            sendExposureSettings();
          }
        },
        body: Flex(
          direction: Axis.vertical,
          children: [
            Expanded(
              // scrollable list view for multiple photos
              child: ListView.separated(
                itemBuilder: (context, index) {
                  return Padding(
                    padding: const EdgeInsets.symmetric(horizontal: 16),
                    child: Column(
                      children: [
                        GestureDetector(
                          onTap: () => _shareImage(_imageList[index], _imageMeta[index], _jpegBytes[index]),
                          child: _imageList[index]
                        ),
                        ImageMetadataWidget(meta: _imageMeta[index]),
                      ],
                    )
                  );
                },
                separatorBuilder: (context, index) => const Divider(height: 30),
                itemCount: _imageList.length,
              ),
            ),
          ]
        ),
        floatingActionButton: getFloatingActionButtonWidget(const Icon(Icons.camera_alt), const Icon(Icons.cancel)),
        persistentFooterButtons: getFooterButtonsWidget(),
      ),
    );
  }

  void _shareImage(Image image, ImageMetadata metadata, Uint8List jpegBytes) async {
    await Share.shareXFiles(
      [XFile.fromData(Uint8List.fromList(jpegBytes), mimeType: 'image/jpeg', name: 'image.jpg')],
      text: 'Frame camera image:\n$metadata',
    );
  }
}


----- Class: MainAppState -----
import 'dart:async';
import 'dart:typed_data';

import 'package:flutter/material.dart';
import 'package:logging/logging.dart';
import 'package:share_plus/share_plus.dart';
import 'package:simple_frame_app/frame_vision_app.dart';
import 'package:simple_frame_app/simple_frame_app.dart';
import 'package:frame_msg/tx/plain_text.dart';

void main() => runApp(const MainApp());

final _log = Logger("MainApp");

class MainApp extends StatefulWidget {
  const MainApp({super.key});

  @override
  MainAppState createState() => MainAppState();
}

class MainAppState extends State<MainApp> with SimpleFrameAppState, FrameVisionAppState {
  // main state of photo request/processing on/off
  bool _processing = false;

  // the list of images to show in the scolling list view
  final List<Image> _imageList = [];
  final List<ImageMetadata> _imageMeta = [];
  final List<Uint8List> _jpegBytes = [];

  MainAppState() {
    Logger.root.level = Level.INFO;
    Logger.root.onRecord.listen((record) {
      debugPrint('${record.level.name}: ${record.time}: ${record.message}');
    });
  }

  @override
  void initState() {
    super.initState();

    // if possible, connect right away and load files on Frame
    // note: camera app wouldn't necessarily run on start
    tryScanAndConnectAndStart(andRun: true);
  }

  @override
  Future<void> onRun() async {
    // initial message to display when running
    var msg = TxPlainText(text: '2-Tap: take photo');
    await frame!.sendMessage(0x0a, msg.pack());
  }

  @override
  Future<void> onCancel() async {
    // no app-specific cleanup required here
  }

  @override
  Future<void> onTap(int taps) async {
    switch (taps) {
      case 2:
        // check if there's processing in progress already and drop the request if so
        if (!_processing) {
          _processing = true;
          // synchronously call the capture and processing (just display) of the photo
          await capture().then(process);
        }
        break;
      default:
    }
  }

  /// The vision pipeline to run when a photo is captured
  /// Which in this case is just displaying
  FutureOr<void> process((Uint8List, ImageMetadata) photo) async {
    var imageData = photo.$1;
    var meta = photo.$2;

    // update the image reel
    setState(() {
      _imageList.insert(0, Image.memory(imageData, gaplessPlayback: true,));
      _imageMeta.insert(0, meta);
      _jpegBytes.insert(0, imageData);
    });

    _processing = false;
  }

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Frame Camera',
      theme: ThemeData.dark(),
      home: Scaffold(
        appBar: AppBar(
          title: const Text("Frame Camera"),
          actions: [getBatteryWidget()]
        ),
        drawer: getCameraDrawer(),
        onDrawerChanged: (isOpened) {
          if (!isOpened) {
            // if the user closes the camera settings, send the updated settings to Frame
            sendExposureSettings();
          }
        },
        body: Flex(
          direction: Axis.vertical,
          children: [
            Expanded(
              // scrollable list view for multiple photos
              child: ListView.separated(
                itemBuilder: (context, index) {
                  return Padding(
                    padding: const EdgeInsets.symmetric(horizontal: 16),
                    child: Column(
                      children: [
                        GestureDetector(
                          onTap: () => _shareImage(_imageList[index], _imageMeta[index], _jpegBytes[index]),
                          child: _imageList[index]
                        ),
                        ImageMetadataWidget(meta: _imageMeta[index]),
                      ],
                    )
                  );
                },
                separatorBuilder: (context, index) => const Divider(height: 30),
                itemCount: _imageList.length,
              ),
            ),
          ]
        ),
        floatingActionButton: getFloatingActionButtonWidget(const Icon(Icons.camera_alt), const Icon(Icons.cancel)),
        persistentFooterButtons: getFooterButtonsWidget(),
      ),
    );
  }

  void _shareImage(Image image, ImageMetadata metadata, Uint8List jpegBytes) async {
    await Share.shareXFiles(
      [XFile.fromData(Uint8List.fromList(jpegBytes), mimeType: 'image/jpeg', name: 'image.jpg')],
      text: 'Frame camera image:\n$metadata',
    );
  }
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\rx\audio.dart =====
----- Class: RxAudio -----
import 'dart:async';
import 'dart:collection';
import 'dart:typed_data';
import 'package:logging/logging.dart';

final _log = Logger("RxAudio");

class RxAudio {

  // Frame to Phone flags
  final int nonFinalChunkFlag;
  final int finalChunkFlag;
  final bool streaming;
  StreamController<Uint8List>? _controller;

  RxAudio({
    this.nonFinalChunkFlag = 0x05,
    this.finalChunkFlag = 0x06,
    this.streaming = false
  });

  /// Attach this RxAudio to the Frame's dataResponse characteristic stream.
  /// If this RxAudio was created with `streaming: true` then the returned
  /// broadcast Stream will produce elements continuously, otherwise it will
  /// be a single subscription stream that produces a single Uint8List element
  /// containing the entire audio clip received.
  /// Both types of Stream are Done when the finalChunkFlag is received from
  /// Frame indicating the end of the audio feed
  Stream<Uint8List> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAudio etc?
    // might be possible though after a clean close(), do I want to prevent it?
    return streaming ?
      _audioDataStreamResponse(dataResponse) :
      _audioDataResponse(dataResponse);
  }

  /// Audio data stream with a single element of a raw audio clip
  Stream<Uint8List> _audioDataResponse(Stream<List<int>> dataResponse) {

    // the audio data as a list of bytes that accumulates with each packet
    BytesBuilder audioData = BytesBuilder(copy: false);
    int rawOffset = 0;

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw data into audio (as bytes)
    _controller = StreamController();

    _controller!.onListen = () {
      _log.fine('stream subscribed');
      dataResponseSubs = dataResponse
          .where(
              (data) => data[0] == nonFinalChunkFlag || data[0] == finalChunkFlag)
          .listen((data) {
        if (data[0] == nonFinalChunkFlag) {
          _log.finer(() => 'Non-final: ${data.length}');
          audioData.add(UnmodifiableListView(data.skip(1)));
          rawOffset += data.length - 1;
        }
        // the last chunk has a first byte of 8 so stop after this
        else if (data[0] == finalChunkFlag) {
          _log.finer(() => 'Final: ${data.length}');
          audioData.add(UnmodifiableListView(data.skip(1)));
          rawOffset += data.length - 1;

          // When full audio data is received, emit it and clear the buffer
          _controller!.add(audioData.takeBytes());
          rawOffset = 0;

          // and close the stream
          _controller!.close();
        }
        _log.finer(() => 'Chunk size: ${data.length - 1}, rawOffset: $rawOffset');
      }, onDone: _controller!.close, onError: _controller!.addError);
    };

    _controller!.onCancel = () {
      _log.fine('stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }

  /// Real-time Audio data stream
  /// A listener can subscribe and unsubscribe and resubscribe to the returned broadcast Stream
  /// multiple times. The Stream only is Done when the final chunk message code is sent
  /// from Frame
  Stream<Uint8List> _audioDataStreamResponse(Stream<List<int>> dataResponse) {

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw data into audio (as bytes)
    // It needs to be a broadcast stream so users can subscribe, unsubscribe, then resubscribe
    // to the same stream
    _controller = StreamController.broadcast();

    _controller!.onListen = () {
      _log.fine('stream subscribed');
      dataResponseSubs?.cancel();
      dataResponseSubs = dataResponse
        .where(
            (data) => data[0] == nonFinalChunkFlag || data[0] == finalChunkFlag)
        .listen((data) {
          // start or middle of an audio stream
          if (data[0] == nonFinalChunkFlag) {
            _log.finer(() => 'Non-final: ${data.length}');
            assert(data.length % 2 == 1); // whole 16-bit pcm samples only (plus msgCode in data[0] makes it odd)
            _controller!.add(Uint8List.fromList(data.skip(1).toList()));
          }
          // the last chunk has a first byte of finalChunkFlag so stop after this
          else if (data[0] == finalChunkFlag) {

            _log.finer(() => 'Final: ${data.length}');

            if (data.length > 1) {
              _controller!.add(Uint8List.fromList(data.skip(1).toList()));
            }

            // upstream is done so close the downstream
            _log.fine('About to close stream');
            _controller!.close();
            _log.fine('stream closed');
          }
          // close or pass on errors if the upstream dataResponse closes/errors
        }, onDone: _controller!.close, onError: _controller!.addError);
    };

    _controller!.onCancel = () {
      _log.fine('stream unsubscribed');
      // unsubscribe from upstream dataResponse
      dataResponseSubs?.cancel();

      // don't close the controller, if the client re-listens to the returned Stream
      // then we re-subscribe to dataResponse in onListen and continue sending data
    };

    return _controller!.stream;
  }

  /// Detaches the RxAudio from the Frame dataResponse Stream permanently.
  /// For `streaming==false` RxAudios, this has no effect because the controller
  /// of the Stream closes when the single clip is completely received.
  /// For `streaming==true` RxAudios, after the RxAudio has been attached to
  /// dataResponse, the client can call listen() and cancel() many times and
  /// the controller for the stream will not be closed. But when finished, it
  /// can be closed with detach and cannot be listened to again.
  void detach() {
    _controller?.close();
  }

  /// Create the contents of a WAV files corresponding to the provided pcmData
  static Uint8List toWavBytes({required Uint8List pcmData, int sampleRate = 8000, int bitsPerSample = 16, int channels = 1}) {
    int byteRate = sampleRate * channels * bitsPerSample ~/ 8;
    int dataSize = pcmData.length;
    int fileSize = 36 + dataSize;

    // WAV Header
    List<int> header = [
      // "RIFF" chunk descriptor
      0x52, 0x49, 0x46, 0x46, // "RIFF" in ASCII
      fileSize & 0xff, (fileSize >> 8) & 0xff, (fileSize >> 16) & 0xff, (fileSize >> 24) & 0xff, // Chunk size
      0x57, 0x41, 0x56, 0x45, // "WAVE" in ASCII

      // "fmt " sub-chunk
      0x66, 0x6d, 0x74, 0x20, // "fmt " in ASCII
      16, 0x00, 0x00, 0x00,   // Subchunk1Size (16 for PCM)
      0x01, 0x00,             // AudioFormat (1 for PCM)
      channels & 0xff, 0x00,   // NumChannels
      sampleRate & 0xff, (sampleRate >> 8) & 0xff, (sampleRate >> 16) & 0xff, (sampleRate >> 24) & 0xff, // SampleRate
      byteRate & 0xff, (byteRate >> 8) & 0xff, (byteRate >> 16) & 0xff, (byteRate >> 24) & 0xff, // ByteRate
      (channels * bitsPerSample ~/ 8) & 0xff, 0x00, // BlockAlign
      bitsPerSample & 0xff, 0x00, // BitsPerSample

      // "data" sub-chunk
      0x64, 0x61, 0x74, 0x61, // "data" in ASCII
      dataSize & 0xff, (dataSize >> 8) & 0xff, (dataSize >> 16) & 0xff, (dataSize >> 24) & 0xff, // Subchunk2Size
    ];

    // Combine header and PCM data
    return Uint8List.fromList(header + pcmData);
  }

}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\rx\auto_exp_result.dart =====
----- Class: RxAutoExpResult -----
import 'dart:async';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxAutoExpResult");

/// Receive handler for auto exposure and white balance data from the auto exposure algorithm
class RxAutoExpResult {

  // Frame to Phone flags
  final int autoExpFlag;
  StreamController<AutoExpResult>? _controller;

  RxAutoExpResult({
    this.autoExpFlag = 0x11,
  });

  /// Attach this RxAutoExpResult to the Frame's dataResponse characteristic stream.
  Stream<AutoExpResult> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAutoExpResult etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == autoExpFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('auto exposure result detected');

          // Ensure the data length is sufficient
          if (data.length < 65) {
            _log.warning('Insufficient data length for AutoExpResult: ${data.length}');
            return;
          }

          // Extract the relevant data (bytes 1 to 65)
          List<int> relevantData = data.sublist(1, 65);

          // Create a ByteData object from the relevant data
          ByteData byteData = ByteData.sublistView(Uint8List.fromList(relevantData));

          // Unpack the data as 16 float32 values
          List<double> unpacked = List.generate(16, (i) => byteData.getFloat32(i * 4, Endian.little));

          _controller!.add(AutoExpResult(
            error: unpacked[0],
            shutter: unpacked[1],
            analogGain: unpacked[2],
            redGain: unpacked[3],
            greenGain: unpacked[4],
            blueGain: unpacked[5],
            brightness: Brightness(
              centerWeightedAverage: unpacked[6],
              scene: unpacked[7],
              matrix: Matrix(
                r: unpacked[8],
                g: unpacked[9],
                b: unpacked[10],
                average: unpacked[11],
              ),
              spot: Spot(
                r: unpacked[12],
                g: unpacked[13],
                b: unpacked[14],
                average: unpacked[15],
              ),
            ),
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('AutoExposureResultDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('AutoExposureResultDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class AutoExpResult {
  final double error;
  final double shutter;
  final double analogGain;
  final double redGain;
  final double greenGain;
  final double blueGain;
  final Brightness brightness;

  AutoExpResult({
    required this.error,
    required this.shutter,
    required this.analogGain,
    required this.redGain,
    required this.greenGain,
    required this.blueGain,
    required this.brightness,
  });
}

class Brightness {
  final double centerWeightedAverage;
  final double scene;
  final Matrix matrix;
  final Spot spot;

  Brightness({
    required this.centerWeightedAverage,
    required this.scene,
    required this.matrix,
    required this.spot,
  });
}

class Matrix {
  final double r;
  final double g;
  final double b;
  final double average;

  Matrix({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}

class Spot {
  final double r;
  final double g;
  final double b;
  final double average;

  Spot({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}



----- Class: AutoExpResult -----
import 'dart:async';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxAutoExpResult");

/// Receive handler for auto exposure and white balance data from the auto exposure algorithm
class RxAutoExpResult {

  // Frame to Phone flags
  final int autoExpFlag;
  StreamController<AutoExpResult>? _controller;

  RxAutoExpResult({
    this.autoExpFlag = 0x11,
  });

  /// Attach this RxAutoExpResult to the Frame's dataResponse characteristic stream.
  Stream<AutoExpResult> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAutoExpResult etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == autoExpFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('auto exposure result detected');

          // Ensure the data length is sufficient
          if (data.length < 65) {
            _log.warning('Insufficient data length for AutoExpResult: ${data.length}');
            return;
          }

          // Extract the relevant data (bytes 1 to 65)
          List<int> relevantData = data.sublist(1, 65);

          // Create a ByteData object from the relevant data
          ByteData byteData = ByteData.sublistView(Uint8List.fromList(relevantData));

          // Unpack the data as 16 float32 values
          List<double> unpacked = List.generate(16, (i) => byteData.getFloat32(i * 4, Endian.little));

          _controller!.add(AutoExpResult(
            error: unpacked[0],
            shutter: unpacked[1],
            analogGain: unpacked[2],
            redGain: unpacked[3],
            greenGain: unpacked[4],
            blueGain: unpacked[5],
            brightness: Brightness(
              centerWeightedAverage: unpacked[6],
              scene: unpacked[7],
              matrix: Matrix(
                r: unpacked[8],
                g: unpacked[9],
                b: unpacked[10],
                average: unpacked[11],
              ),
              spot: Spot(
                r: unpacked[12],
                g: unpacked[13],
                b: unpacked[14],
                average: unpacked[15],
              ),
            ),
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('AutoExposureResultDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('AutoExposureResultDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class AutoExpResult {
  final double error;
  final double shutter;
  final double analogGain;
  final double redGain;
  final double greenGain;
  final double blueGain;
  final Brightness brightness;

  AutoExpResult({
    required this.error,
    required this.shutter,
    required this.analogGain,
    required this.redGain,
    required this.greenGain,
    required this.blueGain,
    required this.brightness,
  });
}

class Brightness {
  final double centerWeightedAverage;
  final double scene;
  final Matrix matrix;
  final Spot spot;

  Brightness({
    required this.centerWeightedAverage,
    required this.scene,
    required this.matrix,
    required this.spot,
  });
}

class Matrix {
  final double r;
  final double g;
  final double b;
  final double average;

  Matrix({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}

class Spot {
  final double r;
  final double g;
  final double b;
  final double average;

  Spot({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}



----- Class: Brightness -----
import 'dart:async';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxAutoExpResult");

/// Receive handler for auto exposure and white balance data from the auto exposure algorithm
class RxAutoExpResult {

  // Frame to Phone flags
  final int autoExpFlag;
  StreamController<AutoExpResult>? _controller;

  RxAutoExpResult({
    this.autoExpFlag = 0x11,
  });

  /// Attach this RxAutoExpResult to the Frame's dataResponse characteristic stream.
  Stream<AutoExpResult> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAutoExpResult etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == autoExpFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('auto exposure result detected');

          // Ensure the data length is sufficient
          if (data.length < 65) {
            _log.warning('Insufficient data length for AutoExpResult: ${data.length}');
            return;
          }

          // Extract the relevant data (bytes 1 to 65)
          List<int> relevantData = data.sublist(1, 65);

          // Create a ByteData object from the relevant data
          ByteData byteData = ByteData.sublistView(Uint8List.fromList(relevantData));

          // Unpack the data as 16 float32 values
          List<double> unpacked = List.generate(16, (i) => byteData.getFloat32(i * 4, Endian.little));

          _controller!.add(AutoExpResult(
            error: unpacked[0],
            shutter: unpacked[1],
            analogGain: unpacked[2],
            redGain: unpacked[3],
            greenGain: unpacked[4],
            blueGain: unpacked[5],
            brightness: Brightness(
              centerWeightedAverage: unpacked[6],
              scene: unpacked[7],
              matrix: Matrix(
                r: unpacked[8],
                g: unpacked[9],
                b: unpacked[10],
                average: unpacked[11],
              ),
              spot: Spot(
                r: unpacked[12],
                g: unpacked[13],
                b: unpacked[14],
                average: unpacked[15],
              ),
            ),
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('AutoExposureResultDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('AutoExposureResultDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class AutoExpResult {
  final double error;
  final double shutter;
  final double analogGain;
  final double redGain;
  final double greenGain;
  final double blueGain;
  final Brightness brightness;

  AutoExpResult({
    required this.error,
    required this.shutter,
    required this.analogGain,
    required this.redGain,
    required this.greenGain,
    required this.blueGain,
    required this.brightness,
  });
}

class Brightness {
  final double centerWeightedAverage;
  final double scene;
  final Matrix matrix;
  final Spot spot;

  Brightness({
    required this.centerWeightedAverage,
    required this.scene,
    required this.matrix,
    required this.spot,
  });
}

class Matrix {
  final double r;
  final double g;
  final double b;
  final double average;

  Matrix({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}

class Spot {
  final double r;
  final double g;
  final double b;
  final double average;

  Spot({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}



----- Class: Matrix -----
import 'dart:async';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxAutoExpResult");

/// Receive handler for auto exposure and white balance data from the auto exposure algorithm
class RxAutoExpResult {

  // Frame to Phone flags
  final int autoExpFlag;
  StreamController<AutoExpResult>? _controller;

  RxAutoExpResult({
    this.autoExpFlag = 0x11,
  });

  /// Attach this RxAutoExpResult to the Frame's dataResponse characteristic stream.
  Stream<AutoExpResult> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAutoExpResult etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == autoExpFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('auto exposure result detected');

          // Ensure the data length is sufficient
          if (data.length < 65) {
            _log.warning('Insufficient data length for AutoExpResult: ${data.length}');
            return;
          }

          // Extract the relevant data (bytes 1 to 65)
          List<int> relevantData = data.sublist(1, 65);

          // Create a ByteData object from the relevant data
          ByteData byteData = ByteData.sublistView(Uint8List.fromList(relevantData));

          // Unpack the data as 16 float32 values
          List<double> unpacked = List.generate(16, (i) => byteData.getFloat32(i * 4, Endian.little));

          _controller!.add(AutoExpResult(
            error: unpacked[0],
            shutter: unpacked[1],
            analogGain: unpacked[2],
            redGain: unpacked[3],
            greenGain: unpacked[4],
            blueGain: unpacked[5],
            brightness: Brightness(
              centerWeightedAverage: unpacked[6],
              scene: unpacked[7],
              matrix: Matrix(
                r: unpacked[8],
                g: unpacked[9],
                b: unpacked[10],
                average: unpacked[11],
              ),
              spot: Spot(
                r: unpacked[12],
                g: unpacked[13],
                b: unpacked[14],
                average: unpacked[15],
              ),
            ),
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('AutoExposureResultDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('AutoExposureResultDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class AutoExpResult {
  final double error;
  final double shutter;
  final double analogGain;
  final double redGain;
  final double greenGain;
  final double blueGain;
  final Brightness brightness;

  AutoExpResult({
    required this.error,
    required this.shutter,
    required this.analogGain,
    required this.redGain,
    required this.greenGain,
    required this.blueGain,
    required this.brightness,
  });
}

class Brightness {
  final double centerWeightedAverage;
  final double scene;
  final Matrix matrix;
  final Spot spot;

  Brightness({
    required this.centerWeightedAverage,
    required this.scene,
    required this.matrix,
    required this.spot,
  });
}

class Matrix {
  final double r;
  final double g;
  final double b;
  final double average;

  Matrix({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}

class Spot {
  final double r;
  final double g;
  final double b;
  final double average;

  Spot({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}



----- Class: Spot -----
import 'dart:async';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxAutoExpResult");

/// Receive handler for auto exposure and white balance data from the auto exposure algorithm
class RxAutoExpResult {

  // Frame to Phone flags
  final int autoExpFlag;
  StreamController<AutoExpResult>? _controller;

  RxAutoExpResult({
    this.autoExpFlag = 0x11,
  });

  /// Attach this RxAutoExpResult to the Frame's dataResponse characteristic stream.
  Stream<AutoExpResult> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAutoExpResult etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == autoExpFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('auto exposure result detected');

          // Ensure the data length is sufficient
          if (data.length < 65) {
            _log.warning('Insufficient data length for AutoExpResult: ${data.length}');
            return;
          }

          // Extract the relevant data (bytes 1 to 65)
          List<int> relevantData = data.sublist(1, 65);

          // Create a ByteData object from the relevant data
          ByteData byteData = ByteData.sublistView(Uint8List.fromList(relevantData));

          // Unpack the data as 16 float32 values
          List<double> unpacked = List.generate(16, (i) => byteData.getFloat32(i * 4, Endian.little));

          _controller!.add(AutoExpResult(
            error: unpacked[0],
            shutter: unpacked[1],
            analogGain: unpacked[2],
            redGain: unpacked[3],
            greenGain: unpacked[4],
            blueGain: unpacked[5],
            brightness: Brightness(
              centerWeightedAverage: unpacked[6],
              scene: unpacked[7],
              matrix: Matrix(
                r: unpacked[8],
                g: unpacked[9],
                b: unpacked[10],
                average: unpacked[11],
              ),
              spot: Spot(
                r: unpacked[12],
                g: unpacked[13],
                b: unpacked[14],
                average: unpacked[15],
              ),
            ),
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('AutoExposureResultDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('AutoExposureResultDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class AutoExpResult {
  final double error;
  final double shutter;
  final double analogGain;
  final double redGain;
  final double greenGain;
  final double blueGain;
  final Brightness brightness;

  AutoExpResult({
    required this.error,
    required this.shutter,
    required this.analogGain,
    required this.redGain,
    required this.greenGain,
    required this.blueGain,
    required this.brightness,
  });
}

class Brightness {
  final double centerWeightedAverage;
  final double scene;
  final Matrix matrix;
  final Spot spot;

  Brightness({
    required this.centerWeightedAverage,
    required this.scene,
    required this.matrix,
    required this.spot,
  });
}

class Matrix {
  final double r;
  final double g;
  final double b;
  final double average;

  Matrix({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}

class Spot {
  final double r;
  final double g;
  final double b;
  final double average;

  Spot({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\rx\imu.dart =====
----- Class: to -----
import 'dart:async';
import 'dart:math';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxIMU");

/// Buffer class to allow us to provide a smoothed moving average of samples
class SensorBuffer {
  final int maxSize;
  final List<(int x, int y, int z)> _buffer = [];

  SensorBuffer(this.maxSize);

  void add((int x, int y, int z) value) {
    _buffer.add(value);
    if (_buffer.length > maxSize) {
      _buffer.removeAt(0);
    }
  }

  (int x, int y, int z) get average {
    if (_buffer.isEmpty) return (0, 0, 0);

    int sumX = 0, sumY = 0, sumZ = 0;
    for (var value in _buffer) {
      sumX += value.$1;
      sumY += value.$2;
      sumZ += value.$3;
    }
    return (
      (sumX ~/ _buffer.length),
      (sumY ~/ _buffer.length),
      (sumZ ~/ _buffer.length)
    );
  }
}

/// IMU data stream, returns raw 3-axis magnetometer and 3-axis accelerometer data
/// and optionally computes derived values
/// Note, a proper calculation of Heading requires magnetometer calibration,
/// tilt compensation (which we can do here from the accelerometer), and magnetic
/// declination adjustment (which is lat-long and time-dependent).
/// Magnetometer calibration and declination adjustments need to be done outside this class.
class RxIMU {
  final int _smoothingSamples;

  // Frame to Phone flags
  final int imuFlag;
  StreamController<IMUData>? _controller;

  // Buffers for smoothing
  late final SensorBuffer _compassBuffer;
  late final SensorBuffer _accelBuffer;

  RxIMU({
    this.imuFlag = 0x0A,
    int smoothingSamples = 1,
  }) : _smoothingSamples = smoothingSamples {
    _compassBuffer = SensorBuffer(_smoothingSamples);
    _accelBuffer = SensorBuffer(_smoothingSamples);
  }

  /// Attach this RxIMU to the Frame's dataResponse characteristic stream.
  Stream<IMUData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxIMU etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms the dataResponse elements into IMUData events
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == imuFlag)
        .listen((data) {
          Uint8List bytes = Uint8List.fromList(data);
          // reinterpret the bytes after offset 2 as signed 16-bit integers
          Int16List s16 = bytes.buffer.asInt16List(2);

          // Get raw values
          var rawCompass = (s16[0], s16[1], s16[2]);
          var rawAccel = (s16[3], s16[4], s16[5]);

          // Add to buffers
          _compassBuffer.add(rawCompass);
          _accelBuffer.add(rawAccel);

          _controller!.add(IMUData(
            compass: _compassBuffer.average,
            accel: _accelBuffer.average,
            raw: IMURawData(
              compass: rawCompass,
              accel: rawAccel,
            ),
          ));

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('ImuDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('ImuDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class IMURawData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;

  IMURawData({
    required this.compass,
    required this.accel,
  });
}

class IMUData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;
  final IMURawData? raw;

  IMUData({
    required this.compass,
    required this.accel,
    this.raw,
  });

  double get pitch => atan2(accel.$2, accel.$3) * 180.0 / pi;
  double get roll => atan2(accel.$1, accel.$3) * 180.0 / pi;
}


----- Class: SensorBuffer -----
import 'dart:async';
import 'dart:math';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxIMU");

/// Buffer class to allow us to provide a smoothed moving average of samples
class SensorBuffer {
  final int maxSize;
  final List<(int x, int y, int z)> _buffer = [];

  SensorBuffer(this.maxSize);

  void add((int x, int y, int z) value) {
    _buffer.add(value);
    if (_buffer.length > maxSize) {
      _buffer.removeAt(0);
    }
  }

  (int x, int y, int z) get average {
    if (_buffer.isEmpty) return (0, 0, 0);

    int sumX = 0, sumY = 0, sumZ = 0;
    for (var value in _buffer) {
      sumX += value.$1;
      sumY += value.$2;
      sumZ += value.$3;
    }
    return (
      (sumX ~/ _buffer.length),
      (sumY ~/ _buffer.length),
      (sumZ ~/ _buffer.length)
    );
  }
}

/// IMU data stream, returns raw 3-axis magnetometer and 3-axis accelerometer data
/// and optionally computes derived values
/// Note, a proper calculation of Heading requires magnetometer calibration,
/// tilt compensation (which we can do here from the accelerometer), and magnetic
/// declination adjustment (which is lat-long and time-dependent).
/// Magnetometer calibration and declination adjustments need to be done outside this class.
class RxIMU {
  final int _smoothingSamples;

  // Frame to Phone flags
  final int imuFlag;
  StreamController<IMUData>? _controller;

  // Buffers for smoothing
  late final SensorBuffer _compassBuffer;
  late final SensorBuffer _accelBuffer;

  RxIMU({
    this.imuFlag = 0x0A,
    int smoothingSamples = 1,
  }) : _smoothingSamples = smoothingSamples {
    _compassBuffer = SensorBuffer(_smoothingSamples);
    _accelBuffer = SensorBuffer(_smoothingSamples);
  }

  /// Attach this RxIMU to the Frame's dataResponse characteristic stream.
  Stream<IMUData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxIMU etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms the dataResponse elements into IMUData events
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == imuFlag)
        .listen((data) {
          Uint8List bytes = Uint8List.fromList(data);
          // reinterpret the bytes after offset 2 as signed 16-bit integers
          Int16List s16 = bytes.buffer.asInt16List(2);

          // Get raw values
          var rawCompass = (s16[0], s16[1], s16[2]);
          var rawAccel = (s16[3], s16[4], s16[5]);

          // Add to buffers
          _compassBuffer.add(rawCompass);
          _accelBuffer.add(rawAccel);

          _controller!.add(IMUData(
            compass: _compassBuffer.average,
            accel: _accelBuffer.average,
            raw: IMURawData(
              compass: rawCompass,
              accel: rawAccel,
            ),
          ));

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('ImuDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('ImuDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class IMURawData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;

  IMURawData({
    required this.compass,
    required this.accel,
  });
}

class IMUData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;
  final IMURawData? raw;

  IMUData({
    required this.compass,
    required this.accel,
    this.raw,
  });

  double get pitch => atan2(accel.$2, accel.$3) * 180.0 / pi;
  double get roll => atan2(accel.$1, accel.$3) * 180.0 / pi;
}


----- Class: RxIMU -----
import 'dart:async';
import 'dart:math';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxIMU");

/// Buffer class to allow us to provide a smoothed moving average of samples
class SensorBuffer {
  final int maxSize;
  final List<(int x, int y, int z)> _buffer = [];

  SensorBuffer(this.maxSize);

  void add((int x, int y, int z) value) {
    _buffer.add(value);
    if (_buffer.length > maxSize) {
      _buffer.removeAt(0);
    }
  }

  (int x, int y, int z) get average {
    if (_buffer.isEmpty) return (0, 0, 0);

    int sumX = 0, sumY = 0, sumZ = 0;
    for (var value in _buffer) {
      sumX += value.$1;
      sumY += value.$2;
      sumZ += value.$3;
    }
    return (
      (sumX ~/ _buffer.length),
      (sumY ~/ _buffer.length),
      (sumZ ~/ _buffer.length)
    );
  }
}

/// IMU data stream, returns raw 3-axis magnetometer and 3-axis accelerometer data
/// and optionally computes derived values
/// Note, a proper calculation of Heading requires magnetometer calibration,
/// tilt compensation (which we can do here from the accelerometer), and magnetic
/// declination adjustment (which is lat-long and time-dependent).
/// Magnetometer calibration and declination adjustments need to be done outside this class.
class RxIMU {
  final int _smoothingSamples;

  // Frame to Phone flags
  final int imuFlag;
  StreamController<IMUData>? _controller;

  // Buffers for smoothing
  late final SensorBuffer _compassBuffer;
  late final SensorBuffer _accelBuffer;

  RxIMU({
    this.imuFlag = 0x0A,
    int smoothingSamples = 1,
  }) : _smoothingSamples = smoothingSamples {
    _compassBuffer = SensorBuffer(_smoothingSamples);
    _accelBuffer = SensorBuffer(_smoothingSamples);
  }

  /// Attach this RxIMU to the Frame's dataResponse characteristic stream.
  Stream<IMUData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxIMU etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms the dataResponse elements into IMUData events
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == imuFlag)
        .listen((data) {
          Uint8List bytes = Uint8List.fromList(data);
          // reinterpret the bytes after offset 2 as signed 16-bit integers
          Int16List s16 = bytes.buffer.asInt16List(2);

          // Get raw values
          var rawCompass = (s16[0], s16[1], s16[2]);
          var rawAccel = (s16[3], s16[4], s16[5]);

          // Add to buffers
          _compassBuffer.add(rawCompass);
          _accelBuffer.add(rawAccel);

          _controller!.add(IMUData(
            compass: _compassBuffer.average,
            accel: _accelBuffer.average,
            raw: IMURawData(
              compass: rawCompass,
              accel: rawAccel,
            ),
          ));

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('ImuDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('ImuDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class IMURawData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;

  IMURawData({
    required this.compass,
    required this.accel,
  });
}

class IMUData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;
  final IMURawData? raw;

  IMUData({
    required this.compass,
    required this.accel,
    this.raw,
  });

  double get pitch => atan2(accel.$2, accel.$3) * 180.0 / pi;
  double get roll => atan2(accel.$1, accel.$3) * 180.0 / pi;
}


----- Class: IMURawData -----
import 'dart:async';
import 'dart:math';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxIMU");

/// Buffer class to allow us to provide a smoothed moving average of samples
class SensorBuffer {
  final int maxSize;
  final List<(int x, int y, int z)> _buffer = [];

  SensorBuffer(this.maxSize);

  void add((int x, int y, int z) value) {
    _buffer.add(value);
    if (_buffer.length > maxSize) {
      _buffer.removeAt(0);
    }
  }

  (int x, int y, int z) get average {
    if (_buffer.isEmpty) return (0, 0, 0);

    int sumX = 0, sumY = 0, sumZ = 0;
    for (var value in _buffer) {
      sumX += value.$1;
      sumY += value.$2;
      sumZ += value.$3;
    }
    return (
      (sumX ~/ _buffer.length),
      (sumY ~/ _buffer.length),
      (sumZ ~/ _buffer.length)
    );
  }
}

/// IMU data stream, returns raw 3-axis magnetometer and 3-axis accelerometer data
/// and optionally computes derived values
/// Note, a proper calculation of Heading requires magnetometer calibration,
/// tilt compensation (which we can do here from the accelerometer), and magnetic
/// declination adjustment (which is lat-long and time-dependent).
/// Magnetometer calibration and declination adjustments need to be done outside this class.
class RxIMU {
  final int _smoothingSamples;

  // Frame to Phone flags
  final int imuFlag;
  StreamController<IMUData>? _controller;

  // Buffers for smoothing
  late final SensorBuffer _compassBuffer;
  late final SensorBuffer _accelBuffer;

  RxIMU({
    this.imuFlag = 0x0A,
    int smoothingSamples = 1,
  }) : _smoothingSamples = smoothingSamples {
    _compassBuffer = SensorBuffer(_smoothingSamples);
    _accelBuffer = SensorBuffer(_smoothingSamples);
  }

  /// Attach this RxIMU to the Frame's dataResponse characteristic stream.
  Stream<IMUData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxIMU etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms the dataResponse elements into IMUData events
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == imuFlag)
        .listen((data) {
          Uint8List bytes = Uint8List.fromList(data);
          // reinterpret the bytes after offset 2 as signed 16-bit integers
          Int16List s16 = bytes.buffer.asInt16List(2);

          // Get raw values
          var rawCompass = (s16[0], s16[1], s16[2]);
          var rawAccel = (s16[3], s16[4], s16[5]);

          // Add to buffers
          _compassBuffer.add(rawCompass);
          _accelBuffer.add(rawAccel);

          _controller!.add(IMUData(
            compass: _compassBuffer.average,
            accel: _accelBuffer.average,
            raw: IMURawData(
              compass: rawCompass,
              accel: rawAccel,
            ),
          ));

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('ImuDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('ImuDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class IMURawData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;

  IMURawData({
    required this.compass,
    required this.accel,
  });
}

class IMUData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;
  final IMURawData? raw;

  IMUData({
    required this.compass,
    required this.accel,
    this.raw,
  });

  double get pitch => atan2(accel.$2, accel.$3) * 180.0 / pi;
  double get roll => atan2(accel.$1, accel.$3) * 180.0 / pi;
}


----- Class: IMUData -----
import 'dart:async';
import 'dart:math';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxIMU");

/// Buffer class to allow us to provide a smoothed moving average of samples
class SensorBuffer {
  final int maxSize;
  final List<(int x, int y, int z)> _buffer = [];

  SensorBuffer(this.maxSize);

  void add((int x, int y, int z) value) {
    _buffer.add(value);
    if (_buffer.length > maxSize) {
      _buffer.removeAt(0);
    }
  }

  (int x, int y, int z) get average {
    if (_buffer.isEmpty) return (0, 0, 0);

    int sumX = 0, sumY = 0, sumZ = 0;
    for (var value in _buffer) {
      sumX += value.$1;
      sumY += value.$2;
      sumZ += value.$3;
    }
    return (
      (sumX ~/ _buffer.length),
      (sumY ~/ _buffer.length),
      (sumZ ~/ _buffer.length)
    );
  }
}

/// IMU data stream, returns raw 3-axis magnetometer and 3-axis accelerometer data
/// and optionally computes derived values
/// Note, a proper calculation of Heading requires magnetometer calibration,
/// tilt compensation (which we can do here from the accelerometer), and magnetic
/// declination adjustment (which is lat-long and time-dependent).
/// Magnetometer calibration and declination adjustments need to be done outside this class.
class RxIMU {
  final int _smoothingSamples;

  // Frame to Phone flags
  final int imuFlag;
  StreamController<IMUData>? _controller;

  // Buffers for smoothing
  late final SensorBuffer _compassBuffer;
  late final SensorBuffer _accelBuffer;

  RxIMU({
    this.imuFlag = 0x0A,
    int smoothingSamples = 1,
  }) : _smoothingSamples = smoothingSamples {
    _compassBuffer = SensorBuffer(_smoothingSamples);
    _accelBuffer = SensorBuffer(_smoothingSamples);
  }

  /// Attach this RxIMU to the Frame's dataResponse characteristic stream.
  Stream<IMUData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxIMU etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms the dataResponse elements into IMUData events
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == imuFlag)
        .listen((data) {
          Uint8List bytes = Uint8List.fromList(data);
          // reinterpret the bytes after offset 2 as signed 16-bit integers
          Int16List s16 = bytes.buffer.asInt16List(2);

          // Get raw values
          var rawCompass = (s16[0], s16[1], s16[2]);
          var rawAccel = (s16[3], s16[4], s16[5]);

          // Add to buffers
          _compassBuffer.add(rawCompass);
          _accelBuffer.add(rawAccel);

          _controller!.add(IMUData(
            compass: _compassBuffer.average,
            accel: _accelBuffer.average,
            raw: IMURawData(
              compass: rawCompass,
              accel: rawAccel,
            ),
          ));

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('ImuDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('ImuDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class IMURawData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;

  IMURawData({
    required this.compass,
    required this.accel,
  });
}

class IMUData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;
  final IMURawData? raw;

  IMUData({
    required this.compass,
    required this.accel,
    this.raw,
  });

  double get pitch => atan2(accel.$2, accel.$3) * 180.0 / pi;
  double get roll => atan2(accel.$1, accel.$3) * 180.0 / pi;
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\rx\metering_data.dart =====
----- Class: RxMeteringData -----
import 'dart:async';

import 'package:logging/logging.dart';

final _log = Logger("RxMeteringData");

/// Receive handler for metering data from the camera sensor
class RxMeteringData {

  // Frame to Phone flags
  final int meteringFlag;
  StreamController<MeteringData>? _controller;

  RxMeteringData({
    this.meteringFlag = 0x12,
  });

  /// Attach this RxMeteringData to the Frame's dataResponse characteristic stream.
  Stream<MeteringData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxMeteringData etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == meteringFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('metering data detected');
          _controller!.add(MeteringData(
            spotR: data[1],
            spotG: data[2],
            spotB: data[3],
            matrixR: data[4],
            matrixG: data[5],
            matrixB: data[6],
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('MeteringDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('MeteringDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class MeteringData {
  final int spotR;
  final int spotG;
  final int spotB;
  final int matrixR;
  final int matrixG;
  final int matrixB;

  MeteringData({
    required this.spotR,
    required this.spotG,
    required this.spotB,
    required this.matrixR,
    required this.matrixG,
    required this.matrixB,
  });
}



----- Class: MeteringData -----
import 'dart:async';

import 'package:logging/logging.dart';

final _log = Logger("RxMeteringData");

/// Receive handler for metering data from the camera sensor
class RxMeteringData {

  // Frame to Phone flags
  final int meteringFlag;
  StreamController<MeteringData>? _controller;

  RxMeteringData({
    this.meteringFlag = 0x12,
  });

  /// Attach this RxMeteringData to the Frame's dataResponse characteristic stream.
  Stream<MeteringData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxMeteringData etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == meteringFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('metering data detected');
          _controller!.add(MeteringData(
            spotR: data[1],
            spotG: data[2],
            spotB: data[3],
            matrixR: data[4],
            matrixG: data[5],
            matrixB: data[6],
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('MeteringDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('MeteringDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class MeteringData {
  final int spotR;
  final int spotG;
  final int spotB;
  final int matrixR;
  final int matrixG;
  final int matrixB;

  MeteringData({
    required this.spotR,
    required this.spotG,
    required this.spotB,
    required this.matrixR,
    required this.matrixG,
    required this.matrixB,
  });
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\rx\photo.dart =====
----- Class: RxPhoto -----
import 'dart:async';
import 'dart:typed_data';

import 'package:image/image.dart' as image_lib;
import 'package:logging/logging.dart';

final _log = Logger("RxPhoto");

/// Returns a photo as a JPEG image from Frame.
/// Note: The camera sensor on Frame is rotated 90 degrees clockwise, so raw images are rotated, but by default
/// RxPhoto will correct this by rotating -90 degrees.
/// If you want to save the cost of copyRotate here you can specify upright=false in the constructor
/// since some ML packages allow for specifying the orientation of the image when passing it in.
/// Pairs with frame.camera.read_raw(), that is, jpeg header and footer
/// are not sent from Frame - only the content, using non-final and final message types
/// Jpeg header and footer are added in here on the client, so a quality level
/// must be provided to select the correct header. Returns a Stream with exactly one jpeg as bytes, then is Done
class RxPhoto {

  // Frame to Phone flags
  final int nonFinalChunkFlag;
  final int finalChunkFlag;

  /// Whether a raw image (without 623-byte jpeg header) will be returned from Frame, hence the corresponding header should be added
  /// Note that the first request for an image with a given resolution and quality level MUST be a complete image so the jpeg header can be saved
  /// and used for subsequent raw images of the same resolution and quality level
  final bool isRaw;

  /// The quality level of the jpeg image to be returned ['VERY_LOW', 'LOW', 'MEDIUM', 'HIGH', 'VERY_HIGH']
  final String quality;

  /// The resolution of the (square) raw image to be returned from Frame
  /// Must be an even number between 100 and 720 inclusive
  final int resolution;

  /// Whether to rotate the image 90 degrees counter-clockwise to make it upright before returning it
  final bool upright;

  StreamController<Uint8List>? _controller;

  /// A map of jpeg headers for each quality level which we fill as we receive the first image of each quality level/resolution
  /// Key format is 'quality_resolution' e.g. 'VERY_LOW_512'
  static final Map<String, Uint8List> jpegHeaderMap = {};
  static bool hasJpegHeader(String quality, int resolution) => jpegHeaderMap.containsKey('${quality}_$resolution');

  RxPhoto({
    this.nonFinalChunkFlag = 0x07,
    this.finalChunkFlag = 0x08,
    this.upright = true,
    this.isRaw = false,
    required this.quality,
    required this.resolution,
  });

  /// Attach this RxPhoto to the Frame's dataResponse characteristic stream.
  /// If `isRaw` is true, then quality and resolution must be specified and match the raw image requested from Frame
  /// so that the correct jpeg header can be prepended.
  Stream<Uint8List> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxPhoto etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the image data as a list of bytes that accumulates with each packet
    List<int> imageData = List.empty(growable: true);
    int rawOffset = 0;

    // if isRaw is true, a jpeg header must be prepended to the raw image data
    if (isRaw) {
      // fetch the jpeg header for this quality level and resolution
      String key = '${quality}_$resolution';

      if (!jpegHeaderMap.containsKey(key)) {
        throw Exception('No jpeg header found for quality level $quality and resolution $resolution - request full jpeg once before requesting raw');
      }

      // add the jpeg header bytes for this quality level (623 bytes)
      imageData.addAll(jpegHeaderMap[key]!);
    }

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw data into images (as bytes)
    _controller = StreamController();

    _controller!.onListen = () {
      _log.fine('ImageDataResponse stream subscribed');
      dataResponseSubs = dataResponse
          .where(
              (data) => data[0] == nonFinalChunkFlag || data[0] == finalChunkFlag)
          .listen((data) {
        if (data[0] == nonFinalChunkFlag) {
          imageData += data.sublist(1);
          rawOffset += data.length - 1;
        }
        // the last chunk has a first byte of finalChunkFlag so stop after this
        else if (data[0] == finalChunkFlag) {
          imageData += data.sublist(1);
          rawOffset += data.length - 1;

          Uint8List finalImageBytes = Uint8List.fromList(imageData);

          // if this image is a full jpeg, save the jpeg header for this quality level and resolution
          // so that it can be prepended to raw images of the same quality level and resolution
          if (!isRaw) {
            String key = '${quality}_$resolution';
            if (!jpegHeaderMap.containsKey(key)) {
              jpegHeaderMap[key] = finalImageBytes.sublist(0, 623);
            }
          }

          // When full image data is received,
          // rotate the image counter-clockwise 90 degrees to make it upright
          // unless requested otherwise (to save processing)
          if (upright) {
            image_lib.Image? im = image_lib.decodeJpg(finalImageBytes);
            im = image_lib.copyRotate(im!, angle: 270);
            // emit the rotated jpeg bytes
            _controller!.add(image_lib.encodeJpg(im));
          }
          else {
            // emit the original rotation jpeg bytes
            _controller!.add(finalImageBytes);
          }

          // clear the buffer
          imageData.clear();
          rawOffset = 0;

          // and close the stream
          _controller!.close();
        }
        _log.finer(() => 'Chunk size: ${data.length - 1}, rawOffset: $rawOffset');
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('Controller being listened to');
    };

    _controller!.onCancel = () {
      _log.fine('ImageDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\rx\tap.dart =====
----- Class: RxTap -----
import 'dart:async';

import 'package:logging/logging.dart';

final _log = Logger("RxTap");

/// Multi-Tap data stream, returns the number of taps detected
class RxTap {

  // Frame to Phone flags
  final int tapFlag;
  final Duration threshold;
  StreamController<int>? _controller;

  RxTap({
    this.tapFlag = 0x09,
    this.threshold = const Duration(milliseconds: 300),
  });

  /// Attach this RxTap to the Frame's dataResponse characteristic stream.
  Stream<int> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxTap etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    // track state of multi-taps
    int lastTapTime = 0;
    int taps = 0;
    Timer? t;

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == tapFlag)
        .listen((data) {
          int tapTime = DateTime.now().millisecondsSinceEpoch;
          // debounce taps that occur too close to the prior tap
          if (tapTime - lastTapTime < 40) {
            _log.finer('tap ignored - debouncing');
            lastTapTime = tapTime;
          }
          else {
            _log.finer('tap detected');
            lastTapTime = tapTime;

            taps++;
            t?.cancel();
            t = Timer(threshold, () {
              _controller!.add(taps);
              taps = 0;
            });
          }

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('TapDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('TapDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }


}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\auto_exp_settings.dart =====
----- Class: TxAutoExpSettings -----
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a collection of camera settings suitable for requesting
/// the frameside app enable auto exposure and gain with the specified settings
class TxAutoExpSettings extends TxMsg {
  final int _meteringIndex;
  final double _exposure;
  final double _exposureSpeed;
  final int _shutterLimit;
  final int _analogGainLimit;
  final double _whiteBalanceSpeed;
  final int _rgbGainLimit;

  TxAutoExpSettings({
      int meteringIndex = 1, // ['SPOT', 'CENTER_WEIGHTED', 'AVERAGE'];
      double exposure = 0.1, // 0.0 <= val <= 1.0
      double exposureSpeed = 0.45, // 0.0 <= val <= 1.0
      int shutterLimit = 16383, // 4 <= val <= 16383
      int analogGainLimit = 16, // 0 <= val <= 248
      double whiteBalanceSpeed = 0.5, // 0.0 <= val <= 1.0
      int rgbGainLimit = 287, // 0 <= val <= 1023
      })
      : _meteringIndex = meteringIndex,
        _exposure = exposure,
        _exposureSpeed = exposureSpeed,
        _shutterLimit = shutterLimit,
        _analogGainLimit = analogGainLimit,
        _whiteBalanceSpeed = whiteBalanceSpeed,
        _rgbGainLimit = rgbGainLimit;

  @override
  Uint8List pack() {
    // several doubles in the range 0 to 1, so map that to an unsigned byte 0..255
    // by multiplying by 255 and rounding
    int intExp = (_exposure * 255).round() & 0xFF;
    int intExpSpeed = (_exposureSpeed * 255).round() & 0xFF;
    int intWhiteBalanceSpeed = (_whiteBalanceSpeed * 255).round() & 0xFF;

    // shutter limit has a range 4..16384 so just map it to a Uint16 over 2 bytes
    int intShutLimMsb = (_shutterLimit >> 8) & 0xFF;
    int intShutLimLsb = _shutterLimit & 0xFF;

    // RGB gain limit has a range 0..1023 so just map it to a Uint16 over 2 bytes
    int intRgbGainLimMsb = (_rgbGainLimit >> 8) & 0xFF;
    int intRgbGainLimLsb = _rgbGainLimit & 0xFF;

    // 9 bytes of auto exposure settings. sendMessage will prepend the data byte & msgCode to each packet
    // and the Uint16 payload length to the first packet
    return Uint8List.fromList([
      _meteringIndex & 0xFF,
      intExp,
      intExpSpeed,
      intShutLimMsb,
      intShutLimLsb,
      _analogGainLimit & 0xFF,
      intWhiteBalanceSpeed,
      intRgbGainLimMsb,
      intRgbGainLimLsb,
    ]);
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\capture_settings.dart =====
----- Class: TxCaptureSettings -----
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a collection of camera settings suitable for requesting
/// the frameside app to take a photo with the specified settings
class TxCaptureSettings extends TxMsg {
  final int _resolution;
  final int _qualityIndex;
  final int _pan;
  final bool _raw;

  TxCaptureSettings({
      int resolution = 512, // any even number between 100 and 720
      int qualityIndex = 4, // zero-based index into [VERY_LOW, LOW, MEDIUM, HIGH, VERY_HIGH]
      int pan = 0, // any number between -140 and 140, where 0 represents a centered image
      bool raw = false,
      })
      : _resolution = resolution,
        _qualityIndex = qualityIndex,
        _pan = pan,
        _raw = raw;

  @override
  Uint8List pack() {
    // resolution has a range 100..720 and must be even so just map resolution~/2 to a Uint16 over 2 bytes
    int halfRes = _resolution ~/ 2;
    int intHalfResolutionMsb = (halfRes >> 8) & 0xFF;
    int intHalfResolutionLsb = halfRes & 0xFF;

    // pan has a range -140..140 so add 140 and map it to a Uint16 over 2 bytes 0..280
    int panShifted = _pan + 140;
    int intPanShiftedMsb = (panShifted >> 8) & 0xFF;
    int intPanShiftedLsb = panShifted & 0xFF;

    // 6 bytes of camera capture settings. sendMessage will prepend the data byte, msgCode to each packet
    // and the Uint16 payload length to the first packet
    return Uint8List.fromList([
      _qualityIndex & 0xFF,
      intHalfResolutionMsb,
      intHalfResolutionLsb,
      intPanShiftedMsb,
      intPanShiftedLsb,
      _raw ? 0x01 : 0x00,
    ]);
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\code.dart =====
----- Class: TxCode -----
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing only a single optional byte
/// suitable for signalling the frameside app to take some action
/// (e.g. toggle streaming, take a photo with default parameters etc.)
class TxCode extends TxMsg {
  int value;

  TxCode({this.value = 0});

  @override
  Uint8List pack() {
    return Uint8List.fromList([value & 0xFF]);
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\image_sprite_block.dart =====
----- Class: TxImageSpriteBlock -----
import 'dart:typed_data';

import 'package:image/image.dart' as img;
import '../tx_msg.dart';
import 'sprite.dart';

/// Represents an image of a specified size sliced into a number of "sprite lines" of the full width of the image, and the specified height,
/// and possibly a final sprite line of a different height.
/// When sending TxImageSpriteBlock to Frame, the sendMessage() will send the header with block dimensions and sprite line height,
/// and the user then sends each line[] as a TxSprite message with the same msgCode as the Block, and the frame app will use the line height
/// to place each line. By sending each line separately we can display them as they arrive, as well as reducing overall memory
/// requirement (each concat() call is smaller).
/// Sending an ImageSpriteBlock with no lines is not intended usage.
class TxImageSpriteBlock extends TxMsg {
  final TxSprite _image;
  int get width => _image.width;
  int get height => _image.height;
  final int _spriteLineHeight;
  int get spriteLineHeight => _spriteLineHeight;

  final List<TxSprite> _spriteLines = [];
  List<TxSprite> get spriteLines => _spriteLines;

  /// intent for the Lua side to render the sprite lines as they are received,
  /// or wait until the whole image can be drawn
  final bool _progressiveRender;

  /// whether subsequent sprite lines after the first set can be sent to override the corresponding
  /// sprite lines from the original image, resulting in an updatable, dynamic image
  /// (whether progressively rendered, or not)
  /// As long as a new block header is not sent
  final bool _updatable;

  /// After construction, an ImageSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be sent
  bool get isEmpty => _spriteLines.isEmpty;

  /// After construction, an ImageSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be sent
  bool get isNotEmpty => _spriteLines.isNotEmpty;

  TxImageSpriteBlock({
    required TxSprite image,
    required int spriteLineHeight,
    bool progressiveRender = true,
    bool updatable = true
    }) : _image = image,
         _spriteLineHeight = spriteLineHeight,
         _progressiveRender = progressiveRender,
         _updatable = updatable {
    // process the full-sized sprite lines
    for (int i = 0; i < image.height ~/ spriteLineHeight; i++) {
      _spriteLines.add(
        TxSprite(
          width: image.width,
          height: spriteLineHeight,
          numColors: image.numColors,
          paletteData: image.paletteData,
          pixelData: image.pixelData.buffer.asUint8List(i * spriteLineHeight * image.width, spriteLineHeight * image.width)));
    }

    // if there is some final, shorter sprite line, process it too
    int finalHeight  = image.height % spriteLineHeight;
    if (finalHeight > 0) {
      _spriteLines.add(
        TxSprite(
          width: image.width,
          height: finalHeight,
          numColors: image.numColors,
          paletteData: image.paletteData,
          pixelData: image.pixelData.buffer.asUint8List(_spriteLines.length * spriteLineHeight * image.width, finalHeight * image.width)));
    }
  }

  /// Convert TxImageSpriteBlock back to a single image for testing/verification
  /// startLine and endLine are inclusive
  Future<Uint8List> toPngBytes() async {
    if (_spriteLines.isEmpty) {
      throw Exception('_spriteLines is empty: no image to convert toPngBytes()');
    }

    // create an image for the whole block
    var preview = img.Image(width: width, height: height);

    // copy in each of the sprites
    for (int i = 0; i <= _spriteLines.length; i++) {
      img.compositeImage(preview, _spriteLines[i].toImage(),
          dstY: (i * spriteLineHeight).toInt());
    }

    return img.encodePng(preview);
  }

  /// Corresponding parser should be called from frame_app data handler
  @override
  Uint8List pack() {
    if (_spriteLines.isEmpty) {
      throw Exception('_spriteLines is empty: no image to pack()');
    }

    // pack the width and height of the image (Uint16 each)
    int widthMsb = width >> 8;
    int widthLsb = width & 0xFF;
    int heightMsb = height >> 8;
    int heightLsb = height & 0xFF;

    // store the spriteLineHeight (Uint16)
    int spriteLineHeightMsb = spriteLineHeight >> 8;
    int spriteLineHeightLsb = spriteLineHeight & 0xFF;

    // special marker for Block header 0xFF, width and height of the block, spriteLineHeight, progressive rendering flag, updatable flag
    return Uint8List.fromList([
      0xFF,
      widthMsb,
      widthLsb,
      heightMsb,
      heightLsb,
      spriteLineHeightMsb,
      spriteLineHeightLsb,
      _progressiveRender ? 1 : 0,
      _updatable ? 1 : 0,
    ]);
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\manual_exp_settings.dart =====
----- Class: TxManualExpSettings -----
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a collection of camera settings suitable for requesting
/// the frameside app enable manual exposure and gain with the specified settings
class TxManualExpSettings extends TxMsg {
  final int _manualShutter;
  final int _manualAnalogGain;
  final int _manualRedGain;
  final int _manualGreenGain;
  final int _manualBlueGain;

  TxManualExpSettings({
      int manualShutter = 4096, // 4 <= val <= 16383
      int manualAnalogGain = 1, // 0 <= val <= 248
      int manualRedGain = 121, // 0 <= val <= 1023
      int manualGreenGain = 64, // 0 <= val <= 1023
      int manualBlueGain = 140, // 0 <= val <= 1023
      })
      : _manualShutter = manualShutter,
        _manualAnalogGain = manualAnalogGain,
        _manualRedGain = manualRedGain,
        _manualGreenGain = manualGreenGain,
        _manualBlueGain = manualBlueGain;

  @override
  Uint8List pack() {
    // manual shutter has a range 4..16384 so just map it to a Uint16 over 2 bytes
    int intManShutterMsb = (_manualShutter >> 8) & 0xFF;
    int intManShutterLsb = _manualShutter & 0xFF;

    // manual color gains have a range 0..1023 so just map them to a Uint16 over 2 bytes
    int intManRedGainMsb = (_manualRedGain >> 8) & 0x03;
    int intManRedGainLsb = _manualRedGain & 0xFF;
    int intManGreenGainMsb = (_manualGreenGain >> 8) & 0x03;
    int intManGreenGainLsb = _manualGreenGain & 0xFF;
    int intManBlueGainMsb = (_manualBlueGain >> 8) & 0x03;
    int intManBlueGainLsb = _manualBlueGain & 0xFF;

    // 9 bytes of manual exposure settings. sendMessage will prepend the data byte & msgCode to each packet
    // and the Uint16 payload length to the first packet
    return Uint8List.fromList([
      intManShutterMsb,
      intManShutterLsb,
      _manualAnalogGain & 0xFF,
      intManRedGainMsb,
      intManRedGainLsb,
      intManGreenGainMsb,
      intManGreenGainLsb,
      intManBlueGainMsb,
      intManBlueGainLsb,
    ]);
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\plain_text.dart =====
----- Class: TxPlainText -----
import 'dart:convert';
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a String of plain text,
/// plus optional top-left corner position coordinates for the
/// text to be printed in the Frame display (Lua/1-based, i.e. [1,1] to [640,400])
/// plus an optional palette offset (1..15, 0/'VOID' is invalid), plus optional character spacing
class TxPlainText extends TxMsg {
  final String _text;
  final int _x, _y;
  final int _paletteOffset;
  final int _spacing;

  TxPlainText({required String text, int x = 1, int y = 1, int paletteOffset = 1, int spacing = 4}) : _text = text, _x = x, _y = y, _paletteOffset = paletteOffset, _spacing = spacing;

  @override
  Uint8List pack() {
    final stringBytes = utf8.encode(_text);
    final strlen = stringBytes.length;

    Uint8List bytes = Uint8List(6 + strlen);
    bytes[0] = _x >> 8;   // x msb
    bytes[1] = _x & 0xFF; // x lsb
    bytes[2] = _y >> 8;   // y msb
    bytes[3] = _y & 0xFF; // y lsb
    bytes[4] = _paletteOffset & 0x0F; // 1..15
    bytes[5] = _spacing & 0xFF;
    bytes.setRange(6, strlen + 6, stringBytes);

    return bytes;
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\sprite.dart =====
----- Class: TxSprite -----
import 'dart:math';
import 'dart:typed_data';

import 'package:image/image.dart' as img;
import 'package:logging/logging.dart';
import '../tx_msg.dart';

final _log = Logger("TxSprite");

class TxSprite extends TxMsg {
  late final int _width;
  int get width => _width;
  late final int _height;
  int get height => _height;
  late final int _numColors;
  int get numColors => _numColors;
  late final Uint8List _paletteData;
  Uint8List get paletteData => _paletteData;
  late final Uint8List _pixelData;
  Uint8List get pixelData => _pixelData;

  /// Create a sprite with the specified size, palette data and pixel data, identified by the specified message code (the identifier used on the Lua side to label this sprite)
  /// width(Uint16), height(Uint16), bpp(Uint8), numColors(Uint8), palette (Uint8 r, Uint8 g, Uint8 b)*numColors, data (length: width x height bytes content: palette index)
  TxSprite({
    required int width,
    required int height,
    required int numColors,
    required Uint8List paletteData,
    required Uint8List pixelData})
    : _width = width,
      _height = height,
      _numColors = numColors,
      _paletteData = paletteData,
      _pixelData = pixelData;

  /// Create a TxSprite from any image bytes that can be decoded by img.decode()
  /// If it's an indexed image, quantize down to 14 colors if larger
  /// (plus black, white as palette entries 0 and 1.)
  /// If it's an RGB image, also quantize to 14 colors (then prepend black and white)
  /// Scale to 640x400 preserving aspect ratio for 1- or 2-bit images
  /// Scale to ~128k pixels preserving aspect ratio for 4-bit images
  /// TODO improve quantization - quality, speed
  /// If quantizing, since neuralNet seems to give the black in entry 0 and white in the last entry
  /// We just leave 0 (black) and swap palette entries 1 and 15 (and remap those pixels)
  TxSprite.fromImageBytes({required Uint8List imageBytes}) {
    var image = img.decodeImage(imageBytes);

    if (image == null) throw Exception('Unable to decode image file');

    // the number of colors in the image (after optional quantization), must be 16 or fewer
    final int numColors;
    bool quantized = false;

    if ((image.hasPalette && image.palette!.numColors > 16) || !image.hasPalette) {
      _log.fine('quantizing image');
      // note, even though we ask for only numberOfColors here, neuralNet gives us back a palette of 256
      // with only the first numberOfColors populated, ordered by increasing luminance (TODO and always containing black, then colors, then white last)
      // we'll trim that palette array down to 16*3 later
      image = img.quantize(image, numberOfColors: 16, method: img.QuantizeMethod.neuralNet, dither: img.DitherKernel.none);
      numColors = 16;
      quantized = true;
    }
    else {
      _log.fine('16 or fewer colors in an indexed image, no quantizing required');
      numColors = image.palette!.numColors;
    }

    if (image.width > 640 || image.height > 400) {
      _log.fine('scaling down oversized image');

      if (image.palette!.numColors <= 4) {
        _log.fine('Low bit depth image, scale to 640x400');
        // 1- or 2-bit images can take as much of 640x400 as needed, preserving aspect ratio
        // use nearest interpolation, we can't use any interpolation that averages colors
        image = img.copyResize(image,
            width: 640,
            height: 400,
            maintainAspect: true,
            interpolation: img.Interpolation.nearest);
      }
      else {
        _log.fine('4-bit image, scale to max 128k pixels');
        // 4-bit images need to be smaller or else we run out of memory. Limit to 64kb, or 128k pixels
        int numSrcPixels = image.height * image.width;

        if (numSrcPixels > 128000) {
          double scaleFactor = sqrt(128000 / numSrcPixels);
          _log.fine(() => 'scaling down by $scaleFactor');

          image = img.copyResize(image,
              width: (image.width * scaleFactor).toInt().clamp(1, 640),
              height: (image.height * scaleFactor).toInt().clamp(1, 400),
              maintainAspect: true,
              interpolation: img.Interpolation.nearest);
        }
        else {
          _log.fine('small 4-bit image, no need to scale down pixels, just max extent in height or width');
          // TODO does this scale up if the image is smaller? It doesn't need to do this.
          image = img.copyResize(image,
              width: 640,
              height: 400,
              maintainAspect: true,
              interpolation: img.Interpolation.nearest);
        }
      }
    }

    _width = image.width;
    _height = image.height;
    _pixelData = image.data!.toUint8List();
    // use a temporary palette in case we need to expand it to add VOID at the start
    Uint8List? initialPalette;

    // we can process RGB or RGBA format palettes, but any others we just exclude here
    if (image.palette!.numChannels == 3) {
      _log.fine('3-channel palette');
      // take the sublist because neuralNet quantized images have the number of colors we want
      // but packaged in a length 256 palette (a bug)
      initialPalette = image.palette!.toUint8List().sublist(0, 3 * numColors);
    }
    else if (image.palette!.numChannels == 4) {
      _log.fine('4-channel palette');
      // strip out the alpha channel from the palette
      // take the sublist because neuralNet quantized images have the number of colors we want
      // but packaged in a length 256 palette (a bug)
      initialPalette = _extractRGB(image.palette!.toUint8List().sublist(0, 4 * numColors));
    }
    else {
      throw Exception('Image colors must have 3 or 4 channels to be converted to a sprite');
    }

    // Frame uses palette entry 0 for VOID.
    // If we can fit another color, we can add VOID at the start and shift every pixel up by one.
    // If we can't fit any more colors, for now just set 0 to black (otherwise the rest of the display
    // will be lit)
    // We move the white palette index to 1 so that regular white text displays OK
    // TODO in future we could:
    // - find an alpha color from the palette (if it exists), and swap it with the color in 0
    // - find black from the palette (if it exists), and swap it with the color in 0
    // - find the darkest luminance color and swap it with the color in 0
    // - neuralNet quantizer seems to set 0 to black and max color to white.
    if (image.palette!.numColors < 16) {
      _log.fine('fewer than 16 colors');

      // if the first RGB color of the palette is not black/void, we need to
      // insert another color (which may promote the image to 2-bit or 4-bit)
      // but no need to if the palette already has black at the start
      if (initialPalette[0] != 0 || initialPalette[1] != 0 || initialPalette[2] != 0) {
        // TODO consider checking for whether we can move/add white to the #1 slot without
        // increasing the palette size to the next bitness
        _log.fine('insert black at the front of the palette');
        _numColors = image.palette!.numColors + 1;

        _paletteData = Uint8List(initialPalette.length + 3);
        _paletteData.setAll(3, initialPalette);
        _log.fine(initialPalette);
        _log.fine(_paletteData);

        // update all the pixels to refer to the new palette index
        for (int i=0; i<_pixelData.length; i++) {
          _pixelData[i] += 1;
        }
      }
      else {
        // palette already has black at the start, just copy it over
        _log.fine('black already at the start of the palette');
        _numColors = image.palette!.numColors;
        _paletteData = initialPalette;
      }
    }
    else {
      _log.fine('exactly 16 colors');

      if (!quantized) {
        // 16 colors in palette set by user's file, might not have black in slot 0
        _log.fine('16 colors exactly, make sure 0 is set to black');
        _numColors = image.palette!.numColors;
        // can't fit any more colors, set entry 0 to black
        _paletteData = initialPalette;
        _paletteData[0] = 0;
        _paletteData[1] = 0;
        _paletteData[2] = 0;
        _log.fine(initialPalette);
        _log.fine(_paletteData);
      }
      else {
        _log.fine('16 colors coming from quantizer');

        _numColors = 16;
        _paletteData = initialPalette;
        _log.fine(initialPalette);
        // black is already in #0 [0, 1, 2]

        // swap color in #1 [3, 4, 5] with white, which is in #15 [45, 46, 47]
        var swapR = _paletteData[3];
        var swapG = _paletteData[4];
        var swapB = _paletteData[5];
        _paletteData[3] = 255;
        _paletteData[4] = 255;
        _paletteData[5] = 255;
        _paletteData[45] = swapR;
        _paletteData[46] = swapG;
        _paletteData[47] = swapB;

        _log.fine(_paletteData);

        // update all the pixels to swap the palette index for white and the color that was in #1
        for (int i=0; i<_pixelData.length; i++) {
          if (_pixelData[i] == 1) {
            _pixelData[i] = 15;
          }
          else if (_pixelData[i] == 15) {
            _pixelData[i] = 1;
          }
        }
      }

      _log.fine(() => 'Sprite: $_width x $_height, $_numColors cols, ${pack().length} bytes');
    }
  }

  /// Create a TxSprite from an indexed PNG
  /// Sprites should be PNGs with palettes of up to 2, 4, or 16 colors (1-, 2-, or 4-bit indexed palettes)
  /// Alpha channel (4th-RGBA), if present, is dropped before sending to Frame (RGB only, but color 0 is VOID)
  /// Scale to 640x400 if larger, preserving aspect ratio
  TxSprite.fromPngBytes({required Uint8List pngBytes}) {
    var imgPng = img.PngDecoder().decode(pngBytes);

    if (imgPng != null &&
        imgPng.hasPalette &&
        imgPng.palette!.numColors <= 16) {
      // resize the image if it's too big - we really shouldn't have to do this for project sprites, just user-picked images
      if (imgPng.width > 640 || imgPng.height > 400) {
        // use nearest interpolation, we can't use any interpolation that averages colors
        imgPng = img.copyResize(imgPng,
            width: 640,
            height: 400,
            maintainAspect: true,
            interpolation: img.Interpolation.nearest);
      }

      _width = imgPng.width;
      _height = imgPng.height;
      _numColors = imgPng.palette!.numColors;
      _pixelData = imgPng.data!.toUint8List();

      // we can process RGB or RGBA format palettes, but any others we just exclude here
      if (imgPng.palette!.numChannels == 3 ||
          imgPng.palette!.numChannels == 4) {
        if (imgPng.palette!.numChannels == 3) {
          _paletteData = imgPng.palette!.toUint8List();
        }
        else if (imgPng.palette!.numChannels == 4) {
          // strip out the alpha channel from the palette
          _paletteData = _extractRGB(imgPng.palette!.toUint8List());
        }

        //_log.fine('Sprite: ${imgPng.width} x ${imgPng.height}, ${imgPng.palette!.numColors} cols, ${sprite.pack().length} bytes');
      } else {
        throw Exception(
            'PNG colors must have 3 or 4 channels to be converted to a sprite');
      }
    } else {
      throw Exception(
          'PNG must be a valid PNG image with a palette (indexed color) and 16 colors or fewer to be converted to a sprite');
    }
  }

  /// Strips the Alpha byte out of a list of RGBA colors
  /// Takes a Uint8List of length 4n made of RGBA bytes, and takes the first 3 bytes out of each 4 (RGB)
  Uint8List _extractRGB(Uint8List rgba) {
    _log.fine('extracting RGB from RGBA');
    // The output list will have 3/4 the length of the input list
    Uint8List rgb = Uint8List((rgba.length * 3) ~/ 4);

    int rgbIndex = 0;
    for (int i = 0; i < rgba.length; i += 4) {
      rgb[rgbIndex++] = rgba[i]; // R
      rgb[rgbIndex++] = rgba[i + 1]; // G
      rgb[rgbIndex++] = rgba[i + 2]; // B
    }

    return rgb;
  }

  /// Corresponding parser should be called from frame_app.lua data_handler()
  @override
  Uint8List pack() {
    int widthMsb = _width >> 8;
    int widthLsb = _width & 0xFF;
    int heightMsb = _height >> 8;
    int heightLsb = _height & 0xFF;
    int bpp = 0;
    Uint8List packed;
    switch (_numColors) {
      case <= 2:
        bpp = 1;
        packed = pack1Bit(_pixelData);
        break;
      case <= 4:
        bpp = 2;
        packed = pack2Bit(_pixelData);
        break;
      case <= 16:
        bpp = 4;
        packed = pack4Bit(_pixelData);
        break;
      default:
        throw Exception(
            'Image must have 16 or fewer colors. Actual: $_numColors');
    }

    // preallocate the list of bytes to send - sprite header, palette, pixel data
    // (packed.length already adds the extra byte if WxH is not divisible by 8)
    Uint8List payload =
        Uint8List.fromList(List.filled(6 + _numColors * 3 + packed.length, 0));

    // NB: palette data could be numColors=12 x 3 (RGB) bytes even if bpp is 4 (max 16 colors)
    // hence we provide both numColors and bpp here.
    // sendMessage will prepend the data byte, msgCode to each packet
    // and the Uint16 payload length to the first packet
    payload
        .setAll(0, [widthMsb, widthLsb, heightMsb, heightLsb, bpp, _numColors]);
    payload.setAll(6, _paletteData);
    payload.setAll(6 + _numColors * 3, packed);

    return payload;
  }

  static Uint8List pack1Bit(Uint8List bpp1) {
    int byteLength =
        (bpp1.length + 7) ~/ 8; // Calculate the required number of bytes
    Uint8List packed =
        Uint8List(byteLength); // Create the Uint8List to hold packed bytes

    for (int i = 0; i < bpp1.length; i++) {
      int byteIndex = i ~/ 8;
      int bitIndex = i % 8;
      packed[byteIndex] |= (bpp1[i] & 0x01) << (7 - bitIndex);
    }

    return packed;
  }

  static Uint8List pack2Bit(Uint8List bpp2) {
    int byteLength =
        (bpp2.length + 3) ~/ 4; // Calculate the required number of bytes
    Uint8List packed =
        Uint8List(byteLength); // Create the Uint8List to hold packed bytes

    for (int i = 0; i < bpp2.length; i++) {
      int byteIndex = i ~/ 4;
      int bitOffset = (3 - (i % 4)) * 2;
      packed[byteIndex] |= (bpp2[i] & 0x03) << bitOffset;
    }

    return packed;
  }

  static Uint8List pack4Bit(Uint8List bpp4) {
    int byteLength =
        (bpp4.length + 1) ~/ 2; // Calculate the required number of bytes
    Uint8List packed =
        Uint8List(byteLength); // Create the Uint8List to hold packed bytes

    for (int i = 0; i < bpp4.length; i++) {
      int byteIndex = i ~/ 2;
      int bitOffset = (1 - (i % 2)) * 4;
      packed[byteIndex] |= (bpp4[i] & 0x0F) << bitOffset;
    }

    return packed;
  }

  /// Convert TxSprite back to an image for testing/verification
  img.Image toImage() {
    // set up the indexed palette
    img.PaletteUint8 pal = img.PaletteUint8(_numColors, 3);
    pal.buffer.asUint8List().setAll(0, _paletteData);

    // TODO Image.palette() doesn't seem to correctly create indexed image.
    // instead, expand out the image to RGB pixels since this is just for phoneside display
    var data = img.ImageDataUint8(_width, _height, 3);
    int pixNum = 0;

    for (var palEntry in _pixelData) {
      data.setPixelRgb(
          pixNum % _width,
          pixNum ~/ _width,
          _paletteData[palEntry * 3],
          _paletteData[palEntry * 3 + 1],
          _paletteData[palEntry * 3 + 2]);

      pixNum++;
    }

    return img.Image.fromBytes(
        width: _width, height: _height, bytes: data.buffer, numChannels: 3);
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx\text_sprite_block.dart =====
----- Class: TxTextSpriteBlock -----
import 'dart:typed_data';
import 'dart:ui' as ui;
import 'dart:ui';

import 'package:image/image.dart' as img;
import '../tx_msg.dart';
import 'sprite.dart';

/// Represents an (optionally) multi-line block of text of a specified width and number of visible rows at a specified lineHeight
/// If the supplied text string is longer, only the last `displayRows` will be shown rendered and sent to Frame.
/// If the supplied text string has fewer than or equal to `displayRows`, only the number of actual rows will be rendered and sent to Frame
/// If any given line of text is shorter than width, the text Sprite will be set to the actual width required.
/// When sending TxTextSpriteBlock to Frame, the sendMessage() will send the header with block dimensions and line-by-line offsets
/// and the user then sends each line[] as a TxSprite message with the same msgCode as the Block, and the frame app will use the offsets
/// to place each line. By sending each line separately we can display them as they arrive, as well as reducing overall memory
/// requirement (each concat() call is smaller).
/// After calling the constructor, check `isNotEmpty` before calling `rasterize()` and sending the header or the sprites.
/// Sending a TextSpriteBlock with no lines is not intended usage.
/// `text` is trimmed (leading and trailing whitespace) before laying out the paragraph, but any blank lines
/// within the range of displayed rows will be sent as an empty (1px) TxSprite
class TxTextSpriteBlock extends TxMsg {
  final int _width;
  int get width => _width;
  final int _fontSize;
  int get fontSize => _fontSize;
  final int _maxDisplayRows;
  int get maxDisplayRows => _maxDisplayRows;
  final List<TxSprite> _sprites = [];
  List<TxSprite> get rasterizedSprites => _sprites;

  late final ui.Paragraph _paragraph;
  late final List<ui.LineMetrics> _lineMetrics;
  int get numLines => _lineMetrics.length;

  static img.PaletteUint8? monochromePal;

  /// return a 2-color, 3-channel palette (just black then white)
  static img.PaletteUint8 _getPalette() {
    if (monochromePal == null) {
      monochromePal = img.PaletteUint8(2, 3);
      monochromePal!.setRgb(0, 0, 0, 0);
      monochromePal!.setRgb(1, 255, 255, 255);
    }

    return monochromePal!;
  }

  /// After construction, a TextSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be rasterized nor sent
  bool get isEmpty => _lineMetrics.isEmpty;

  /// After construction, a TextSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be rasterized nor sent
  bool get isNotEmpty => _lineMetrics.isNotEmpty;

  TxTextSpriteBlock({
      required int width,
      required int fontSize,
      required int maxDisplayRows,
      String? fontFamily,
      ui.TextAlign textAlign = ui.TextAlign.left,
      ui.TextDirection textDirection = ui.TextDirection.ltr,
      required String text})
      : _width = width,
        _fontSize = fontSize,
        _maxDisplayRows = maxDisplayRows {
    final paragraphBuilder = ui.ParagraphBuilder(ui.ParagraphStyle(
      textAlign: textAlign,
      textDirection: textDirection,
      fontFamily: fontFamily, // gets platform default if null
      fontSize: _fontSize.toDouble(), // Adjust font size as needed
    ));

    paragraphBuilder.addText(text);
    _paragraph = paragraphBuilder.build();

    _paragraph.layout(ui.ParagraphConstraints(width: width.toDouble()));

    // work out height using metrics after paragraph.layout() call
    _lineMetrics = _paragraph.computeLineMetrics();
  }

  /// Since the Paragraph rasterizing to the Canvas, and the getting of the Image bytes
  /// are async functions, there needs to be an async function not just the constructor.
  /// Plus we want the caller to decide how many lines of a long paragraph to rasterize, and when.
  /// Text lines as TxSprites are accumulated in this object.
  /// startLine and endLine are inclusive
  Future<void> rasterize({required int startLine, required int endLine}) async {
    if (isNotEmpty) {

      if (startLine < 0 || startLine > _lineMetrics.length - 1) throw Exception('startLine must be > 0 and < ${_lineMetrics.length}');
      if (endLine < startLine || endLine > _lineMetrics.length - 1) throw Exception('endLine must be >= startLine and < ${_lineMetrics.length}');

      // Calculate the top and bottom boundaries for the selected lines
      double topBoundary = 0;
      double bottomBoundary = 0;

      // work out a clip rectangle so we only draw the lines between startLine and endLine
      topBoundary = _lineMetrics[startLine].baseline - _lineMetrics[startLine].ascent;
      bottomBoundary = _lineMetrics[endLine].baseline + _lineMetrics[endLine].descent;

      // Define the area to clip: a window over the selected lines
      final clipRect = Rect.fromLTWH(
        0, // Start from the left edge of the canvas
        topBoundary, // Start clipping from the top of the startLine
        width.toDouble(), // Full width of the paragraph
        bottomBoundary - topBoundary, // Height of the selected lines
      );

      final pictureRecorder = ui.PictureRecorder();
      final canvas = ui.Canvas(pictureRecorder);
      canvas.clipRect(clipRect);

      canvas.drawParagraph(_paragraph, ui.Offset.zero);
      final ui.Picture picture = pictureRecorder.endRecording();

      final int totalHeight = (bottomBoundary - topBoundary).toInt();
      final int topOffset = topBoundary.toInt();

      final ui.Image image = await picture.toImage(_width, totalHeight);

      var byteData =
          (await image.toByteData(format: ui.ImageByteFormat.rawUnmodified))!;

      // loop over each requested line of text in the paragraph and create a TxSprite
      for (var line in _lineMetrics.sublist(startLine, endLine + 1)) {
        final int tlX = line.left.toInt();
        final int tlY = (line.baseline - line.ascent).toInt();
        final int tlyShifted = tlY - topOffset;
        int lineWidth = line.width.toInt();
        int lineHeight = (line.ascent + line.descent).toInt();

        // check for non-blank lines
        if (lineWidth > 0 && lineHeight > 0) {
          var linePixelData = Uint8List(lineWidth * lineHeight);

          for (int i = 0; i < lineHeight; i++) {
            // take one row of the source image byteData, remembering it's in RGBA so 4 bytes per pixel
            // and remembering the origin of the image is the top of the startLine, so we need to
            // shift all the top-left Ys by that first Y offset.
            var sourceRow = byteData.buffer
                .asUint8List(((tlyShifted + i) * _width + tlX) * 4, lineWidth * 4);

            for (int j = 0; j < lineWidth; j++) {
              // take only every 4th byte because the source buffer is RGBA
              // and map it to palette index 1 if it's 128 or bigger (monochrome palette only, and text rendering will be anti-aliased)
              linePixelData[i * lineWidth + j] = sourceRow[4 * j] >= 128 ? 1 : 0;
            }
          }

          // make a Sprite out of the line and add to the list
          _sprites.add(TxSprite(
            width: lineWidth,
            height: lineHeight,
            numColors: 2,
            paletteData: _getPalette().data,
            pixelData: linePixelData
          ));
        }
        else {
          // zero-width line, a blank line in the text block
          // so we make a 1x1 px sprite in the void color
          _sprites.add(TxSprite(
            width: 1,
            height: 1,
            numColors: 2,
            paletteData: _getPalette().data,
            pixelData: Uint8List(1)
          ));
        }
      }
    }
  }

  /// Convert TxTextSpriteBlock back to a single image for testing/verification
  /// startLine and endLine are inclusive
  Future<Uint8List> toPngBytes({required int startLine, required int endLine}) async {
    if (_sprites.isEmpty) {
      throw Exception('_sprites is empty: call rasterize() before toPngBytes()');
    }

    // work out which range of lines we're drawing, and shift up by topOffset in Y
    final double topBoundary = _lineMetrics[startLine].baseline - _lineMetrics[startLine].ascent;
    final double bottomBoundary = _lineMetrics[endLine].baseline + _lineMetrics[endLine].descent;
    final int totalHeight = (bottomBoundary - topBoundary).toInt();
    final int topOffset = topBoundary.toInt();

    // create an image for the whole block
    var preview = img.Image(width: width, height: totalHeight);

    // copy in each of the sprites
    for (int i = startLine; i <= endLine; i++) {
      img.compositeImage(preview, rasterizedSprites[i].toImage(),
          dstY: (_lineMetrics[i].baseline - _lineMetrics[i].ascent - topOffset).toInt());
    }

    return img.encodePng(preview);
  }

  /// Corresponding parser should be called from frame_app data handler
  @override
  Uint8List pack() {
    if (_sprites.isEmpty) {
      throw Exception('_sprites is empty: call rasterize() before pack()');
    }

    int widthMsb = _width >> 8;
    int widthLsb = _width & 0xFF;

    // store the x (16-bit) and y (16-bit) offsets as pairs for each of the lines
    Uint8List offsets = Uint8List(_lineMetrics.length * 4);

    for (int i = 0; i < _lineMetrics.length; i++) {
      var lm = _lineMetrics[i];
      int xOffset = lm.left.toInt();
      int yOffset = (lm.baseline - lm.ascent).toInt();
      offsets[4 * i] = xOffset >> 8;
      offsets[4 * i + 1] = xOffset & 0xFF;
      offsets[4 * i + 2] = yOffset >> 8;
      offsets[4 * i + 3] = yOffset & 0xFF;
    }

    // special marker for Block header 0xFF, width of the block, max display rows, num lines, offsets within block for each line
    return Uint8List.fromList([
      0xFF,
      widthMsb,
      widthLsb,
      _maxDisplayRows & 0xFF,
      _sprites.length & 0xFF,
      ...offsets
    ]);
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_msg-main\lib\tx_msg.dart =====
----- Class: for -----
import 'dart:typed_data';

/// The base class for all Tx (transmit phone to Frame) messages that can be sent using sendMessage()
/// which performs splitting across multiple MTU-sized packets
/// an assembled automatically frameside by the data handler.
abstract class TxMsg {

  /// pack() should produce a message data payload that can be parsed by a corresponding
  /// parser in the frameside application (Lua)
  /// The 0x01 (raw user data marker) byte and the msgCode byte are
  /// prepended to each bluetooth write() call by the Frame BLE sendDataRaw() method,
  /// followed by the maximum amount of payload data that will fit until the whole message is sent.
  Uint8List pack();
}



----- Class: TxMsg -----
class TxMsg {

  /// pack() should produce a message data payload that can be parsed by a corresponding
  /// parser in the frameside application (Lua)
  /// The 0x01 (raw user data marker) byte and the msgCode byte are
  /// prepended to each bluetooth write() call by the Frame BLE sendDataRaw() method,
  /// followed by the maximum amount of payload data that will fit until the whole message is sent.
  Uint8List pack();
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_vision_api-main\lib\api_call.dart =====
----- Class: ApiService -----
import 'package:http/http.dart' as http;
import 'package:http_parser/http_parser.dart';

class ApiService {
  final String endpointUrl;

  ApiService({required this.endpointUrl});

  Future<String> processImage({
    required List<int> imageBytes,
    String fileName = 'image.jpg',
  }) async {
    // Create multipart request
    final request = http.MultipartRequest('POST', Uri.parse(endpointUrl));

    // Add image file
    final multipartFile = http.MultipartFile.fromBytes(
      'image',
      imageBytes,
      filename: fileName,
      contentType: MediaType('image', 'jpeg'),
    );
    request.files.add(multipartFile);

    // Send request
    final streamedResponse = await request.send();
    final response = await http.Response.fromStream(streamedResponse);

    if (response.statusCode != 200) {
      throw Exception('API call returned status ${response.statusCode}: ${response.body}');
    }

    return response.body;
  }
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_vision_api-main\lib\foreground_service.dart =====
----- Class: _ForegroundFirstTaskHandler -----
import 'dart:isolate';
import 'package:flutter_foreground_task/flutter_foreground_task.dart';
import 'package:logging/logging.dart';

final _log = Logger("Foreground task");

void initializeForegroundService() {
  FlutterForegroundTask.init(
    androidNotificationOptions: AndroidNotificationOptions(
      channelId: 'foreground_service',
      channelName: 'Frame Service',
      channelImportance: NotificationChannelImportance.MIN,
      iconData: null,
    ),
    iosNotificationOptions: const IOSNotificationOptions(
      showNotification: false,
      playSound: false,
    ),
    foregroundTaskOptions: const ForegroundTaskOptions(
      isOnceEvent: true,
    ),
  );
}

Future<void> startForegroundService() async {
  if (!(await FlutterForegroundTask.isRunningService)) {
    FlutterForegroundTask.startService(
      notificationTitle: 'Frame is connected',
      notificationText: 'Tap to return to the app',
      callback: _startForegroundCallback,
    );
  }
}

@pragma('vm:entry-point')
void _startForegroundCallback() {
  FlutterForegroundTask.setTaskHandler(_ForegroundFirstTaskHandler());
}

class _ForegroundFirstTaskHandler extends TaskHandler {
  @override
  void onStart(DateTime timestamp, SendPort? sendPort) async {
    _log.info("Starting foreground task");
  }

  @override
  void onRepeatEvent(DateTime timestamp, SendPort? sendPort) async {
    _log.info("Foreground repeat event triggered");
  }

  @override
  void onDestroy(DateTime timestamp, SendPort? sendPort) async {
    _log.info("Destroying foreground task");
    FlutterForegroundTask.stopService();
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_vision_api-main\lib\main.dart =====
----- Class: MainApp -----
import 'dart:async';
import 'dart:typed_data';

import 'package:flutter/material.dart';
import 'package:flutter_foreground_task/flutter_foreground_task.dart';
import 'package:logging/logging.dart';
import 'package:share_plus/share_plus.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:simple_frame_app/frame_vision_app.dart';
import 'package:simple_frame_app/simple_frame_app.dart';
import 'package:frame_msg/tx/plain_text.dart';

import 'api_call.dart';
import 'foreground_service.dart';
import 'text_pagination.dart';

void main() {
  // Set up Android foreground service
  initializeForegroundService();

  runApp(const MainApp());
}

final _log = Logger("MainApp");

class MainApp extends StatefulWidget {
  const MainApp({super.key});

  @override
  MainAppState createState() => MainAppState();
}

/// FrameVisionAppState mixin provides scaffolding for photo capture on (multi-) tap and a mechanism for processing each photo
/// in addition to the connection and application state management provided by SimpleFrameAppState
class MainAppState extends State<MainApp> with SimpleFrameAppState, FrameVisionAppState {

  // Custom API state
  String _apiEndpoint = '';
  final TextEditingController _apiEndpointTextFieldController = TextEditingController();
  final TextEditingController _promptTextFieldController = TextEditingController();

  // the image and metadata to show
  Image? _image;
  Uint8List? _imageData;
  ImageMetadata? _imageMeta;
  bool _processing = false;

  // the response to show, and the timer to clear it after 10s
  Timer? _clearTimer;
  final List<String> _responseTextList = [];
  final TextPagination _pagination = TextPagination();

  MainAppState() {
    Logger.root.level = Level.INFO;
    Logger.root.onRecord.listen((record) {
      debugPrint('${record.level.name}: ${record.time}: ${record.message}');
    });
  }

  @override
  void dispose() {
    _apiEndpointTextFieldController.dispose();
    _promptTextFieldController.dispose();
    super.dispose();
  }

  @override
  void initState() {
    super.initState();

    // Frame connection and saved text field loading need to be performed asynchronously
    asyncInit();
  }

  Future<void> asyncInit() async {
    await _loadApiEndpoint();

    // kick off the connection to Frame and start the app if possible (unawaited)
    tryScanAndConnectAndStart(andRun: true);
  }

  Future<void> _loadApiEndpoint() async {
    final prefs = await SharedPreferences.getInstance();

    setState(() {
      _apiEndpoint = prefs.getString('api_endpoint') ?? '';
      _apiEndpointTextFieldController.text = _apiEndpoint;
    });
  }

  Future<void> _saveApiEndpoint() async {
    _apiEndpoint = _apiEndpointTextFieldController.text;
    final prefs = await SharedPreferences.getInstance();
    await prefs.setString('api_endpoint', _apiEndpoint);
  }

  @override
  Future<void> onRun() async {
    await frame!.sendMessage(0x0a,
      TxPlainText(
        text: '3-Tap: take photo\n______________\n1-Tap: next page\n2-Tap: previous page'
      ).pack()
    );
  }

  @override
  Future<void> onCancel() async {
    _responseTextList.clear();
    _pagination.clear();
  }

  @override
  Future<void> onTap(int taps) async {
    switch (taps) {
      // Next Page
      case 1:
        // Cancel any pending clear operations
        _clearTimer?.cancel();
        _clearTimer = null;

        // next
        _pagination.nextPage();
        await frame!.sendMessage(0x0a,
          TxPlainText(
            text: _pagination.getCurrentPage().join('\n')
          ).pack()
        );
        break;
      // Previous Page
      case 2:
        // Cancel any pending clear operations
        _clearTimer?.cancel();
        _clearTimer = null;

        // prev
        _pagination.previousPage();
        await frame!.sendMessage(0x0a,
          TxPlainText(
            text: _pagination.getCurrentPage().join('\n')
          ).pack()
        );
        break;
      // Take Photo
      case 3:
        // check if there's processing in progress already and drop the request if so
        if (!_processing) {
          _processing = true;
          // start new vision capture

          // Cancel any pending clear operations
          _clearTimer?.cancel();
          _clearTimer = null;

          // show we're capturing on the Frame display
          await frame!.sendMessage(0x0a,
            TxPlainText(
              text: '\u{F0007}', // starry eyes emoji
              paletteOffset: 8, // yellow
            ).pack()
          );

          // asynchronously kick off the capture/processing pipeline
          capture().then(process);
        }
        break;
      default:
    }
  }

  /// The vision pipeline to run when a photo is captured
  FutureOr<void> process((Uint8List, ImageMetadata) photo) async {
    var imageData = photo.$1;
    var meta = photo.$2;

    try {
      // update UI with image and empty the text list
      setState(() {
        _imageData = imageData;
        _image = Image.memory(imageData, gaplessPlayback: true,);
        _imageMeta = meta;
        _responseTextList.clear();
      });

      // Perform vision processing pipeline on the current image
      // Initialize the service with the current _apiEndpoint
      final apiService = ApiService(endpointUrl: _apiEndpoint);

      // show we're calling the API
      await frame!.sendMessage(0x0a,
        TxPlainText(
          text: '\u{F0003}', // 3d shades emoji
          x: 285,
          y: 1,
          paletteOffset: 8,
        ).pack()
      );

      try {
        // Make the API call
        final response = await apiService.processImage(
          imageBytes: imageData,
        );

        // Handle the response
        _log.fine(() => 'Received text: $response');

        // show in ListView and paginate for Frame
        _handleResponseText(response);

      } catch (e) {
        // Error calling API (includes 404s as well as 500s)
        // separate "error in API" and "error calling API" if we can do so here
        _log.severe(e);
        await _handleResponseText(e.toString());
      }

      // indicate that we're done processing
      _processing = false;

    } catch (e) {
      // error processing image (or other)
      String err = 'Error processing image: $e';
      _log.severe(err);
      await _handleResponseText(err);
      _processing = false;
    }
  }

  /// replace ListView text with the response,
  /// and also send the response to Frame for display
  Future<void> _handleResponseText(String text) async {
    _responseTextList.clear();
    _pagination.clear();
    List<String> splitText = text.split('\n');

    // add to the ListView
    _responseTextList.addAll(splitText);

    // prepare for display on Frame (accommodating its line width)
    for (var line in splitText) {
      _pagination.appendLine(line);
    }

    // put the response on Frame's display
    await frame!.sendMessage(0x0a,
      TxPlainText(
        text: _pagination.getCurrentPage().join('\n')
      ).pack()
    );

    // redraw the UI
    setState(() {});

    // clear the display in 10s unless canceled
    _scheduleClearDisplay();
  }

  /// clear Frame's display after showing text for 10s (_clearTimer can be canceled)
  void _scheduleClearDisplay() {
    if (!_processing) {
      _clearTimer = Timer(const Duration(seconds: 10), () async {
        // clear Frame's display
        await frame!.sendMessage(0x0a,
          TxPlainText(
            text: ' '
          ).pack()
        );
      });
    }
  }

  /// Use the platform Share mechanism to share the image and the generated text
  static void _shareImage(Uint8List? jpegBytes, String text) async {
    if (jpegBytes != null) {
      try {
        // Share the image bytes as a JPEG file
        await Share.shareXFiles(
          [XFile.fromData(jpegBytes, mimeType: 'image/jpeg', name: 'image.jpg')],
          text: text,
        );
      }
      catch (e) {
        _log.severe('Error preparing image for sharing: $e');
      }
    }
  }

  @override
  Widget build(BuildContext context) {
    startForegroundService();
    return WithForegroundTask(
      child: MaterialApp(
        title: 'API - Frame Vision',
        theme: ThemeData.dark(),
        home: Scaffold(
          resizeToAvoidBottomInset: true,
          appBar: AppBar(
            title: const Text('API - Frame Vision'),
            actions: [getBatteryWidget()]
          ),
          drawer: getCameraDrawer(),
          body: Column(
            children: [
              Row(
                children: [
                  Expanded(child: TextField(
                    controller: _apiEndpointTextFieldController,
                    decoration: const InputDecoration(
                      hintText: 'E.g. http://192.168.0.5:8000/process'
                    ),
                  )),
                  ElevatedButton(onPressed: _saveApiEndpoint, child: const Text('Save'))
                ],
              ),
              Expanded(
              child: GestureDetector(
                onTap: () {
                  if (_imageData != null) {
                    _shareImage(_imageData, _responseTextList.join('\n'));
                  }
                },
                child: CustomScrollView(
                  slivers: [
                    SliverToBoxAdapter(
                      child: Padding(
                        padding: const EdgeInsets.symmetric(horizontal: 16),
                        child: _image,
                      ),
                    ),
                    if (_imageMeta != null)
                      SliverToBoxAdapter(
                        child: Padding(
                          padding: const EdgeInsets.symmetric(horizontal: 16),
                          child: Column(children: [
                            ImageMetadataWidget(meta: _imageMeta!),
                            const Divider()
                          ]),
                        ),
                      ),
                    SliverList(
                      delegate: SliverChildBuilderDelegate(
                        (context, index) {
                          return Padding(
                            padding: const EdgeInsets.symmetric(
                              horizontal: 16.0,
                            ),
                            child: Text(_responseTextList[index]),
                          );
                        },
                        childCount: _responseTextList.length,
                      ),
                    ),
                    // This ensures the list can grow dynamically
                    SliverFillRemaining(
                      hasScrollBody: false,
                      child: Container(), // Empty container to allow scrolling
                    ),
                  ],
                ),
              ),
            ),
            ],
          ),
          floatingActionButton: getFloatingActionButtonWidget(const Icon(Icons.camera_alt), const Icon(Icons.cancel)),
          persistentFooterButtons: getFooterButtonsWidget(),
        ),
      ),
    );
  }
}



----- Class: MainAppState -----
import 'dart:async';
import 'dart:typed_data';

import 'package:flutter/material.dart';
import 'package:flutter_foreground_task/flutter_foreground_task.dart';
import 'package:logging/logging.dart';
import 'package:share_plus/share_plus.dart';
import 'package:shared_preferences/shared_preferences.dart';
import 'package:simple_frame_app/frame_vision_app.dart';
import 'package:simple_frame_app/simple_frame_app.dart';
import 'package:frame_msg/tx/plain_text.dart';

import 'api_call.dart';
import 'foreground_service.dart';
import 'text_pagination.dart';

void main() {
  // Set up Android foreground service
  initializeForegroundService();

  runApp(const MainApp());
}

final _log = Logger("MainApp");

class MainApp extends StatefulWidget {
  const MainApp({super.key});

  @override
  MainAppState createState() => MainAppState();
}

/// FrameVisionAppState mixin provides scaffolding for photo capture on (multi-) tap and a mechanism for processing each photo
/// in addition to the connection and application state management provided by SimpleFrameAppState
class MainAppState extends State<MainApp> with SimpleFrameAppState, FrameVisionAppState {

  // Custom API state
  String _apiEndpoint = '';
  final TextEditingController _apiEndpointTextFieldController = TextEditingController();
  final TextEditingController _promptTextFieldController = TextEditingController();

  // the image and metadata to show
  Image? _image;
  Uint8List? _imageData;
  ImageMetadata? _imageMeta;
  bool _processing = false;

  // the response to show, and the timer to clear it after 10s
  Timer? _clearTimer;
  final List<String> _responseTextList = [];
  final TextPagination _pagination = TextPagination();

  MainAppState() {
    Logger.root.level = Level.INFO;
    Logger.root.onRecord.listen((record) {
      debugPrint('${record.level.name}: ${record.time}: ${record.message}');
    });
  }

  @override
  void dispose() {
    _apiEndpointTextFieldController.dispose();
    _promptTextFieldController.dispose();
    super.dispose();
  }

  @override
  void initState() {
    super.initState();

    // Frame connection and saved text field loading need to be performed asynchronously
    asyncInit();
  }

  Future<void> asyncInit() async {
    await _loadApiEndpoint();

    // kick off the connection to Frame and start the app if possible (unawaited)
    tryScanAndConnectAndStart(andRun: true);
  }

  Future<void> _loadApiEndpoint() async {
    final prefs = await SharedPreferences.getInstance();

    setState(() {
      _apiEndpoint = prefs.getString('api_endpoint') ?? '';
      _apiEndpointTextFieldController.text = _apiEndpoint;
    });
  }

  Future<void> _saveApiEndpoint() async {
    _apiEndpoint = _apiEndpointTextFieldController.text;
    final prefs = await SharedPreferences.getInstance();
    await prefs.setString('api_endpoint', _apiEndpoint);
  }

  @override
  Future<void> onRun() async {
    await frame!.sendMessage(0x0a,
      TxPlainText(
        text: '3-Tap: take photo\n______________\n1-Tap: next page\n2-Tap: previous page'
      ).pack()
    );
  }

  @override
  Future<void> onCancel() async {
    _responseTextList.clear();
    _pagination.clear();
  }

  @override
  Future<void> onTap(int taps) async {
    switch (taps) {
      // Next Page
      case 1:
        // Cancel any pending clear operations
        _clearTimer?.cancel();
        _clearTimer = null;

        // next
        _pagination.nextPage();
        await frame!.sendMessage(0x0a,
          TxPlainText(
            text: _pagination.getCurrentPage().join('\n')
          ).pack()
        );
        break;
      // Previous Page
      case 2:
        // Cancel any pending clear operations
        _clearTimer?.cancel();
        _clearTimer = null;

        // prev
        _pagination.previousPage();
        await frame!.sendMessage(0x0a,
          TxPlainText(
            text: _pagination.getCurrentPage().join('\n')
          ).pack()
        );
        break;
      // Take Photo
      case 3:
        // check if there's processing in progress already and drop the request if so
        if (!_processing) {
          _processing = true;
          // start new vision capture

          // Cancel any pending clear operations
          _clearTimer?.cancel();
          _clearTimer = null;

          // show we're capturing on the Frame display
          await frame!.sendMessage(0x0a,
            TxPlainText(
              text: '\u{F0007}', // starry eyes emoji
              paletteOffset: 8, // yellow
            ).pack()
          );

          // asynchronously kick off the capture/processing pipeline
          capture().then(process);
        }
        break;
      default:
    }
  }

  /// The vision pipeline to run when a photo is captured
  FutureOr<void> process((Uint8List, ImageMetadata) photo) async {
    var imageData = photo.$1;
    var meta = photo.$2;

    try {
      // update UI with image and empty the text list
      setState(() {
        _imageData = imageData;
        _image = Image.memory(imageData, gaplessPlayback: true,);
        _imageMeta = meta;
        _responseTextList.clear();
      });

      // Perform vision processing pipeline on the current image
      // Initialize the service with the current _apiEndpoint
      final apiService = ApiService(endpointUrl: _apiEndpoint);

      // show we're calling the API
      await frame!.sendMessage(0x0a,
        TxPlainText(
          text: '\u{F0003}', // 3d shades emoji
          x: 285,
          y: 1,
          paletteOffset: 8,
        ).pack()
      );

      try {
        // Make the API call
        final response = await apiService.processImage(
          imageBytes: imageData,
        );

        // Handle the response
        _log.fine(() => 'Received text: $response');

        // show in ListView and paginate for Frame
        _handleResponseText(response);

      } catch (e) {
        // Error calling API (includes 404s as well as 500s)
        // separate "error in API" and "error calling API" if we can do so here
        _log.severe(e);
        await _handleResponseText(e.toString());
      }

      // indicate that we're done processing
      _processing = false;

    } catch (e) {
      // error processing image (or other)
      String err = 'Error processing image: $e';
      _log.severe(err);
      await _handleResponseText(err);
      _processing = false;
    }
  }

  /// replace ListView text with the response,
  /// and also send the response to Frame for display
  Future<void> _handleResponseText(String text) async {
    _responseTextList.clear();
    _pagination.clear();
    List<String> splitText = text.split('\n');

    // add to the ListView
    _responseTextList.addAll(splitText);

    // prepare for display on Frame (accommodating its line width)
    for (var line in splitText) {
      _pagination.appendLine(line);
    }

    // put the response on Frame's display
    await frame!.sendMessage(0x0a,
      TxPlainText(
        text: _pagination.getCurrentPage().join('\n')
      ).pack()
    );

    // redraw the UI
    setState(() {});

    // clear the display in 10s unless canceled
    _scheduleClearDisplay();
  }

  /// clear Frame's display after showing text for 10s (_clearTimer can be canceled)
  void _scheduleClearDisplay() {
    if (!_processing) {
      _clearTimer = Timer(const Duration(seconds: 10), () async {
        // clear Frame's display
        await frame!.sendMessage(0x0a,
          TxPlainText(
            text: ' '
          ).pack()
        );
      });
    }
  }

  /// Use the platform Share mechanism to share the image and the generated text
  static void _shareImage(Uint8List? jpegBytes, String text) async {
    if (jpegBytes != null) {
      try {
        // Share the image bytes as a JPEG file
        await Share.shareXFiles(
          [XFile.fromData(jpegBytes, mimeType: 'image/jpeg', name: 'image.jpg')],
          text: text,
        );
      }
      catch (e) {
        _log.severe('Error preparing image for sharing: $e');
      }
    }
  }

  @override
  Widget build(BuildContext context) {
    startForegroundService();
    return WithForegroundTask(
      child: MaterialApp(
        title: 'API - Frame Vision',
        theme: ThemeData.dark(),
        home: Scaffold(
          resizeToAvoidBottomInset: true,
          appBar: AppBar(
            title: const Text('API - Frame Vision'),
            actions: [getBatteryWidget()]
          ),
          drawer: getCameraDrawer(),
          body: Column(
            children: [
              Row(
                children: [
                  Expanded(child: TextField(
                    controller: _apiEndpointTextFieldController,
                    decoration: const InputDecoration(
                      hintText: 'E.g. http://192.168.0.5:8000/process'
                    ),
                  )),
                  ElevatedButton(onPressed: _saveApiEndpoint, child: const Text('Save'))
                ],
              ),
              Expanded(
              child: GestureDetector(
                onTap: () {
                  if (_imageData != null) {
                    _shareImage(_imageData, _responseTextList.join('\n'));
                  }
                },
                child: CustomScrollView(
                  slivers: [
                    SliverToBoxAdapter(
                      child: Padding(
                        padding: const EdgeInsets.symmetric(horizontal: 16),
                        child: _image,
                      ),
                    ),
                    if (_imageMeta != null)
                      SliverToBoxAdapter(
                        child: Padding(
                          padding: const EdgeInsets.symmetric(horizontal: 16),
                          child: Column(children: [
                            ImageMetadataWidget(meta: _imageMeta!),
                            const Divider()
                          ]),
                        ),
                      ),
                    SliverList(
                      delegate: SliverChildBuilderDelegate(
                        (context, index) {
                          return Padding(
                            padding: const EdgeInsets.symmetric(
                              horizontal: 16.0,
                            ),
                            child: Text(_responseTextList[index]),
                          );
                        },
                        childCount: _responseTextList.length,
                      ),
                    ),
                    // This ensures the list can grow dynamically
                    SliverFillRemaining(
                      hasScrollBody: false,
                      child: Container(), // Empty container to allow scrolling
                    ),
                  ],
                ),
              ),
            ),
            ],
          ),
          floatingActionButton: getFloatingActionButtonWidget(const Icon(Icons.camera_alt), const Icon(Icons.cancel)),
          persistentFooterButtons: getFooterButtonsWidget(),
        ),
      ),
    );
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\frame_vision_api-main\lib\text_pagination.dart =====
----- Class: TextPagination -----
import 'dart:math';

import 'package:simple_frame_app/text_utils.dart';

class TextPagination {
  final List<String> _originalLines = [];
  final int displayLinesPerPage;

  // Cached wrapped lines for efficiency, split into immutable and mutable parts
  final List<String> _immutableWrappedLines = [];
  List<String> _mutableWrappedLines = [];
  int _currentPageIndex = 0;

  TextPagination({
    this.displayLinesPerPage = 5,
  });

  void updateLastLine(String newLastLine) {
    // Replace the last line in originalLines and recompute mutable wrapped lines
    if (_originalLines.isNotEmpty) {
      _originalLines[_originalLines.length - 1] = newLastLine;
      _mutableWrappedLines = TextUtils.wrapText(newLastLine, 640, 4);
    }
  }

  void appendLine(String newLine) {
    // If there are mutable wrapped lines, transition them to immutable
    if (_mutableWrappedLines.isNotEmpty) {
      _immutableWrappedLines.addAll(_mutableWrappedLines);
      _mutableWrappedLines.clear();
    }

    // Add a new line to the original lines
    _originalLines.add(newLine);

    // Set the new line as the mutable wrapped lines
    _mutableWrappedLines = TextUtils.wrapText(newLine, 640, 4);
  }

  List<String> getCurrentPage() {
    // Combine immutable and mutable wrapped lines
    final allWrappedLines = [..._immutableWrappedLines, ..._mutableWrappedLines];

    int startIndex = _currentPageIndex * displayLinesPerPage;
    return allWrappedLines.sublist(
      startIndex,
      min(startIndex + displayLinesPerPage, allWrappedLines.length)
    );
  }

  bool hasNextPage() {
    final allWrappedLines = [..._immutableWrappedLines, ..._mutableWrappedLines];
    return (_currentPageIndex + 1) * displayLinesPerPage < allWrappedLines.length;
  }

  bool hasPreviousPage() {
    return _currentPageIndex > 0;
  }

  void nextPage() {
    if (hasNextPage()) {
      _currentPageIndex++;
    }
  }

  void previousPage() {
    if (hasPreviousPage()) {
      _currentPageIndex--;
    }
  }

  void clear() {
    // Reset all content to initial state
    _originalLines.clear();
    _immutableWrappedLines.clear();
    _mutableWrappedLines.clear();
    _currentPageIndex = 0;
  }

  int get totalPages {
    final allWrappedLines = [..._immutableWrappedLines, ..._mutableWrappedLines];
    return (allWrappedLines.length / displayLinesPerPage).ceil();
  }

  int get currentPageNumber => _currentPageIndex + 1;
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\models\app_logic_model.dart =====
----- Class: AppLogicModel -----
import 'dart:async';
import 'dart:convert';
import 'package:collection/collection.dart';
import 'package:flutter/services.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/foundation.dart';
import 'package:logging/logging.dart';
import 'package:noa/bluetooth.dart';
import 'package:noa/noa_api.dart';
import 'package:noa/util/state_machine.dart';
import 'package:shared_preferences/shared_preferences.dart';

final _log = Logger("App logic");

// NOTE Update these when changing firmware or scripts
const _firmwareVersion = "v25.080.0838";
const _scriptVersion = "v1.0.5";

enum State {
  getUserSettings,
  waitForLogin,
  scanning,
  found,
  connect,
  stopLuaApp,
  checkFirmwareVersion,
  uploadMainLua,
  uploadGraphicsLua,
  uploadStateLua,
  triggerUpdate,
  updateFirmware,
  requiresRepair,
  connected,
  disconnected,
  recheckFirmwareVersion,
  checkScriptVersion,
  sendResponseToDevice,
  logout,
  deleteAccount
}

enum Event {
  init,
  done,
  error,
  loggedIn,
  deviceFound,
  deviceLost,
  deviceConnected,
  updatableDeviceConnected,
  deviceDisconnected,
  deviceInvalid,
  buttonPressed,
  cancelPressed,
  logoutPressed,
  deletePressed,
  deviceUpToDate,
  deviceNeedsUpdate,
  noaResponse,
}

enum TuneLength {
  shortest('shortest'),
  short('short'),
  standard('standard'),
  long('long'),
  longest('longest');

  const TuneLength(this.value);
  final String value;
}

class AppLogicModel extends ChangeNotifier {
  // Public state variables
  StateMachine state = StateMachine(State.getUserSettings);
  NoaUser noaUser = NoaUser();
  double bluetoothUploadProgress = 0;
  String deviceName = "Device";
  List<NoaMessage> noaMessages = List.empty(growable: true);

  void setUserAuthToken(String token) {
    SharedPreferences.getInstance().then((value) async {
      await value.setString("userAuthToken", token);
      triggerEvent(Event.loggedIn);
    });
  }

  Future<String?> _getUserAuthToken() async {
    return await SharedPreferences.getInstance()
        .then((value) => value.getString('userAuthToken'));
  }

  void _setPairedDevice(String token) {
    SharedPreferences.getInstance().then((value) async {
      await value.setString("PairedDevice", token);
      triggerEvent(Event.loggedIn);
    });
  }

  Future<String?> _getPairedDevice() async {
    return await SharedPreferences.getInstance()
        .then((value) => value.getString('PairedDevice'));
  }

  // User's tune preferences
  String _tunePrompt = "";
  String get tunePrompt => _tunePrompt;
  set tunePrompt(String value) {
    _tunePrompt = value;
    () async {
      final savedData = await SharedPreferences.getInstance();
      savedData.setString("tunePrompt", _tunePrompt);
    }();
  }

  int _tuneTemperature = 50;
  int get tuneTemperature => _tuneTemperature;
  set tuneTemperature(int value) {
    _tuneTemperature = value;
    () async {
      final savedData = await SharedPreferences.getInstance();
      savedData.setInt("tuneTemperature", _tuneTemperature);
    }();
    notifyListeners();
  }

  bool _customServer = false;
  bool get customServer => _customServer;
  set customServer(bool value) {
    _customServer = value;
    SharedPreferences.getInstance()
        .then((sp) => sp.setBool("customServer", value));
    notifyListeners();
  }

  String _apiEndpoint = "";
  String get apiEndpoint => _apiEndpoint;
  set apiEndpoint(String value) {
    _apiEndpoint = value;
    SharedPreferences.getInstance()
        .then((sp) => sp.setString("apiEndpoint", value));
    notifyListeners();
  }

  String _apiToken = "";
  String get apiToken => _apiToken;
  set apiToken(String value) {
    _apiToken = value;
    SharedPreferences.getInstance()
        .then((sp) => sp.setString("apiToken", value));
    notifyListeners();
  }

  String _apiHeader = "";
  String get apiHeader => _apiHeader;
  set apiHeader(String value) {
    _apiHeader = value;
    SharedPreferences.getInstance()
        .then((sp) => sp.setString("apiHeader", value));
    notifyListeners();
  }

  TuneLength _tuneLength = TuneLength.standard;
  TuneLength get tuneLength => _tuneLength;
  set tuneLength(TuneLength value) {
    _tuneLength = value;
    () async {
      final savedData = await SharedPreferences.getInstance();
      savedData.setString("tuneLength", _tuneLength.name);
    }();
    notifyListeners();
  }

  late bool _textToSpeech;
  bool get textToSpeech => _textToSpeech;
  set textToSpeech(bool value) {
    _textToSpeech = value;
    SharedPreferences.getInstance()
        .then((sp) => sp.setBool("textToSpeech", value));
    notifyListeners();
  }

  late bool _promptless;
  bool get promptless => _promptless;
  set promptless(bool value) {
    _promptless = value;
    SharedPreferences.getInstance()
        .then((sp) => sp.setBool("promptless", value));
    notifyListeners();
  }

  // Private state variables
  StreamSubscription? _scanStream;
  StreamSubscription? _connectionStream;
  StreamSubscription? _luaResponseStream;
  StreamSubscription? _dataResponseStream;
  BrilliantScannedDevice? _nearbyDevice;
  BrilliantDevice? _connectedDevice;
  List<int> _audioData = List.empty(growable: true);
  List<int> _imageData = List.empty(growable: true);

  AppLogicModel() {
    // Uncomment to create AppStore images
    // noaMessages.add(NoaMessage(
    //   message: "Recommend me some pizza places I near Union Square",
    //   from: NoaRole.user,
    //   time: DateTime.now().add(const Duration(seconds: 2)),
    // ));

    // noaMessages.add(NoaMessage(
    //   message:
    //       "You might want to check out Bravo Pizza, Union Square Pizza, or Joe's Pizza for some good pizza near Union Square.",
    //   from: NoaRole.noa,
    //   time: DateTime.now().add(const Duration(seconds: 3)),
    // ));

    // noaMessages.add(NoaMessage(
    //   message: "Does Joe's have any good vegetarian options?",
    //   from: NoaRole.user,
    //   time: DateTime.now().add(const Duration(seconds: 4)),
    // ));

    // noaMessages.add(NoaMessage(
    //   message:
    //       "Joe's Pizza does offer vegetarian options, including a cheese-less veggie pie that's quite popular.",
    //   from: NoaRole.noa,
    //   time: DateTime.now().add(const Duration(seconds: 5)),
    // ));

    () async {
      noaMessages.add(NoaMessage(
        message: "Hey I'm Noa! Let's show you around",
        from: NoaRole.noa,
        time: DateTime.now(),
        exclude: true,
      ));

      noaMessages.add(NoaMessage(
          message: "Tap the side of your Frame to wake me up",
          from: NoaRole.noa,
          time: DateTime.now(),
          image: (await rootBundle.load('assets/images/tutorial/wake_up.png'))
              .buffer
              .asUint8List(),
          exclude: true));

      noaMessages.add(NoaMessage(
          message: "Tap again and ask me anything",
          from: NoaRole.noa,
          time: DateTime.now(),
          image: (await rootBundle.load('assets/images/tutorial/tap_start.png'))
              .buffer
              .asUint8List(),
          exclude: true));

      noaMessages.add(NoaMessage(
          message: "...and then a third time to finish",
          from: NoaRole.noa,
          time: DateTime.now(),
          image:
              (await rootBundle.load('assets/images/tutorial/tap_finish.png'))
                  .buffer
                  .asUint8List(),
          exclude: true));

      noaMessages.add(NoaMessage(
          message:
              "The response just takes a few seconds. Tap again to ask a follow up question",
          from: NoaRole.noa,
          time: DateTime.now(),
          image: (await rootBundle
                  .load('assets/images/tutorial/tap_follow_up.png'))
              .buffer
              .asUint8List(),
          exclude: true));

      noaMessages.add(NoaMessage(
          message: "The follow up just takes a few more seconds",
          from: NoaRole.noa,
          time: DateTime.now(),
          image: (await rootBundle.load('assets/images/tutorial/response.png'))
              .buffer
              .asUint8List(),
          exclude: true));
    }();
  }

  void triggerEvent(Event event) {
    state.event(event);

    do {
      switch (state.current) {
        case State.getUserSettings:
          state.onEntry(() async {
            try {
              // Load the user's Tune settings or defaults if none are set
              final savedData = await SharedPreferences.getInstance();
              _tunePrompt = savedData.getString('tunePrompt') ??
                  "You are Noa, a smart and witty personal AI assistant inside the user's AR smart glasses that answers all user queries and questions";
              _tuneTemperature = savedData.getInt('tuneTemperature') ?? 50;
              var len = savedData.getString('tuneLength') ?? 'standard';
              _tuneLength = TuneLength.values
                  .firstWhere((e) => e.toString() == 'TuneLength.$len');
              _textToSpeech = savedData.getBool('textToSpeech') ?? true;
              _apiEndpoint = savedData.getString('apiEndpoint') ?? "";
              _apiToken = savedData.getString('apiToken') ?? "";
              _apiHeader = savedData.getString('apiHeader') ?? "";
              _customServer = savedData.getBool('customServer') ?? false;
              _promptless = savedData.getBool('promptless') ?? false;

              // Check if the auto token is loaded and if Frame is paired
              if (await _getUserAuthToken() != null &&
                  await _getPairedDevice() != null) {
                noaUser = await NoaApi.getUser((await _getUserAuthToken())!);
                triggerEvent(Event.done);
                return;
              }
              throw ("Not logged in or paired");
            } catch (error) {
              _log.info(error);
              triggerEvent(Event.error);
            }
          });
          state.changeOn(Event.done, State.disconnected);
          state.changeOn(Event.error, State.waitForLogin);
          break;

        case State.waitForLogin:
          state.changeOn(Event.loggedIn, State.scanning,
              transitionTask: () async =>
                  noaUser = await NoaApi.getUser((await _getUserAuthToken())!));
          break;

        case State.scanning:
          state.onEntry(() async {
            await _scanStream?.cancel();
            _scanStream = BrilliantBluetooth.scan()
                .timeout(const Duration(seconds: 2), onTimeout: (sink) {
              _nearbyDevice = null;
              triggerEvent(Event.deviceLost);
            }).listen((device) {
              _nearbyDevice = device;
              deviceName = device.device.advName;
              triggerEvent(Event.deviceFound);
            });
          });
          state.changeOn(Event.deviceFound, State.found);
          state.changeOn(Event.cancelPressed, State.disconnected,
              transitionTask: () async => await BrilliantBluetooth.stopScan());
          break;

        case State.found:
          state.changeOn(Event.deviceLost, State.scanning);
          state.changeOn(Event.buttonPressed, State.connect);
          state.changeOn(Event.cancelPressed, State.disconnected,
              transitionTask: () async => await BrilliantBluetooth.stopScan());
          break;

        case State.connect:
          state.onEntry(() async {
            try {
              _connectedDevice =
                  await BrilliantBluetooth.connect(_nearbyDevice!);
              switch (_connectedDevice!.state) {
                case BrilliantConnectionState.connected:
                  triggerEvent(Event.deviceConnected);
                  break;
                case BrilliantConnectionState.dfuConnected:
                  triggerEvent(Event.updatableDeviceConnected);
                  break;
                default:
                  throw ();
              }
            } catch (_) {
              triggerEvent(Event.deviceInvalid);
            }
          });
          state.changeOn(Event.deviceConnected, State.stopLuaApp);
          state.changeOn(Event.updatableDeviceConnected, State.updateFirmware);
          state.changeOn(Event.deviceInvalid, State.requiresRepair);
          break;

        case State.stopLuaApp:
          state.onEntry(() async {
            try {
              await _connectedDevice!.sendBreakSignal();
              triggerEvent(Event.done);
            } catch (_) {
              triggerEvent(Event.error);
            }
          });
          state.changeOn(Event.done, State.checkFirmwareVersion);
          state.changeOn(Event.error, State.requiresRepair);
          break;

        case State.checkFirmwareVersion:
          state.onEntry(() async {
            try {
              final response = await _connectedDevice!
                  .sendString("print(frame.FIRMWARE_VERSION)")
                  .timeout(const Duration(seconds: 1));
              if (response == _firmwareVersion) {
                triggerEvent(Event.deviceUpToDate);
              } else {
                triggerEvent(Event.deviceNeedsUpdate);
              }
            } catch (_) {
              triggerEvent(Event.error);
            }
          });
          state.changeOn(Event.deviceUpToDate, State.uploadMainLua);
          state.changeOn(Event.deviceNeedsUpdate, State.triggerUpdate);
          state.changeOn(Event.error, State.requiresRepair);
          break;

        case State.uploadMainLua:
          state.onEntry(() async {
            try {
              await _connectedDevice!.uploadScript(
                'main.lua',
                'assets/lua_scripts/main.lua',
              );
              triggerEvent(Event.done);
            } catch (_) {
              triggerEvent(Event.error);
            }
          });

          state.changeOn(Event.done, State.uploadGraphicsLua);
          state.changeOn(Event.error, State.requiresRepair);
          break;

        case State.uploadGraphicsLua:
          state.onEntry(() async {
            try {
              await _connectedDevice!.uploadScript(
                'graphics.lua',
                'assets/lua_scripts/graphics.lua',
              );
              triggerEvent(Event.done);
            } catch (_) {
              triggerEvent(Event.error);
            }
          });

          state.changeOn(Event.done, State.uploadStateLua);
          state.changeOn(Event.error, State.requiresRepair);
          break;

        case State.uploadStateLua:
          state.onEntry(() async {
            try {
              await _connectedDevice!.uploadScript(
                'state.lua',
                'assets/lua_scripts/state.lua',
              );
              await _connectedDevice!.sendResetSignal();
              _setPairedDevice(_connectedDevice!.device.remoteId.toString());
              triggerEvent(Event.done);
            } catch (_) {
              triggerEvent(Event.error);
            }
          });

          state.changeOn(Event.done, State.connected);
          state.changeOn(Event.error, State.requiresRepair);
          break;

        case State.triggerUpdate:
          state.onEntry(() async {
            try {
              await _connectedDevice!.sendString(
                "frame.update()",
                awaitResponse: false,
              );
            } catch (_) {
              triggerEvent(Event.error);
            }
            await _scanStream?.cancel();
            _scanStream = BrilliantBluetooth.scan().listen((device) {
              _nearbyDevice = device;
              triggerEvent(Event.deviceFound);
            });
          });
          state.changeOn(Event.deviceFound, State.connect,
              transitionTask: () async => await BrilliantBluetooth.stopScan());
          state.changeOn(Event.error, State.requiresRepair);
          break;

        case State.updateFirmware:
          state.onEntry(() async {
            _connectedDevice!
                .updateFirmware("assets/frame-firmware-$_firmwareVersion.zip")
                .listen(
              (value) {
                bluetoothUploadProgress = value;
                notifyListeners();
              },
              onDone: () async {
                try {
                  await _scanStream?.cancel();
                  _scanStream = BrilliantBluetooth.scan().listen((device) {
                    _nearbyDevice = device;
                    triggerEvent(Event.deviceFound);
                  });
                } catch (error) {
                  triggerEvent(Event.error);
                }
              },
              onError: (_) async {
                await _connectedDevice?.disconnect();
                triggerEvent(Event.error);
              },
              cancelOnError: true,
            );
          });
          state.changeOn(Event.deviceFound, State.connect);
          state.changeOn(Event.error, State.requiresRepair);
          break;

        case State.requiresRepair:
          state.changeOn(Event.buttonPressed, State.scanning);
          state.changeOn(Event.cancelPressed, State.disconnected);
          break;

        case State.connected:
          state.onEntry(() async {
            _connectionStream?.cancel();
            _connectionStream =
                _connectedDevice!.connectionState.listen((event) {
              _connectedDevice = event;
              if (event.state == BrilliantConnectionState.disconnected) {
                triggerEvent(Event.deviceDisconnected);
              }
            });
            _connectionStream?.onError((_) {});

            _luaResponseStream?.cancel();
            _luaResponseStream =
                _connectedDevice!.stringResponse.listen((event) {});

            _dataResponseStream?.cancel();
            _dataResponseStream =
                _connectedDevice!.dataResponse.listen((event) async {
              String getTunePrompt() {
                String prompt = "";
                if (_tunePrompt != "") {
                  prompt += "$_tunePrompt. ";
                }

                switch (_tuneLength) {
                  case TuneLength.shortest:
                    prompt += "Limit responses to 1 to 3 words. ";
                    break;
                  case TuneLength.short:
                    prompt += "Limit responses to 1 sentence. ";
                    break;
                  case TuneLength.standard:
                    prompt += "Limit responses to 1 to 2 sentences. ";
                    break;
                  case TuneLength.long:
                    prompt += "Limit responses to 1 short paragraph. ";
                    break;
                  case TuneLength.longest:
                    prompt += "Limit responses to 2 paragraphs. ";
                    break;
                }
                return prompt;
              }

              switch (event[0]) {
                case 0x10:
                  _log.info("Received user generation request from device");
                  _audioData.clear();
                  _imageData.clear();
                  break;
                case 0x12:
                  _log.info("Received wildcard request from device");
                  try {
                    noaMessages += await NoaApi.getWildcardMessage(
                      (await _getUserAuthToken())!,
                      getTunePrompt(),
                      _tuneTemperature / 50,
                      textToSpeech,
                    );
                    noaUser =
                        await NoaApi.getUser((await _getUserAuthToken())!);
                    triggerEvent(Event.noaResponse);
                  } catch (_) {}
                  break;
                case 0x13:
                  _audioData += event.sublist(1);
                  break;
                case 0x14:
                  _imageData += event.sublist(1);
                  break;
                case 0x15:
                  _log.info(
                      "Received all data from device. ${_audioData.length} bytes of audio, ${_imageData.length} bytes of image");
                  try {
                    final newMessages = await NoaApi.getMessage(
                        (await _getUserAuthToken())!,
                        Uint8List.fromList(_audioData),
                        Uint8List.fromList(_imageData),
                        getTunePrompt(),
                        _tuneTemperature / 50,
                        noaMessages,
                        textToSpeech,
                        apiEndpoint,
                        apiHeader,
                        apiToken,
                        customServer,
                        promptless);
                    final topicChanged =
                        newMessages.where((msg) => msg.topicChanged).isNotEmpty;
                    if (topicChanged) {
                      for (var msg in noaMessages) {
                        msg.exclude = true;
                      }
                    }
                    noaMessages += newMessages;
                    noaUser =
                        await NoaApi.getUser((await _getUserAuthToken())!);
                    triggerEvent(Event.noaResponse);
                  } catch (_) {}
                  break;
              }
            });
          });

          state.changeOn(Event.noaResponse, State.sendResponseToDevice);
          state.changeOn(Event.deviceDisconnected, State.disconnected);
          state.changeOn(Event.logoutPressed, State.logout);
          state.changeOn(Event.deletePressed, State.deleteAccount);
          break;

        case State.sendResponseToDevice:
          state.onEntry(() async {
            try {
              final splitString = utf8
                  .encode(noaMessages.last.message)
                  .slices(_connectedDevice!.maxDataLength! - 1);
              for (var slice in splitString) {
                List<int> data = slice.toList()..insert(0, 0x20);
                await _connectedDevice!
                    .sendData(data)
                    .timeout(const Duration(seconds: 1));
                await Future.delayed(const Duration(milliseconds: 50));
              }
              await Future.delayed(const Duration(milliseconds: 300));
            } catch (_) {}
            triggerEvent(Event.done);
          });

          state.changeOn(Event.done, State.connected);
          state.changeOn(Event.logoutPressed, State.logout);
          state.changeOn(Event.deletePressed, State.deleteAccount);
          break;

        case State.disconnected:
          state.onEntry(() async {
            _connectionStream?.cancel();
            _connectionStream =
                _connectedDevice?.connectionState.listen((event) {
              _connectedDevice = event;
              if (event.state == BrilliantConnectionState.connected) {
                triggerEvent(Event.deviceConnected);
              }
            });
            _connectionStream?.onError((_) {});

            try {
              _connectedDevice ??= await BrilliantBluetooth.reconnect(
                  (await _getPairedDevice())!);
              if (_connectedDevice?.state ==
                  BrilliantConnectionState.connected) {
                triggerEvent(Event.deviceConnected);
              }
            } catch (_) {}
          });
          state.changeOn(Event.deviceConnected, State.recheckFirmwareVersion);
          state.changeOn(Event.logoutPressed, State.logout);
          state.changeOn(Event.deletePressed, State.deleteAccount);
          break;

        case State.recheckFirmwareVersion:
          state.onEntry(() async {
            _dataResponseStream?.cancel();
            _dataResponseStream =
                _connectedDevice!.dataResponse.listen((event) async {
              _log.info("Firmware version: ${utf8.decode(event.sublist(1))}");
              if (utf8.decode(event.sublist(1)) == _firmwareVersion) {
                triggerEvent(Event.deviceUpToDate);
              } else {
                triggerEvent(Event.deviceNeedsUpdate);
              }
            });
            try {
              await _connectedDevice!
                  .sendData(List<int>.filled(1, 0x16))
                  .timeout(const Duration(seconds: 1));
            } catch (_) {
              triggerEvent(Event.error);
            }
          });
          state.changeOn(Event.deviceUpToDate, State.checkScriptVersion);
          state.changeOn(Event.deviceNeedsUpdate, State.stopLuaApp);
          state.changeOn(Event.error, State.stopLuaApp);
          state.changeOn(Event.logoutPressed, State.logout);
          break;

        case State.checkScriptVersion:
          state.onEntry(() async {
            _dataResponseStream?.cancel();
            _dataResponseStream =
                _connectedDevice!.dataResponse.listen((event) async {
              _log.info("Script version: ${utf8.decode(event.sublist(1))}");
              if (utf8.decode(event.sublist(1)) == _scriptVersion) {
                triggerEvent(Event.deviceUpToDate);
              } else {
                triggerEvent(Event.deviceNeedsUpdate);
              }
            });
            try {
              await _connectedDevice!
                  .sendData(List<int>.filled(1, 0x17))
                  .timeout(const Duration(seconds: 1));
            } catch (_) {
              triggerEvent(Event.error);
            }
          });
          state.changeOn(Event.deviceUpToDate, State.connected);
          state.changeOn(Event.deviceNeedsUpdate, State.stopLuaApp);
          state.changeOn(Event.error, State.stopLuaApp);
          state.changeOn(Event.logoutPressed, State.logout);
          break;

        case State.logout:
          state.onEntry(() async {
            try {
              await SharedPreferences.getInstance().then((sp) => sp.clear());
              await _connectedDevice?.disconnect();
              await NoaApi.signOut((await _getUserAuthToken())!);
              noaMessages.clear();
              triggerEvent(Event.done);
            } catch (error) {
              _log.warning("Error logging out. $error");
              triggerEvent(Event.done);
            }
          });
          state.changeOn(Event.done, State.getUserSettings);
          break;

        case State.deleteAccount:
          state.onEntry(() async {
            try {
              await _connectedDevice?.disconnect();
              await NoaApi.deleteUser((await _getUserAuthToken())!);
              await SharedPreferences.getInstance().then((sp) => sp.clear());
              noaMessages.clear();
              triggerEvent(Event.done);
            } catch (error) {
              _log.warning("Error deleting account. $error");
              triggerEvent(Event.done);
            }
          });
          state.changeOn(Event.done, State.getUserSettings);
          break;
      }
    } while (state.changePending());

    notifyListeners();
  }

  @override
  void dispose() {
    BrilliantBluetooth.stopScan();
    super.dispose();
  }
}

final model = ChangeNotifierProvider<AppLogicModel>((ref) {
  return AppLogicModel();
});





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\account.dart =====
----- Class: AccountPage -----
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:noa/models/app_logic_model.dart' as app;
import 'package:noa/pages/regulatory.dart';
import 'package:noa/pages/splash.dart';
import 'package:noa/style.dart';
import 'package:noa/util/switch_page.dart';
import 'package:noa/widgets/top_title_bar.dart';
import 'package:url_launcher/url_launcher.dart';

Widget _accountInfoText(String title, String detail) {
  return Padding(
    padding: const EdgeInsets.only(bottom: 42),
    child: Column(
      children: [
        Text(title, style: textStyleLightSubHeading),
        Text(detail, style: textStyleDarkTitle),
      ],
    ),
  );
}

Widget _linkedFooterText(String text, bool redText, Function action) {
  return Padding(
    padding: const EdgeInsets.only(top: 8),
    child: GestureDetector(
      onTap: () => action(),
      child: Text(
        text,
        style: redText ? textStyleRed : textStyleDark,
      ),
    ),
  );
}

class AccountPage extends ConsumerWidget {
  const AccountPage({super.key});

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    return Scaffold(
      backgroundColor: colorWhite,
      appBar: topTitleBar(context, 'ACCOUNT', false, true),
      body: Column(
        children: [
          Center(
            child: Column(
              children: [
                _accountInfoText(
                    "Signed In As", ref.watch(app.model).noaUser.email),
                _accountInfoText("Credits Used",
                    "${ref.watch(app.model).noaUser.creditsUsed} / ${ref.watch(app.model).noaUser.maxCredits}"),
                _accountInfoText("Plan", ref.watch(app.model).noaUser.plan)
              ],
            ),
          ),
          Expanded(
            child: Padding(
              padding: const EdgeInsets.only(left: 42, bottom: 50),
              child: Column(
                mainAxisAlignment: MainAxisAlignment.end,
                crossAxisAlignment: CrossAxisAlignment.stretch,
                children: [
                  _linkedFooterText("Tutorials", false, () async {
                    try {
                      await launchUrl(Uri.parse(
                          "https://www.youtube.com/playlist?list=PLfbaC5GRVJJgSPdN-KWndTld35tihu1Ic"));
                    } catch (_) {}
                  }),
                  _linkedFooterText("Logout", false, () async {
                    ref.read(app.model).triggerEvent(app.Event.logoutPressed);
                    if (context.mounted) {
                      Navigator.pop(context);
                      switchPage(context, const SplashPage());
                    }
                  }),
                  _linkedFooterText("Privacy Policy", false, () async {
                    try {
                      await launchUrl(Uri.parse(
                          "https://brilliant.xyz/pages/privacy-policy"));
                    } catch (_) {}
                  }),
                  _linkedFooterText("Terms & Conditions", false, () async {
                    try {
                      await launchUrl(Uri.parse(
                          "https://brilliant.xyz/pages/terms-conditions"));
                    } catch (_) {}
                  }),
                  _linkedFooterText("Regulatory", false, () async {
                    switchPage(context, const RegulatoryPage());
                  }),
                  _linkedFooterText("Delete Account", true, () {
                    // TODO ask user to confirm
                    ref.read(app.model).triggerEvent(app.Event.deletePressed);
                    if (context.mounted) {
                      Navigator.pop(context);
                      switchPage(context, const SplashPage());
                    }
                  }),
                ],
              ),
            ),
          ),
        ],
      ),
    );
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\hack.dart =====
----- Class: HackPage -----
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:flutter/services.dart';
import 'package:noa/style.dart';
import 'package:noa/util/app_log.dart';
import 'package:noa/util/show_toast.dart';
import 'package:noa/widgets/bottom_nav_bar.dart';
import 'package:noa/widgets/top_title_bar.dart';

final ScrollController _bluetoothLogScrollController = ScrollController();
final ScrollController _appLogScrollController = ScrollController();

Widget _logTextBox(
  BuildContext context,
  String data,
  ScrollController controller,
) {
  return Expanded(
    child: GestureDetector(
      onLongPress: () async {
        await Clipboard.setData(ClipboardData(text: data));
        if (context.mounted) {
          showToast("Copied", context);
        }
      },
      child: Container(
        decoration: BoxDecoration(
          border: Border.all(color: colorLight),
          borderRadius: const BorderRadius.all(Radius.circular(10)),
        ),
        padding: const EdgeInsets.all(10),
        margin: const EdgeInsets.only(bottom: 28),
        width: double.infinity,
        child: SingleChildScrollView(
          controller: controller,
          scrollDirection: Axis.vertical,
          reverse: true,
          child: SingleChildScrollView(
            scrollDirection: Axis.horizontal,
            child: Text(
              data,
              style: textStyleLight,
            ),
          ),
        ),
      ),
    ),
  );
}

class HackPage extends ConsumerWidget {
  const HackPage({super.key});

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      _bluetoothLogScrollController.animateTo(
          _bluetoothLogScrollController.position.minScrollExtent,
          duration: const Duration(milliseconds: 100),
          curve: Curves.easeOut);
      _appLogScrollController.animateTo(
          _appLogScrollController.position.minScrollExtent,
          duration: const Duration(milliseconds: 100),
          curve: Curves.easeOut);
    });

    return Scaffold(
      backgroundColor: colorDark,
      appBar: topTitleBar(context, 'LOG', true, false),
      body: Padding(
        padding: const EdgeInsets.only(left: 42, right: 42),
        child: Column(
          crossAxisAlignment: CrossAxisAlignment.start,
          children: [
            const Padding(
              padding: EdgeInsets.only(bottom: 10),
              child: Text("Bluetooth log", style: textStyleLightSubHeading),
            ),
            _logTextBox(
              context,
              ref.watch(appLog).bluetooth,
              _bluetoothLogScrollController,
            ),
            const Padding(
              padding: EdgeInsets.only(bottom: 10),
              child: Text("App log", style: textStyleLightSubHeading),
            ),
            _logTextBox(
              context,
              ref.watch(appLog).app,
              _appLogScrollController,
            ),
          ],
        ),
      ),
      bottomNavigationBar: bottomNavBar(context, 2, true),
    );
  }
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\login.dart =====
----- Class: LoginPage -----
import 'dart:io';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/gestures.dart';
import 'package:flutter/material.dart';
import 'package:noa/models/app_logic_model.dart' as app;
import 'package:noa/noa_api.dart';
import 'package:noa/pages/pairing.dart';
import 'package:noa/style.dart';
import 'package:noa/util/alert_dialog.dart';
import 'package:noa/util/location.dart';
import 'package:noa/util/sign_in.dart';
import 'package:noa/util/switch_page.dart';
import 'package:url_launcher/url_launcher.dart';
import 'package:webview_flutter/webview_flutter.dart';

TextSpan _clickableLink({required String text, required String url}) {
  return TextSpan(
    text: text,
    style: textStylePink,
    recognizer: TapGestureRecognizer()
      ..onTap = () async {
        try {
          await launchUrl(Uri.parse(url));
        } catch (_) {}
      },
  );
}

Widget _loginButton(
  BuildContext context,
  WidgetRef ref,
  String image,
  Function action,
) {
  return GestureDetector(
    onTap: () async {
      try {
        await InternetAddress.lookup('www.google.com');
        ref.read(app.model).setUserAuthToken(await action());
      } on SocketException catch (_) {
        if (context.mounted) {
          alertDialog(
            context,
            "Couldn't Sign In",
            "Noa requires an internet connection",
          );
        }
      } on NoaApiServerException catch (error) {
        if (context.mounted) {
          alertDialog(
            context,
            "Couldn't Sign In",
            "Server responded with an error: $error",
          );
        }
      } catch (_) {}
    },
    child: Padding(
      padding: const EdgeInsets.only(bottom: 20),
      child: Image.asset(image),
    ),
  );
}

class LoginPage extends ConsumerStatefulWidget {
  const LoginPage({super.key});

  @override
  ConsumerState<LoginPage> createState() => _LoginPageState();
}

class _LoginPageState extends ConsumerState<LoginPage> {
  late bool showWebview;

  @override
  void initState() {
    showWebview = false;
    super.initState();
  }

  @override
  Widget build(BuildContext context) {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      Location.requestPermission(context);
      if (ref.watch(app.model).state.current != app.State.waitForLogin) {
        switchPage(context, const PairingPage());
      }
    });

    return Scaffold(
      backgroundColor: colorDark,
      appBar: AppBar(
        backgroundColor: colorDark,
        title: Image.asset('assets/images/brilliant_logo.png'),
        centerTitle: true,
      ),
      body: Stack(
        children: [
          Column(
            children: [
              Expanded(child: Image.asset('assets/images/noa_logo.png')),
              Column(
                children: [
                  if (Platform.isIOS)
                    _loginButton(
                      context,
                      ref,
                      'assets/images/sign_in_with_apple_button.png',
                      SignIn().withApple,
                    ),
                  if (Platform.isIOS)
                    _loginButton(
                      context,
                      ref,
                      'assets/images/sign_in_with_google_button.png',
                      SignIn().withGoogle,
                    ),
                  GestureDetector(
                    onTap: () async {
                      try {
                        await InternetAddress.lookup('www.google.com');
                        setState(() => showWebview = true);
                      } on SocketException catch (_) {
                        if (context.mounted) {
                          alertDialog(
                            context,
                            "Couldn't Sign In",
                            "Noa requires an internet connection",
                          );
                        }
                      }
                    },
                    child: Padding(
                      padding: const EdgeInsets.only(bottom: 20),
                      child: Image.asset(
                          'assets/images/sign_in_with_email_button.png'),
                    ),
                  )
                ],
              )
            ],
          ),
          if (showWebview)
            Container(
              padding: const EdgeInsets.all(50),
              color: const Color(0xA0292929),
              child: Container(
                decoration: BoxDecoration(
                  border: Border.all(color: colorWhite, width: 2),
                ),
                child: WebViewWidget(
                  controller: WebViewController()
                    ..loadRequest(
                        Uri.parse("https://api.brilliant.xyz/noa/login?app=1"))
                    ..setJavaScriptMode(JavaScriptMode.unrestricted)
                    ..addJavaScriptChannel("userAuthToken",
                        onMessageReceived: (message) {
                      if (message.message == "cancelled") {
                        setState(() {
                          showWebview = false;
                        });
                      } else if (message.message != "") {
                        ref.read(app.model).setUserAuthToken(message.message);
                      }
                    }),
                ),
              ),
            )
        ],
      ),
      bottomNavigationBar: Padding(
        padding: const EdgeInsets.only(bottom: 48, top: 48),
        child: RichText(
          textAlign: TextAlign.center,
          text: TextSpan(
            children: <TextSpan>[
              const TextSpan(text: ''),
              _clickableLink(
                text: 'Privacy Policy',
                url: 'https://brilliant.xyz/pages/privacy-policy',
              ),
              const TextSpan(text: ' and ', style: textStyleWhite),
              _clickableLink(
                text: 'Terms and Conditions',
                url: 'https://brilliant.xyz/pages/terms-conditions',
              ),
              const TextSpan(text: ' of Noa.', style: textStyleWhite),
            ],
          ),
        ),
      ),
    );
  }
}



----- Class: _LoginPageState -----
import 'dart:io';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/gestures.dart';
import 'package:flutter/material.dart';
import 'package:noa/models/app_logic_model.dart' as app;
import 'package:noa/noa_api.dart';
import 'package:noa/pages/pairing.dart';
import 'package:noa/style.dart';
import 'package:noa/util/alert_dialog.dart';
import 'package:noa/util/location.dart';
import 'package:noa/util/sign_in.dart';
import 'package:noa/util/switch_page.dart';
import 'package:url_launcher/url_launcher.dart';
import 'package:webview_flutter/webview_flutter.dart';

TextSpan _clickableLink({required String text, required String url}) {
  return TextSpan(
    text: text,
    style: textStylePink,
    recognizer: TapGestureRecognizer()
      ..onTap = () async {
        try {
          await launchUrl(Uri.parse(url));
        } catch (_) {}
      },
  );
}

Widget _loginButton(
  BuildContext context,
  WidgetRef ref,
  String image,
  Function action,
) {
  return GestureDetector(
    onTap: () async {
      try {
        await InternetAddress.lookup('www.google.com');
        ref.read(app.model).setUserAuthToken(await action());
      } on SocketException catch (_) {
        if (context.mounted) {
          alertDialog(
            context,
            "Couldn't Sign In",
            "Noa requires an internet connection",
          );
        }
      } on NoaApiServerException catch (error) {
        if (context.mounted) {
          alertDialog(
            context,
            "Couldn't Sign In",
            "Server responded with an error: $error",
          );
        }
      } catch (_) {}
    },
    child: Padding(
      padding: const EdgeInsets.only(bottom: 20),
      child: Image.asset(image),
    ),
  );
}

class LoginPage extends ConsumerStatefulWidget {
  const LoginPage({super.key});

  @override
  ConsumerState<LoginPage> createState() => _LoginPageState();
}

class _LoginPageState extends ConsumerState<LoginPage> {
  late bool showWebview;

  @override
  void initState() {
    showWebview = false;
    super.initState();
  }

  @override
  Widget build(BuildContext context) {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      Location.requestPermission(context);
      if (ref.watch(app.model).state.current != app.State.waitForLogin) {
        switchPage(context, const PairingPage());
      }
    });

    return Scaffold(
      backgroundColor: colorDark,
      appBar: AppBar(
        backgroundColor: colorDark,
        title: Image.asset('assets/images/brilliant_logo.png'),
        centerTitle: true,
      ),
      body: Stack(
        children: [
          Column(
            children: [
              Expanded(child: Image.asset('assets/images/noa_logo.png')),
              Column(
                children: [
                  if (Platform.isIOS)
                    _loginButton(
                      context,
                      ref,
                      'assets/images/sign_in_with_apple_button.png',
                      SignIn().withApple,
                    ),
                  if (Platform.isIOS)
                    _loginButton(
                      context,
                      ref,
                      'assets/images/sign_in_with_google_button.png',
                      SignIn().withGoogle,
                    ),
                  GestureDetector(
                    onTap: () async {
                      try {
                        await InternetAddress.lookup('www.google.com');
                        setState(() => showWebview = true);
                      } on SocketException catch (_) {
                        if (context.mounted) {
                          alertDialog(
                            context,
                            "Couldn't Sign In",
                            "Noa requires an internet connection",
                          );
                        }
                      }
                    },
                    child: Padding(
                      padding: const EdgeInsets.only(bottom: 20),
                      child: Image.asset(
                          'assets/images/sign_in_with_email_button.png'),
                    ),
                  )
                ],
              )
            ],
          ),
          if (showWebview)
            Container(
              padding: const EdgeInsets.all(50),
              color: const Color(0xA0292929),
              child: Container(
                decoration: BoxDecoration(
                  border: Border.all(color: colorWhite, width: 2),
                ),
                child: WebViewWidget(
                  controller: WebViewController()
                    ..loadRequest(
                        Uri.parse("https://api.brilliant.xyz/noa/login?app=1"))
                    ..setJavaScriptMode(JavaScriptMode.unrestricted)
                    ..addJavaScriptChannel("userAuthToken",
                        onMessageReceived: (message) {
                      if (message.message == "cancelled") {
                        setState(() {
                          showWebview = false;
                        });
                      } else if (message.message != "") {
                        ref.read(app.model).setUserAuthToken(message.message);
                      }
                    }),
                ),
              ),
            )
        ],
      ),
      bottomNavigationBar: Padding(
        padding: const EdgeInsets.only(bottom: 48, top: 48),
        child: RichText(
          textAlign: TextAlign.center,
          text: TextSpan(
            children: <TextSpan>[
              const TextSpan(text: ''),
              _clickableLink(
                text: 'Privacy Policy',
                url: 'https://brilliant.xyz/pages/privacy-policy',
              ),
              const TextSpan(text: ' and ', style: textStyleWhite),
              _clickableLink(
                text: 'Terms and Conditions',
                url: 'https://brilliant.xyz/pages/terms-conditions',
              ),
              const TextSpan(text: ' of Noa.', style: textStyleWhite),
            ],
          ),
        ),
      ),
    );
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\noa.dart =====
----- Class: NoaPage -----
import 'dart:async';

import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:noa/main.dart';
import 'package:noa/models/app_logic_model.dart' as app;
import 'package:noa/noa_api.dart';
import 'package:noa/pages/pairing.dart';
import 'package:noa/style.dart';
import 'package:noa/util/show_toast.dart';
import 'package:noa/util/switch_page.dart';
import 'package:noa/widgets/bottom_nav_bar.dart';
import 'package:noa/widgets/top_title_bar.dart';
import 'package:saver_gallery/saver_gallery.dart';
import 'package:uuid/uuid.dart';

final ScrollController _scrollController = ScrollController();

class NoaPage extends ConsumerWidget {
  const NoaPage({super.key});

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      switch (ref.watch(app.model).state.current) {
        case app.State.stopLuaApp:
        case app.State.checkFirmwareVersion:
        case app.State.uploadMainLua:
        case app.State.uploadGraphicsLua:
        case app.State.uploadStateLua:
        case app.State.triggerUpdate:
        case app.State.updateFirmware:
          switchPage(context, const PairingPage());
          break;
        default:
      }
      Timer(const Duration(milliseconds: 100), () {
        if (context.mounted) {
          ref.watch(app.model.select((value) {
            if (value.noaMessages.length > 6) {
              _scrollController.animateTo(
                _scrollController.position.maxScrollExtent,
                duration: const Duration(milliseconds: 100),
                curve: Curves.easeOut,
              );
            }
          }));
        }
      });
    });

    return Scaffold(
      backgroundColor: colorWhite,
      appBar: topTitleBar(context, 'CHAT', false, false),
      body: PageStorage(
        bucket: globalPageStorageBucket,
        child: ListView.builder(
          key: const PageStorageKey<String>('noaPage'),
          controller: _scrollController,
          itemCount: ref.watch(app.model).noaMessages.length,
          itemBuilder: (context, index) {
            TextStyle style = textStyleLight;
            if (ref.watch(app.model).noaMessages[index].from == NoaRole.noa) {
              style = textStyleDark;
            }
            return Column(
              crossAxisAlignment: CrossAxisAlignment.start,
              children: [
                if (index == 0 ||
                    ref
                            .watch(app.model)
                            .noaMessages[index]
                            .time
                            .difference(ref
                                .watch(app.model)
                                .noaMessages[index - 1]
                                .time)
                            .inSeconds >
                        1700)
                  Container(
                    margin: const EdgeInsets.only(top: 40, left: 42, right: 42),
                    child: Row(
                      children: [
                        Text(
                          "${ref.watch(app.model).noaMessages[index].time.hour.toString().padLeft(2, '0')}:${ref.watch(app.model).noaMessages[index].time.minute.toString().padLeft(2, '0')}",
                          style: const TextStyle(color: colorLight),
                        ),
                        const Flexible(
                          child: Divider(
                            indent: 10,
                            color: colorLight,
                          ),
                        ),
                      ],
                    ),
                  ),
                Container(
                  margin: const EdgeInsets.only(top: 10, left: 65, right: 42),
                  child: Text(
                    ref.watch(app.model).noaMessages[index].message,
                    style: style,
                  ),
                ),
                if (ref.watch(app.model).noaMessages[index].image != null)
                  Container(
                    decoration: BoxDecoration(
                      border: Border.all(
                        color: colorLight,
                        width: 0.5,
                      ),
                      borderRadius: BorderRadius.circular(10.5),
                    ),
                    margin: const EdgeInsets.only(
                        top: 10, bottom: 10, left: 65, right: 65),
                    child: ClipRRect(
                      borderRadius: BorderRadius.circular(10),
                      child: SizedBox.fromSize(
                        child: GestureDetector(
                          onLongPress: () async {
                            await SaverGallery.saveImage(
                                ref.watch(app.model).noaMessages[index].image!,
                                name: const Uuid().v1(),
                                androidExistNotSave: false);
                            if (context.mounted) {
                              showToast("Saved to photos", context);
                            }
                          },
                          child: Image.memory(
                              ref.watch(app.model).noaMessages[index].image!),
                        ),
                      ),
                    ),
                  ),
              ],
            );
          },
          padding: const EdgeInsets.only(bottom: 20),
        ),
      ),
      bottomNavigationBar: bottomNavBar(context, 0, false),
    );
  }
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\pairing.dart =====
----- Class: PairingPage -----
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:noa/models/app_logic_model.dart' as app;
import 'package:noa/pages/noa.dart';
import 'package:noa/style.dart';
import 'package:noa/util/switch_page.dart';

class PairingPage extends ConsumerWidget {
  const PairingPage({super.key});

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      if (ref.watch(app.model).state.current == app.State.connected ||
          ref.watch(app.model).state.current == app.State.disconnected) {
        switchPage(context, const NoaPage());
      }
    });

    String pairingBoxText = "";
    String pairingBoxButtonText = "";
    Image pairingBoxImage = Image.asset('assets/images/charge.gif');
    bool pairingBoxButtonEnabled = false;
    int updateProgress = ref.watch(app.model).bluetoothUploadProgress.toInt();
    String deviceName = ref.watch(app.model).deviceName;

    switch (ref.watch(app.model).state.current) {
      case app.State.scanning:
        pairingBoxText = "Bring your device close";
        pairingBoxButtonText = "Searching";
        pairingBoxImage = Image.asset('assets/images/charge.gif');
        pairingBoxButtonEnabled = false;
        break;
      case app.State.found:
        pairingBoxText = "$deviceName found";
        pairingBoxButtonText = "Pair";
        pairingBoxImage = Image.asset('assets/images/charge.gif');
        pairingBoxButtonEnabled = true;
        break;
      case app.State.connect:
      case app.State.stopLuaApp:
      case app.State.checkFirmwareVersion:
      case app.State.triggerUpdate:
        pairingBoxText = "$deviceName found";
        pairingBoxButtonText = "Connecting";
        pairingBoxImage = Image.asset('assets/images/charge.gif');
        pairingBoxButtonEnabled = false;
        break;
      case app.State.updateFirmware:
        pairingBoxText = "Updating software $updateProgress%";
        pairingBoxButtonText = "Keep your device close";
        pairingBoxImage = Image.asset('assets/images/charge.gif');
        pairingBoxButtonEnabled = false;
        break;
      case app.State.uploadMainLua:
        pairingBoxText = "Setting up Noa 50%";
        pairingBoxButtonText = "Keep your device close";
        pairingBoxImage = Image.asset('assets/images/charge.gif');
        pairingBoxButtonEnabled = false;
        break;
      case app.State.uploadGraphicsLua:
        pairingBoxText = "Setting up Noa 68%";
        pairingBoxButtonText = "Keep your device close";
        pairingBoxImage = Image.asset('assets/images/charge.gif');
        pairingBoxButtonEnabled = false;
        break;
      case app.State.uploadStateLua:
        pairingBoxText = "Setting up Noa 83%";
        pairingBoxButtonText = "Keep your device close";
        pairingBoxImage = Image.asset('assets/images/charge.gif');
        pairingBoxButtonEnabled = false;
        break;
      case app.State.requiresRepair:
        pairingBoxText = "Un-pair Frame first";
        pairingBoxButtonText = "Try again";
        pairingBoxImage = Image.asset('assets/images/repair.gif');
        pairingBoxButtonEnabled = true;
        break;
    }

    return Scaffold(
      backgroundColor: colorDark,
      appBar: AppBar(
        backgroundColor: colorDark,
        title: Image.asset('assets/images/brilliant_logo.png'),
      ),
      body: Column(
        children: [
          const Expanded(
            child: Center(
              child: Text("Setup your device", style: textStyleLightHeading),
            ),
          ),
          AspectRatio(
            aspectRatio: 1,
            child: Container(
              margin: const EdgeInsets.only(bottom: 22, left: 11, right: 11),
              decoration: const BoxDecoration(
                color: colorWhite,
                borderRadius: BorderRadius.all(Radius.circular(42)),
              ),
              child: Column(
                children: [
                  Align(
                    alignment: Alignment.centerRight,
                    child: Padding(
                      padding: const EdgeInsets.only(top: 20, right: 20),
                      child: GestureDetector(
                        onTap: () {
                          ref
                              .read(app.model)
                              .triggerEvent(app.Event.cancelPressed);
                        },
                        child: const Icon(
                          Icons.cancel,
                          color: colorDark,
                        ),
                      ),
                    ),
                  ),
                  Text(
                    pairingBoxText,
                    style: const TextStyle(
                      fontFamily: 'SF Pro Display',
                      color: colorDark,
                      fontSize: 24,
                      fontWeight: FontWeight.w600,
                    ),
                  ), //
                  Expanded(
                    child: pairingBoxImage,
                  ),
                  GestureDetector(
                    onTap: () {
                      ref.read(app.model).triggerEvent(app.Event.buttonPressed);
                    },
                    child: Container(
                      decoration: BoxDecoration(
                        color: pairingBoxButtonEnabled ? colorDark : colorLight,
                        borderRadius:
                            const BorderRadius.all(Radius.circular(20)),
                      ),
                      height: 50,
                      margin: const EdgeInsets.only(
                          left: 31, right: 31, bottom: 28),
                      child: Center(
                        child: Text(
                          pairingBoxButtonText,
                          style: textStyleWhiteWidget,
                        ),
                      ),
                    ),
                  ),
                ],
              ),
            ),
          ),
        ],
      ),
    );
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\regulatory.dart =====
----- Class: RegulatoryPage -----
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:noa/style.dart';
import 'package:noa/widgets/top_title_bar.dart';

Widget _regulationEntry(String country, Widget body) {
  return Padding(
    padding: const EdgeInsets.only(top: 16),
    child: Row(
      mainAxisAlignment: MainAxisAlignment.spaceAround,
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Expanded(
          child: Text(country, style: textStyleDark),
        ),
        Expanded(
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            children: [body],
          ),
        ),
      ],
    ),
  );
}

class RegulatoryPage extends ConsumerWidget {
  const RegulatoryPage({super.key});

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    return Scaffold(
        backgroundColor: colorWhite,
        appBar: topTitleBar(context, 'REGULATORY', false, true),
        body: Padding(
          padding: const EdgeInsets.only(left: 42, right: 42),
          child: SingleChildScrollView(
            child: Column(
              children: [
                Column(
                  children: [
                    const Row(
                      mainAxisAlignment: MainAxisAlignment.spaceAround,
                      children: [
                        Expanded(
                          child:
                              Text("Country", style: textStyleLightSubHeading),
                        ),
                        Expanded(
                          child: Text("Label", style: textStyleLightSubHeading),
                        ),
                      ],
                    ),
                    _regulationEntry(
                      "United States",
                      Column(
                        crossAxisAlignment: CrossAxisAlignment.start,
                        children: [
                          const Padding(
                              padding: EdgeInsets.only(bottom: 8),
                              child: Text("FCC ID: 2BFWB-F1",
                                  style: textStyleDark)),
                          Padding(
                            padding: const EdgeInsets.only(bottom: 8),
                            child: Image.asset('assets/images/fcc_icon.png'),
                          ),
                          const Padding(
                            padding: EdgeInsets.only(bottom: 8),
                            child: Text(
                              "This device complies with Part 15 of the FCC Rules. Operation is subject to the following two conditions: (1) This device may not cause harmful interference, and (2) This device must accept any interference received, including interference that may cause undesired operation.",
                              style: textStyleDark,
                            ),
                          ),
                        ],
                      ),
                    ),
                    _regulationEntry(
                      "Europe / \nUnited Kingdom",
                      Image.asset('assets/images/eu_reg_icons.png'),
                    ),
                    _regulationEntry(
                      "Japan",
                      Image.asset('assets/images/telec_icon.png'),
                    ),
                  ],
                ),
                const Padding(
                  padding: EdgeInsets.only(top: 40, bottom: 8),
                  child: Text(
                    "Brilliant Labs Pte Ltd\n68 Circular Road #02-01\n049422 Singapore",
                    style: textStyleDark,
                    textAlign: TextAlign.center,
                  ),
                ),
                const Padding(
                    padding: EdgeInsets.only(bottom: 40),
                    child: Text(
                      "Frame is made in Singapore",
                      style: textStyleDark,
                    )),
              ],
            ),
          ),
        ));
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\splash.dart =====
----- Class: SplashPage -----
import 'dart:async';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:noa/models/app_logic_model.dart' as app;
import 'package:noa/pages/login.dart';
import 'package:noa/pages/noa.dart';
import 'package:noa/style.dart';
import 'package:noa/util/switch_page.dart';

class SplashPage extends ConsumerWidget {
  const SplashPage({super.key});

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    WidgetsBinding.instance.addPostFrameCallback((_) {
      ref.read(app.model).triggerEvent(app.Event.init);
      Timer(const Duration(milliseconds: 1500), () {
        switch (ref.watch(app.model).state.current) {
          case app.State.connected:
          case app.State.disconnected:
            switchPage(context, const NoaPage());
            break;
          default:
            switchPage(context, const LoginPage());
        }
      });
    });

    return Scaffold(
      backgroundColor: colorWhite,
      body: Center(
        child: Image.asset('assets/images/brilliant_logo_black.png'),
      ),
    );
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\pages\tune.dart =====
----- Class: TunePage -----
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:noa/models/app_logic_model.dart' as app;
import 'package:noa/style.dart';
import 'package:noa/widgets/bottom_nav_bar.dart';
import 'package:noa/widgets/top_title_bar.dart';

Widget _textBox(WidgetRef ref, int index) {
  late String title;
  late String value;
  late bool isCustomServerEnabled = ref.watch(app.model.select((v) => v.customServer));
  late bool willShow = true;
  switch (index) {
    case 0:
      willShow = !isCustomServerEnabled;
      title = "System prompt";
      value = ref.watch(app.model.select((v) => v.tunePrompt)); 
      break;
  }
  if (!willShow) {
    return Container();
  }
  return Padding(
    padding: const EdgeInsets.only(bottom: 21),
    child: Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Padding(
          padding: const EdgeInsets.only(bottom: 10),
          child: Text(title, style: textStyleLightSubHeading),
        ),
        Container(
          decoration: const BoxDecoration(
            color: colorLight,
            borderRadius: BorderRadius.all(Radius.circular(10)),
          ),
          padding: const EdgeInsets.only(
            top: 5,
            bottom: 7,
            left: 10,
            right: 10,
          ),
          child: TextFormField(
            initialValue: value,
            minLines: 8,
            maxLines: null,
            onTapOutside: (event) => FocusScope.of(ref.context).unfocus(),
            onChanged: (value) {
              switch (index) {
                case 0:
                  ref.read(app.model.select((v) => v.tunePrompt = value));
                  break;
              }
            },
            style: textStyleDark,
            decoration: const InputDecoration.collapsed(
              fillColor: colorLight,
              filled: true,
              hintText: "",
            ),
          ),
        ),
      ],
    ),
  );
}

Widget _inputBox(WidgetRef ref, int index) {
  late String title;
  late String value;
  late bool isCustomServerEnabled = ref.watch(app.model.select((v) => v.customServer));
  late bool willShow = true;

  switch (index) {
    case 0:
      willShow = isCustomServerEnabled;
      title = "API Endpoint";
      value = ref.watch(app.model.select((v) => v.apiEndpoint));
      break;
    case 1:
      willShow = isCustomServerEnabled;
      title = "API Header Value";
      value = ref.watch(app.model.select((v) => v.apiHeader));
      break;
    case 2:
      willShow = isCustomServerEnabled;
      title = "API Header Key";
      value = ref.watch(app.model.select((v) => v.apiToken));
      break;
  }
  if (!willShow) {
    return Container();
  }
  return Padding(
    padding: const EdgeInsets.only(bottom: 21),
    child: Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Padding(
          padding: const EdgeInsets.only(bottom: 10),
          child: Text(title, style: textStyleLightSubHeading),
        ),
        Container(
          decoration: const BoxDecoration(
            color: colorLight,
            borderRadius: BorderRadius.all(Radius.circular(10)),
          ),
          padding: const EdgeInsets.only(
            top: 5,
            bottom: 7,
            left: 10,
            right: 10,
          ),
          child: TextFormField(
            initialValue: value,
            minLines: 1,
            maxLines: null,
            onTapOutside: (event) => FocusScope.of(ref.context).unfocus(),
            onChanged: (value) {
              switch (index) {
                case 0:
                  ref.read(app.model.select((v) => v.apiEndpoint = value));
                  break;
                case 1:
                  ref.read(app.model.select((v) => v.apiHeader = value));
                  break;
                case 2:
                  ref.read(app.model.select((v) => v.apiToken = value));
                  break;
              }
            },
            style: textStyleDark,
            decoration: const InputDecoration.collapsed(
              fillColor: colorLight,
              filled: true,
              hintText: "",
            ),
          ),
        ),
      ],
    ),
  );
}

Widget _slider(WidgetRef ref, int index) {
  late String title;
  late int divisions;
  late int value;
  late String label;
  late bool isCustomServerEnabled = ref.watch(app.model.select((v) => v.customServer));
  late bool willShow = true;
  switch (index) {
    case 0:
      willShow = !isCustomServerEnabled;
      title = "Temperature";
      divisions = 100;
      value = ref.watch(app.model.select((v) => v.tuneTemperature));
      label = value.toString();
      break;
    case 1:
      willShow = !isCustomServerEnabled;
      title = "Response length";
      divisions = 4;
      value = ref.watch(app.model.select((v) => v.tuneLength.index));
      label = ref.watch(app.model.select((v) => v.tuneLength.name));
      break;
  }
  if (!willShow) {
    return Container();
  }
  return Padding(
    padding: const EdgeInsets.only(bottom: 10),
    child: Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Padding(
          padding: const EdgeInsets.only(bottom: 0),
          child: Text(title, style: textStyleLightSubHeading),
        ),
        SliderTheme(
          data: const SliderThemeData(
            trackHeight: 5,
            activeTrackColor: colorLight,
            activeTickMarkColor: colorLight,
            inactiveTrackColor: colorLight,
            inactiveTickMarkColor: colorLight,
            thumbColor: colorLight,
            valueIndicatorColor: colorDark,
            trackShape: RectangularSliderTrackShape(),
          ),
          child: Slider(
            label: label,
            value: value.toDouble(),
            divisions: divisions,
            min: 0,
            max: divisions.toDouble(),
            onChanged: (double value) {
              switch (index) {
                case 0:
                  ref.read(app.model
                      .select((v) => v.tuneTemperature = value.toInt()));
                  break;
                case 1:
                  late app.TuneLength enumValue;
                  switch (value.toInt()) {
                    case 0:
                      enumValue = app.TuneLength.shortest;
                      break;
                    case 1:
                      enumValue = app.TuneLength.short;
                      break;
                    case 2:
                      enumValue = app.TuneLength.standard;
                      break;
                    case 3:
                      enumValue = app.TuneLength.long;
                      break;
                    case 4:
                      enumValue = app.TuneLength.longest;
                      break;
                  }
                  ref.read(app.model.select((v) => v.tuneLength = enumValue));
                  break;
              }
            },
          ),
        ),
      ],
    ),
  );
}

Widget _checkBox(WidgetRef ref, int index) {
  late String title;
  late bool value;
  late String disableOption = "Disabled";
  late String enableOption = "Enabled";
  late bool isCustomServerEnabled = ref.watch(app.model.select((v) => v.customServer));
  late bool willShow = true;

  switch (index) {
    case 0:
      willShow = !isCustomServerEnabled;
      title = "Text to speech";
      value = ref.watch(app.model.select((v) => v.textToSpeech));
      disableOption = "Disabled";
      enableOption = "Enabled";
    case 1:
      willShow = !isCustomServerEnabled;
      title = "Promptless";
      value = ref.watch(app.model.select((v) => v.promptless));
    case 2:
      title = "Server";
      value = ref.watch(app.model.select((v) => v.customServer));
      disableOption = "Noa Server";
      enableOption = "Custom Server";
  }
  if (!willShow) {
    return Container();
  }

  return Padding(
    padding: const EdgeInsets.only(bottom: 10),
    child: Column(
      crossAxisAlignment: CrossAxisAlignment.start,
      children: [
        Padding(
          padding: const EdgeInsets.only(bottom: 8.0),
          child: Text(title, style: textStyleLightSubHeading),
        ),
        Row(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
             Padding(
              padding: const EdgeInsets.only(right: 8),
              child: Text(disableOption, style: textStyleDark),
            ),
            Switch(
              value: value,
              activeColor: colorDark,
              inactiveTrackColor: colorWhite,
              inactiveThumbColor: colorLight,
              onChanged: (value) {
                switch (index) {
                  case 0:
                    ref.read(app.model.select((v) => v.textToSpeech = value));
                    break;
                  case 1:
                    ref.read(app.model.select((v) => v.promptless = value));
                    break;
                  case 2:
                    ref.read(app.model.select((v) => v.customServer = value));
                    break;
                }
              },
            ),
            Padding(
              padding: const EdgeInsets.only(right: 8, left: 8),
              child: Text(enableOption, style: textStyleDark),
            ),
          ],
        ),
      ],
    ),
  );
}

class TunePage extends ConsumerWidget {
  const TunePage({super.key});

  @override
  Widget build(BuildContext context, WidgetRef ref) {
    return Scaffold(
      backgroundColor: colorWhite,
      appBar: topTitleBar(context, 'HACK', false, false),
      body: Padding(
        padding: const EdgeInsets.only(left: 42, right: 42),
        child: SingleChildScrollView(
          child: Column(
            children: [
              _checkBox(ref, 2),
              _textBox(ref, 0),
              _slider(ref, 0),
              _slider(ref, 1),
              _checkBox(ref, 0),
              _inputBox(ref, 0),
              _inputBox(ref, 2),
              _inputBox(ref, 1),
              _checkBox(ref, 1),
            ],
          ),
        ),
      ),
      bottomNavigationBar: bottomNavBar(context, 1, false),
    );
  }
}




===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\util\app_log.dart =====
----- Class: AppLog -----
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/foundation.dart';
import 'package:logging/logging.dart';

class AppLog extends ChangeNotifier {
  String app = "";
  String bluetooth = "";

  AppLog() {
    Logger.root.level = Level.INFO;
    Logger.root.onRecord.listen((log) {
      if (kDebugMode) {
        print('${log.level.name} - ${log.loggerName}: ${log.message}');
      }
      if (log.loggerName == "Bluetooth") {
        bluetooth += "${log.level.name} - ${log.message}\n";
      } else {
        app += "${log.level.name} - ${log.loggerName}: ${log.message}\n";
      }
      // TODO limit the size of this string
      notifyListeners();
    });
  }
}

final appLog = ChangeNotifierProvider<AppLog>((ref) => AppLog());





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\util\foreground_service.dart =====
----- Class: _ForegroundFirstTaskHandler -----
import 'dart:isolate';
import 'package:flutter_foreground_task/flutter_foreground_task.dart';
import 'package:logging/logging.dart';

final _log = Logger("Foreground task");

void initializeForegroundService() {
  FlutterForegroundTask.init(
    androidNotificationOptions: AndroidNotificationOptions(
      channelId: 'foreground_service',
      channelName: 'Noa Service',
      channelImportance: NotificationChannelImportance.MIN,
      iconData: null,
    ),
    iosNotificationOptions: const IOSNotificationOptions(
      showNotification: false,
      playSound: false,
    ),
    foregroundTaskOptions: const ForegroundTaskOptions(
      isOnceEvent: true,
    ),
  );
}

void startForegroundService() async {
  if (await FlutterForegroundTask.isRunningService) {
    FlutterForegroundTask.restartService();
  } else {
    FlutterForegroundTask.startService(
      notificationTitle: 'Noa is standing by',
      notificationText: 'Tap to return to the app',
      callback: _startForegroundCallback,
    );
  }
}

@pragma('vm:entry-point')
void _startForegroundCallback() {
  FlutterForegroundTask.setTaskHandler(_ForegroundFirstTaskHandler());
}

class _ForegroundFirstTaskHandler extends TaskHandler {
  @override
  void onStart(DateTime timestamp, SendPort? sendPort) async {
    _log.info("Starting foreground task");
  }

  @override
  void onRepeatEvent(DateTime timestamp, SendPort? sendPort) async {
    _log.info("Foreground repeat event triggered");
  }

  @override
  void onDestroy(DateTime timestamp, SendPort? sendPort) async {
    _log.info("Destroying foreground task");
    FlutterForegroundTask.stopService();
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\util\location.dart =====
----- Class: Location -----
import 'dart:async';
import 'dart:io';
import 'package:flutter/material.dart';
import 'package:geocoding/geocoding.dart' as geocoding;
import 'package:geolocator/geolocator.dart';
import 'package:logging/logging.dart';

final _log = Logger("Location");

Position? _position;

class Location {
  static Future<void> requestPermission(BuildContext context) async {
    LocationPermission permission = await Geolocator.checkPermission();

    if (permission == LocationPermission.denied) {
      _log.info("Requesting location permission from user");

      if (Platform.isAndroid) {
        Completer completer = Completer();
        if (context.mounted) {
          showDialog(
            context: context,
            builder: (BuildContext context) => AlertDialog(
              title: const Text("Allow location?"),
              content: const Text(
                  "Noa can give responses and recommendations based on your current location even when the app is in the background. This is optional and can be turned off at anytime from your system settings"),
              actions: <Widget>[
                TextButton(
                  onPressed: () {
                    Navigator.pop(context);
                    completer.complete();
                  },
                  child: const Text('Okay'),
                )
              ],
            ),
          );
        }
        await completer.future;
      }

      await Geolocator.requestPermission();
      permission = await Geolocator.checkPermission();
      if (permission == LocationPermission.denied ||
          permission == LocationPermission.deniedForever) {
        _log.info("Permission rejected by user. Won't use location");
        return;
      }
    }

    startLocationStream();
  }

static void startLocationStream() async {
    late LocationSettings locationSettings;
    LocationPermission permission = await Geolocator.checkPermission();

    if (permission == LocationPermission.denied ||
        permission == LocationPermission.deniedForever) {
      _log.info("location permission not present. Won't use location");
      return;
    }

    if (Platform.isIOS) {
      locationSettings = AppleSettings(
          accuracy: LocationAccuracy.low,
          pauseLocationUpdatesAutomatically: true);
    }

    if (Platform.isAndroid) {
      locationSettings = AndroidSettings(
          accuracy: LocationAccuracy.low,
          intervalDuration: const Duration(minutes: 5));
    }

    Geolocator.getPositionStream(locationSettings: locationSettings)
        .listen((Position? position) {
      _log.fine("Location updated. Accuracy: ${position!.accuracy}");
      _position = position;
    });
  }

  static Future<String> getAddress() async {
    String appendComma(String string) {
      if (string != "") {
        string += ", ";
      }
      return string;
    }

    try {
      if (_position == null) {
        return "";
      }

      _log.info(
          "Using co-ordinates: Latitude: ${_position!.latitude}, longitude: ${_position!.longitude}");

      geocoding.Placemark placemark = (await geocoding.placemarkFromCoordinates(
        _position!.latitude,
        _position!.longitude,
      ))
          .first;

      String returnString = "";

      if (placemark.name != null) {
        returnString += placemark.name!;
      }

      if (placemark.street != null && placemark.street != placemark.name) {
        returnString = appendComma(returnString);
        returnString += placemark.street!;
      }

      if (placemark.subLocality != null) {
        returnString = appendComma(returnString);
        returnString += placemark.subLocality!;
      }

      if (placemark.locality != null) {
        returnString = appendComma(returnString);
        returnString += placemark.locality!;
      }

      if (placemark.postalCode != null) {
        returnString = appendComma(returnString);
        returnString += placemark.postalCode!;
      }

      if (placemark.country != null) {
        returnString = appendComma(returnString);
        returnString += placemark.country!;
      }

      return returnString;
    } catch (error) {
      _log.warning("Could not get location: $error");
      return Future.error(error);
    }
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\util\sign_in.dart =====
----- Class: SignIn -----
import 'dart:io';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:flutter/foundation.dart';
import 'package:google_sign_in/google_sign_in.dart';
import 'package:logging/logging.dart';
import 'package:noa/noa_api.dart';
import 'package:sign_in_with_apple/sign_in_with_apple.dart';

final _log = Logger("Sign in");

class SignIn {
  Future<String> withApple() async {
    try {
      _log.info("Signing in using Apple");

      final credential = await SignInWithApple.getAppleIDCredential(
        scopes: [
          AppleIDAuthorizationScopes.email,
        ],
        webAuthenticationOptions: WebAuthenticationOptions(
          clientId: 'xyz.brilliant.noaflutter',
          redirectUri: Uri.parse('https://api.brilliant.xyz/noa/login/apple'),
        ),
      );

      return await NoaApi.signIn(
        credential.authorizationCode,
        NoaApiAuthProvider.apple,
      );
    } catch (error) {
      _log.warning("Could not sign in: $error");
      return Future.error(error);
    }
  }

  Future<String> withGoogle() async {
    try {
      _log.info("Signing in using Google");

      GoogleSignInAccount? account;

      if (Platform.isAndroid) {
        account = await GoogleSignIn(
          serverClientId: kReleaseMode
              ? dotenv.env['GOOGLE_ANDROID_CLIENT_ID']
              : dotenv.env['GOOGLE_ANDROID_DEBUG_CLIENT_ID'],
          scopes: ['email'],
        ).signIn();
      }

      if (Platform.isIOS) {
        account = await GoogleSignIn(
          clientId: dotenv.env['GOOGLE_IOS_CLIENT_ID'],
          scopes: ['email'],
        ).signIn();
      }

      final GoogleSignInAuthentication auth = await account!.authentication;

      return await NoaApi.signIn(
        auth.idToken ?? "",
        NoaApiAuthProvider.google,
      );
    } catch (error) {
      _log.warning("Could not sign in: $error");
      return Future.error(error);
    }
  }

  withDiscord() async {}
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\util\state_machine.dart =====
----- Class: StateMachine -----
import 'package:logging/logging.dart';

final _log = Logger("State machine");

class StateMachine {
  dynamic current;
  dynamic _next;
  dynamic _event;
  bool _onEntryHandled = false;

  StateMachine(initialState) {
    current = initialState;
    _next = initialState;
  }

  void event(event) {
    _event = event;
  }

  void changeOn(event, next, {Function? transitionTask}) {
    if (event == _event) {
      _event = null;
      _next = next;
      _onEntryHandled = false;

      if (transitionTask != null) {
        _log.fine("Executing transitionTask");
        transitionTask();
      }

      _log.info("$event triggered change $current  $next");
    }
  }

  bool changePending() {
    if (_next == current) {
      return false;
    }

    current = _next;
    return true;
  }

  void onEntry(Function task) {
    if (_onEntryHandled == false) {
      _log.fine("Executing onEntry task");
      task();
      _onEntryHandled = true;
    }
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\bluetooth.dart =====
----- Class: BrilliantBluetoothException -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'dart:typed_data';
import 'package:archive/archive_io.dart';
import 'package:flutter_blue_plus/flutter_blue_plus.dart';
import 'package:flutter/services.dart';
import 'package:logging/logging.dart';

final _log = Logger("Bluetooth");

class BrilliantBluetoothException implements Exception {
  final String msg;
  const BrilliantBluetoothException(this.msg);
  @override
  String toString() => 'BrilliantBluetoothException: $msg';
}

enum BrilliantConnectionState {
  connected,
  dfuConnected,
  disconnected,
}

class BrilliantScannedDevice {
  BluetoothDevice device;
  int? rssi;

  BrilliantScannedDevice({
    required this.device,
    required this.rssi,
  });
}

class BrilliantDevice {
  BluetoothDevice device;
  BrilliantConnectionState state;
  int? maxStringLength;
  int? maxDataLength;

  BluetoothCharacteristic? _txChannel;
  BluetoothCharacteristic? _rxChannel;
  BluetoothCharacteristic? _dfuControl;
  BluetoothCharacteristic? _dfuPacket;

  BrilliantDevice({
    required this.state,
    required this.device,
    this.maxStringLength,
    this.maxDataLength,
  });

  Stream<BrilliantDevice> get connectionState {
    return FlutterBluePlus.events.onConnectionStateChanged
        .where((event) =>
            event.connectionState == BluetoothConnectionState.connected ||
            (event.connectionState == BluetoothConnectionState.disconnected &&
                event.device.disconnectReason != null &&
                event.device.disconnectReason!.code != 23789258))
        .asyncMap((event) async {
      if (event.connectionState == BluetoothConnectionState.connected) {
        _log.info("Connection state stream: Connected");
        try {
          return await BrilliantBluetooth._enableServices(event.device);
        } catch (error) {
          _log.warning("Connection state stream: Invalid due to $error");
          return Future.error(BrilliantBluetoothException(error.toString()));
        }
      }
      _log.info(
          "Connection state stream: Disconnected due to ${event.device.disconnectReason!.description}");
      if (Platform.isAndroid) {
        event.device.connect(timeout: const Duration(days: 365));
      }
      return BrilliantDevice(
        state: BrilliantConnectionState.disconnected,
        device: event.device,
      );
    });
  }

  Stream<String> get stringResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] != 0x01)
        .map((event) {
      if (event.value[0] != 0x02) {
        _log.info("Received string: ${utf8.decode(event.value)}");
      }
      return utf8.decode(event.value);
    });
  }

  Stream<List<int>> get dataResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] == 0x01)
        .map((event) {
      _log.fine("Received data: ${event.value.sublist(1)}");
      return event.value.sublist(1);
    });
  }

  Future<void> disconnect() async {
    _log.info("Disconnecting");
    try {
      await device.disconnect();
    } catch (_) {}
  }

  Future<void> sendBreakSignal() async {
    _log.info("Sending break signal");
    await sendString("\x03", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<void> sendResetSignal() async {
    _log.info("Sending reset signal");
    await sendString("\x04", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<String?> sendString(
    String string, {
    bool awaitResponse = true,
    bool log = true,
  }) async {
    try {
      if (log) {
        _log.info("Sending string: $string");
      }

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (string.length > maxStringLength!) {
        throw ("Payload exceeds allowed length of $maxStringLength");
      }

      await _txChannel!.write(utf8.encode(string), withoutResponse: true);

      if (awaitResponse == false) {
        return null;
      }

      final response = await _rxChannel!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return utf8.decode(response);
    } catch (error) {
      _log.warning("Couldn't send string. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> sendData(List<int> data) async {
    try {
      _log.info("Sending ${data.length} bytes of plain data");
      _log.fine(data);

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (data.length > maxDataLength!) {
        throw ("Payload exceeds allowed length of $maxDataLength");
      }

      var finalData = data.toList()..insert(0, 0x01);

      await _txChannel!.write(finalData, withoutResponse: true);
    } catch (error) {
      _log.warning("Couldn't send data. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> uploadScript(String fileName, String filePath) async {
    try {
      _log.info("Uploading script: $fileName");

      String file = await rootBundle.loadString(filePath);

      file = file.replaceAll('\\', '\\\\');
      file = file.replaceAll("\r\n", "\\n");
      file = file.replaceAll("\n", "\\n");
      file = file.replaceAll("'", "\\'");
      file = file.replaceAll('"', '\\"');

      var resp = await sendString(
          "f=frame.file.open('$fileName', 'w');print('\x02')",
          log: false);

      if (resp != "\x02") {
        throw ("Error opening file: $resp");
      }

      int index = 0;
      int chunkSize = maxStringLength! - 22;

      while (index < file.length) {
        // Don't go over the end of the string
        if (index + chunkSize > file.length) {
          chunkSize = file.length - index;
        }

        // Don't split on an escape character
        while (file[index + chunkSize - 1] == '\\') {
          chunkSize -= 1;
        }

        String chunk = file.substring(index, index + chunkSize);

        resp = await sendString("f:write('$chunk');print('\x02')", log: false);

        if (resp != "\x02") {
          throw ("Error writing file: $resp");
        }

        index += chunkSize;
      }

      resp = await sendString("f:close();print('\x02')", log: false);

      if (resp != "\x02") {
        throw ("Error closing file: $resp");
      }
    } catch (error) {
      _log.warning("Couldn't upload script. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> updateFirmware(String filePath) async* {
    try {
      yield 0;

      _log.info("Starting firmware update");

      if (state != BrilliantConnectionState.dfuConnected) {
        throw ("DFU device is not connected");
      }

      if (_dfuControl == null || _dfuPacket == null) {
        throw ("Device is not in DFU mode");
      }

      final updateZipFile = await rootBundle.load(filePath);
      final zip = ZipDecoder().decodeBytes(updateZipFile.buffer.asUint8List());

      final initFile = zip.firstWhere((file) => file.name.endsWith(".dat"));
      final imageFile = zip.firstWhere((file) => file.name.endsWith(".bin"));

      await for (var _ in _transferDfuFile(initFile.content, true)) {}
      await Future.delayed(const Duration(milliseconds: 500));
      await for (var value in _transferDfuFile(imageFile.content, false)) {
        yield value;
      }

      _log.info("Firmware update completed");
    } catch (error) {
      _log.warning("Couldn't complete firmware update. $error");
      yield* Stream.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> _transferDfuFile(Uint8List file, bool isInitFile) async* {
    Uint8List response;

    try {
      if (isInitFile) {
        _log.fine("Uploading DFU init file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x01]));
      } else {
        _log.fine("Uploading DFU image file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x02]));
      }
    } catch (_) {
      throw ("Couldn't create DFU file on device");
    }

    final maxSize = ByteData.view(response.buffer).getUint32(3, Endian.little);
    var offset = ByteData.view(response.buffer).getUint32(7, Endian.little);
    final crc = ByteData.view(response.buffer).getUint32(11, Endian.little);

    _log.fine("Received allowed size: $maxSize, offset: $offset, CRC: $crc");

    while (offset < file.length) {
      final chunkSize = min(maxSize, file.length - offset);
      final chunkCrc = getCrc32(file.sublist(0, offset + chunkSize));

      // Create command with size
      final chunkSizeAsBytes = [
        chunkSize & 0xFF,
        chunkSize >> 8 & 0xFF,
        chunkSize >> 16 & 0xff,
        chunkSize >> 24 & 0xff
      ];

      try {
        if (isInitFile) {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x01, ...chunkSizeAsBytes]));
        } else {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x02, ...chunkSizeAsBytes]));
        }
      } catch (_) {
        throw ("Couldn't issue DFU create command");
      }

      // Split chunk into packets of MTU size
      final packetSize = device.mtuNow - 3;
      final packets = (chunkSize / packetSize).ceil();

      for (var p = 0; p < packets; p++) {
        final fileStart = offset + p * packetSize;
        var fileEnd = fileStart + packetSize;

        // The last packet could be smaller
        if (fileEnd - offset > maxSize) {
          fileEnd -= fileEnd - offset - maxSize;
        }

        // The last part of the file could also be smaller
        if (fileEnd > file.length) {
          fileEnd = file.length;
        }

        final fileSlice = file.sublist(fileStart, fileEnd);

        final percentDone = (100 / file.length) * offset;
        yield percentDone;

        _log.fine(
            "Sending ${fileSlice.length} bytes of packet data. ${percentDone.toInt()}% Complete");

        await _dfuSendPacketData(fileSlice)
            .onError((_, __) => throw ("Couldn't send DFU data"));
      }

      // Calculate CRC
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x03]));
      } catch (_) {
        throw ("Couldn't get CRC from device");
      }
      offset = ByteData.view(response.buffer).getUint32(3, Endian.little);
      final returnedCrc =
          ByteData.view(response.buffer).getUint32(7, Endian.little);

      if (returnedCrc != chunkCrc) {
        throw ("CRC mismatch after sending this chunk");
      }

      // Execute command (The last command may disconnect which is normal)
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x04]));
      } catch (_) {}
    }

    _log.fine("DFU file sent");
  }

  Future<Uint8List> _dfuSendControlData(Uint8List data) async {
    try {
      _log.fine("Sending ${data.length} bytes of DFU control data: $data");

      _dfuControl!.write(data, timeout: 1);

      final response = await _dfuControl!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return Uint8List.fromList(response);
    } catch (error) {
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> _dfuSendPacketData(Uint8List data) async {
    await _dfuPacket!.write(data, withoutResponse: true);
  }
}

class BrilliantBluetooth {
  static Future<void> requestPermission() async {
    try {
      await FlutterBluePlus.startScan();
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't obtain Bluetooth permission. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Stream<BrilliantScannedDevice> scan() async* {
    try {
      _log.info("Starting to scan for devices");

      await FlutterBluePlus.startScan(
        withServices: [
          Guid('7a230001-5475-a6a4-654c-8431f6ad49c4'),
          Guid('fe59'),
        ],
        continuousUpdates: true,
        removeIfGone: const Duration(seconds: 2),
      );
    } catch (error) {
      _log.warning("Scanning failed. $error");
      throw BrilliantBluetoothException(error.toString());
    }

    yield* FlutterBluePlus.scanResults
        .where((results) => results.isNotEmpty)
        // TODO filter by name: "Frame", "Frame Update", "Monocle" & "DFUTarg"
        .map((results) {
      ScanResult nearestDevice = results[0];
      for (int i = 0; i < results.length; i++) {
        if (results[i].rssi > nearestDevice.rssi) {
          nearestDevice = results[i];
        }
      }

      _log.fine(
          "Found ${nearestDevice.device.advName} rssi: ${nearestDevice.rssi}");

      return BrilliantScannedDevice(
        device: nearestDevice.device,
        rssi: nearestDevice.rssi,
      );
    });
  }

  static Future<void> stopScan() async {
    try {
      _log.info("Stopping scan for devices");
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't stop scanning. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> connect(BrilliantScannedDevice scanned) async {
    try {
      _log.info("Connecting");

      await FlutterBluePlus.stopScan();

      await scanned.device.connect(
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      );

      final connectionState = await scanned.device.connectionState
          .firstWhere((event) => event == BluetoothConnectionState.connected)
          .timeout(const Duration(seconds: 3));

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(scanned.device);
      }

      throw ("${scanned.device.disconnectReason?.description}");
    } catch (error) {
      await scanned.device.disconnect();
      _log.warning("Couldn't connect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> reconnect(String uuid) async {
    try {
      _log.info("Will re-connect to device: $uuid once found");

      BluetoothDevice device = BluetoothDevice.fromId(uuid);

      await device.connect(
        timeout: const Duration(days: 365),
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      ); // TODO Should wait but it throws an error on Android after some time

      final connectionState = await device.connectionState.firstWhere((state) =>
          state == BluetoothConnectionState.connected ||
          (state == BluetoothConnectionState.disconnected &&
              device.disconnectReason != null));

      _log.info("Found reconnectable device: $uuid");

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(device);
      }

      throw ("${device.disconnectReason?.description}");
    } catch (error) {
      _log.warning("Couldn't reconnect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> _enableServices(BluetoothDevice device) async {
    if (Platform.isAndroid) {
      await device.requestMtu(512);
    }

    BrilliantDevice finalDevice = BrilliantDevice(
      device: device,
      state: BrilliantConnectionState.disconnected,
    );

    List<BluetoothService> services = await device.discoverServices();

    for (var service in services) {
      // If Frame
      if (service.serviceUuid == Guid('7a230001-5475-a6a4-654c-8431f6ad49c4')) {
        _log.fine("Found Frame service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('7a230002-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame TX characteristic");
            finalDevice._txChannel = characteristic;
          }
          if (characteristic.characteristicUuid ==
              Guid('7a230003-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame RX characteristic");
            finalDevice._rxChannel = characteristic;

            await characteristic.setNotifyValue(true);
            _log.fine("Enabled RX notifications");

            finalDevice.maxStringLength = device.mtuNow - 3;
            finalDevice.maxDataLength = device.mtuNow - 4;
            _log.fine("Max string length: ${finalDevice.maxStringLength}");
            _log.fine("Max data length: ${finalDevice.maxDataLength}");
          }
        }
      }

      // If DFU
      if (service.serviceUuid == Guid('fe59')) {
        _log.fine("Found DFU service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('8ec90001-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU control characteristic");
            finalDevice._dfuControl = characteristic;
            await characteristic.setNotifyValue(true);
            _log.fine("Enabled DFU control notifications");
          }
          if (characteristic.characteristicUuid ==
              Guid('8ec90002-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU packet characteristic");
            finalDevice._dfuPacket = characteristic;
          }
        }
      }
    }

    if (finalDevice._txChannel != null && finalDevice._rxChannel != null) {
      finalDevice.state = BrilliantConnectionState.connected;
      return finalDevice;
    }

    if (finalDevice._dfuControl != null && finalDevice._dfuPacket != null) {
      finalDevice.state = BrilliantConnectionState.dfuConnected;
      return finalDevice;
    }

    throw ("Incomplete set of services found");
  }
}



----- Class: BrilliantScannedDevice -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'dart:typed_data';
import 'package:archive/archive_io.dart';
import 'package:flutter_blue_plus/flutter_blue_plus.dart';
import 'package:flutter/services.dart';
import 'package:logging/logging.dart';

final _log = Logger("Bluetooth");

class BrilliantBluetoothException implements Exception {
  final String msg;
  const BrilliantBluetoothException(this.msg);
  @override
  String toString() => 'BrilliantBluetoothException: $msg';
}

enum BrilliantConnectionState {
  connected,
  dfuConnected,
  disconnected,
}

class BrilliantScannedDevice {
  BluetoothDevice device;
  int? rssi;

  BrilliantScannedDevice({
    required this.device,
    required this.rssi,
  });
}

class BrilliantDevice {
  BluetoothDevice device;
  BrilliantConnectionState state;
  int? maxStringLength;
  int? maxDataLength;

  BluetoothCharacteristic? _txChannel;
  BluetoothCharacteristic? _rxChannel;
  BluetoothCharacteristic? _dfuControl;
  BluetoothCharacteristic? _dfuPacket;

  BrilliantDevice({
    required this.state,
    required this.device,
    this.maxStringLength,
    this.maxDataLength,
  });

  Stream<BrilliantDevice> get connectionState {
    return FlutterBluePlus.events.onConnectionStateChanged
        .where((event) =>
            event.connectionState == BluetoothConnectionState.connected ||
            (event.connectionState == BluetoothConnectionState.disconnected &&
                event.device.disconnectReason != null &&
                event.device.disconnectReason!.code != 23789258))
        .asyncMap((event) async {
      if (event.connectionState == BluetoothConnectionState.connected) {
        _log.info("Connection state stream: Connected");
        try {
          return await BrilliantBluetooth._enableServices(event.device);
        } catch (error) {
          _log.warning("Connection state stream: Invalid due to $error");
          return Future.error(BrilliantBluetoothException(error.toString()));
        }
      }
      _log.info(
          "Connection state stream: Disconnected due to ${event.device.disconnectReason!.description}");
      if (Platform.isAndroid) {
        event.device.connect(timeout: const Duration(days: 365));
      }
      return BrilliantDevice(
        state: BrilliantConnectionState.disconnected,
        device: event.device,
      );
    });
  }

  Stream<String> get stringResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] != 0x01)
        .map((event) {
      if (event.value[0] != 0x02) {
        _log.info("Received string: ${utf8.decode(event.value)}");
      }
      return utf8.decode(event.value);
    });
  }

  Stream<List<int>> get dataResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] == 0x01)
        .map((event) {
      _log.fine("Received data: ${event.value.sublist(1)}");
      return event.value.sublist(1);
    });
  }

  Future<void> disconnect() async {
    _log.info("Disconnecting");
    try {
      await device.disconnect();
    } catch (_) {}
  }

  Future<void> sendBreakSignal() async {
    _log.info("Sending break signal");
    await sendString("\x03", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<void> sendResetSignal() async {
    _log.info("Sending reset signal");
    await sendString("\x04", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<String?> sendString(
    String string, {
    bool awaitResponse = true,
    bool log = true,
  }) async {
    try {
      if (log) {
        _log.info("Sending string: $string");
      }

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (string.length > maxStringLength!) {
        throw ("Payload exceeds allowed length of $maxStringLength");
      }

      await _txChannel!.write(utf8.encode(string), withoutResponse: true);

      if (awaitResponse == false) {
        return null;
      }

      final response = await _rxChannel!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return utf8.decode(response);
    } catch (error) {
      _log.warning("Couldn't send string. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> sendData(List<int> data) async {
    try {
      _log.info("Sending ${data.length} bytes of plain data");
      _log.fine(data);

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (data.length > maxDataLength!) {
        throw ("Payload exceeds allowed length of $maxDataLength");
      }

      var finalData = data.toList()..insert(0, 0x01);

      await _txChannel!.write(finalData, withoutResponse: true);
    } catch (error) {
      _log.warning("Couldn't send data. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> uploadScript(String fileName, String filePath) async {
    try {
      _log.info("Uploading script: $fileName");

      String file = await rootBundle.loadString(filePath);

      file = file.replaceAll('\\', '\\\\');
      file = file.replaceAll("\r\n", "\\n");
      file = file.replaceAll("\n", "\\n");
      file = file.replaceAll("'", "\\'");
      file = file.replaceAll('"', '\\"');

      var resp = await sendString(
          "f=frame.file.open('$fileName', 'w');print('\x02')",
          log: false);

      if (resp != "\x02") {
        throw ("Error opening file: $resp");
      }

      int index = 0;
      int chunkSize = maxStringLength! - 22;

      while (index < file.length) {
        // Don't go over the end of the string
        if (index + chunkSize > file.length) {
          chunkSize = file.length - index;
        }

        // Don't split on an escape character
        while (file[index + chunkSize - 1] == '\\') {
          chunkSize -= 1;
        }

        String chunk = file.substring(index, index + chunkSize);

        resp = await sendString("f:write('$chunk');print('\x02')", log: false);

        if (resp != "\x02") {
          throw ("Error writing file: $resp");
        }

        index += chunkSize;
      }

      resp = await sendString("f:close();print('\x02')", log: false);

      if (resp != "\x02") {
        throw ("Error closing file: $resp");
      }
    } catch (error) {
      _log.warning("Couldn't upload script. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> updateFirmware(String filePath) async* {
    try {
      yield 0;

      _log.info("Starting firmware update");

      if (state != BrilliantConnectionState.dfuConnected) {
        throw ("DFU device is not connected");
      }

      if (_dfuControl == null || _dfuPacket == null) {
        throw ("Device is not in DFU mode");
      }

      final updateZipFile = await rootBundle.load(filePath);
      final zip = ZipDecoder().decodeBytes(updateZipFile.buffer.asUint8List());

      final initFile = zip.firstWhere((file) => file.name.endsWith(".dat"));
      final imageFile = zip.firstWhere((file) => file.name.endsWith(".bin"));

      await for (var _ in _transferDfuFile(initFile.content, true)) {}
      await Future.delayed(const Duration(milliseconds: 500));
      await for (var value in _transferDfuFile(imageFile.content, false)) {
        yield value;
      }

      _log.info("Firmware update completed");
    } catch (error) {
      _log.warning("Couldn't complete firmware update. $error");
      yield* Stream.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> _transferDfuFile(Uint8List file, bool isInitFile) async* {
    Uint8List response;

    try {
      if (isInitFile) {
        _log.fine("Uploading DFU init file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x01]));
      } else {
        _log.fine("Uploading DFU image file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x02]));
      }
    } catch (_) {
      throw ("Couldn't create DFU file on device");
    }

    final maxSize = ByteData.view(response.buffer).getUint32(3, Endian.little);
    var offset = ByteData.view(response.buffer).getUint32(7, Endian.little);
    final crc = ByteData.view(response.buffer).getUint32(11, Endian.little);

    _log.fine("Received allowed size: $maxSize, offset: $offset, CRC: $crc");

    while (offset < file.length) {
      final chunkSize = min(maxSize, file.length - offset);
      final chunkCrc = getCrc32(file.sublist(0, offset + chunkSize));

      // Create command with size
      final chunkSizeAsBytes = [
        chunkSize & 0xFF,
        chunkSize >> 8 & 0xFF,
        chunkSize >> 16 & 0xff,
        chunkSize >> 24 & 0xff
      ];

      try {
        if (isInitFile) {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x01, ...chunkSizeAsBytes]));
        } else {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x02, ...chunkSizeAsBytes]));
        }
      } catch (_) {
        throw ("Couldn't issue DFU create command");
      }

      // Split chunk into packets of MTU size
      final packetSize = device.mtuNow - 3;
      final packets = (chunkSize / packetSize).ceil();

      for (var p = 0; p < packets; p++) {
        final fileStart = offset + p * packetSize;
        var fileEnd = fileStart + packetSize;

        // The last packet could be smaller
        if (fileEnd - offset > maxSize) {
          fileEnd -= fileEnd - offset - maxSize;
        }

        // The last part of the file could also be smaller
        if (fileEnd > file.length) {
          fileEnd = file.length;
        }

        final fileSlice = file.sublist(fileStart, fileEnd);

        final percentDone = (100 / file.length) * offset;
        yield percentDone;

        _log.fine(
            "Sending ${fileSlice.length} bytes of packet data. ${percentDone.toInt()}% Complete");

        await _dfuSendPacketData(fileSlice)
            .onError((_, __) => throw ("Couldn't send DFU data"));
      }

      // Calculate CRC
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x03]));
      } catch (_) {
        throw ("Couldn't get CRC from device");
      }
      offset = ByteData.view(response.buffer).getUint32(3, Endian.little);
      final returnedCrc =
          ByteData.view(response.buffer).getUint32(7, Endian.little);

      if (returnedCrc != chunkCrc) {
        throw ("CRC mismatch after sending this chunk");
      }

      // Execute command (The last command may disconnect which is normal)
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x04]));
      } catch (_) {}
    }

    _log.fine("DFU file sent");
  }

  Future<Uint8List> _dfuSendControlData(Uint8List data) async {
    try {
      _log.fine("Sending ${data.length} bytes of DFU control data: $data");

      _dfuControl!.write(data, timeout: 1);

      final response = await _dfuControl!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return Uint8List.fromList(response);
    } catch (error) {
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> _dfuSendPacketData(Uint8List data) async {
    await _dfuPacket!.write(data, withoutResponse: true);
  }
}

class BrilliantBluetooth {
  static Future<void> requestPermission() async {
    try {
      await FlutterBluePlus.startScan();
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't obtain Bluetooth permission. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Stream<BrilliantScannedDevice> scan() async* {
    try {
      _log.info("Starting to scan for devices");

      await FlutterBluePlus.startScan(
        withServices: [
          Guid('7a230001-5475-a6a4-654c-8431f6ad49c4'),
          Guid('fe59'),
        ],
        continuousUpdates: true,
        removeIfGone: const Duration(seconds: 2),
      );
    } catch (error) {
      _log.warning("Scanning failed. $error");
      throw BrilliantBluetoothException(error.toString());
    }

    yield* FlutterBluePlus.scanResults
        .where((results) => results.isNotEmpty)
        // TODO filter by name: "Frame", "Frame Update", "Monocle" & "DFUTarg"
        .map((results) {
      ScanResult nearestDevice = results[0];
      for (int i = 0; i < results.length; i++) {
        if (results[i].rssi > nearestDevice.rssi) {
          nearestDevice = results[i];
        }
      }

      _log.fine(
          "Found ${nearestDevice.device.advName} rssi: ${nearestDevice.rssi}");

      return BrilliantScannedDevice(
        device: nearestDevice.device,
        rssi: nearestDevice.rssi,
      );
    });
  }

  static Future<void> stopScan() async {
    try {
      _log.info("Stopping scan for devices");
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't stop scanning. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> connect(BrilliantScannedDevice scanned) async {
    try {
      _log.info("Connecting");

      await FlutterBluePlus.stopScan();

      await scanned.device.connect(
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      );

      final connectionState = await scanned.device.connectionState
          .firstWhere((event) => event == BluetoothConnectionState.connected)
          .timeout(const Duration(seconds: 3));

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(scanned.device);
      }

      throw ("${scanned.device.disconnectReason?.description}");
    } catch (error) {
      await scanned.device.disconnect();
      _log.warning("Couldn't connect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> reconnect(String uuid) async {
    try {
      _log.info("Will re-connect to device: $uuid once found");

      BluetoothDevice device = BluetoothDevice.fromId(uuid);

      await device.connect(
        timeout: const Duration(days: 365),
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      ); // TODO Should wait but it throws an error on Android after some time

      final connectionState = await device.connectionState.firstWhere((state) =>
          state == BluetoothConnectionState.connected ||
          (state == BluetoothConnectionState.disconnected &&
              device.disconnectReason != null));

      _log.info("Found reconnectable device: $uuid");

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(device);
      }

      throw ("${device.disconnectReason?.description}");
    } catch (error) {
      _log.warning("Couldn't reconnect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> _enableServices(BluetoothDevice device) async {
    if (Platform.isAndroid) {
      await device.requestMtu(512);
    }

    BrilliantDevice finalDevice = BrilliantDevice(
      device: device,
      state: BrilliantConnectionState.disconnected,
    );

    List<BluetoothService> services = await device.discoverServices();

    for (var service in services) {
      // If Frame
      if (service.serviceUuid == Guid('7a230001-5475-a6a4-654c-8431f6ad49c4')) {
        _log.fine("Found Frame service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('7a230002-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame TX characteristic");
            finalDevice._txChannel = characteristic;
          }
          if (characteristic.characteristicUuid ==
              Guid('7a230003-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame RX characteristic");
            finalDevice._rxChannel = characteristic;

            await characteristic.setNotifyValue(true);
            _log.fine("Enabled RX notifications");

            finalDevice.maxStringLength = device.mtuNow - 3;
            finalDevice.maxDataLength = device.mtuNow - 4;
            _log.fine("Max string length: ${finalDevice.maxStringLength}");
            _log.fine("Max data length: ${finalDevice.maxDataLength}");
          }
        }
      }

      // If DFU
      if (service.serviceUuid == Guid('fe59')) {
        _log.fine("Found DFU service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('8ec90001-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU control characteristic");
            finalDevice._dfuControl = characteristic;
            await characteristic.setNotifyValue(true);
            _log.fine("Enabled DFU control notifications");
          }
          if (characteristic.characteristicUuid ==
              Guid('8ec90002-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU packet characteristic");
            finalDevice._dfuPacket = characteristic;
          }
        }
      }
    }

    if (finalDevice._txChannel != null && finalDevice._rxChannel != null) {
      finalDevice.state = BrilliantConnectionState.connected;
      return finalDevice;
    }

    if (finalDevice._dfuControl != null && finalDevice._dfuPacket != null) {
      finalDevice.state = BrilliantConnectionState.dfuConnected;
      return finalDevice;
    }

    throw ("Incomplete set of services found");
  }
}



----- Class: BrilliantDevice -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'dart:typed_data';
import 'package:archive/archive_io.dart';
import 'package:flutter_blue_plus/flutter_blue_plus.dart';
import 'package:flutter/services.dart';
import 'package:logging/logging.dart';

final _log = Logger("Bluetooth");

class BrilliantBluetoothException implements Exception {
  final String msg;
  const BrilliantBluetoothException(this.msg);
  @override
  String toString() => 'BrilliantBluetoothException: $msg';
}

enum BrilliantConnectionState {
  connected,
  dfuConnected,
  disconnected,
}

class BrilliantScannedDevice {
  BluetoothDevice device;
  int? rssi;

  BrilliantScannedDevice({
    required this.device,
    required this.rssi,
  });
}

class BrilliantDevice {
  BluetoothDevice device;
  BrilliantConnectionState state;
  int? maxStringLength;
  int? maxDataLength;

  BluetoothCharacteristic? _txChannel;
  BluetoothCharacteristic? _rxChannel;
  BluetoothCharacteristic? _dfuControl;
  BluetoothCharacteristic? _dfuPacket;

  BrilliantDevice({
    required this.state,
    required this.device,
    this.maxStringLength,
    this.maxDataLength,
  });

  Stream<BrilliantDevice> get connectionState {
    return FlutterBluePlus.events.onConnectionStateChanged
        .where((event) =>
            event.connectionState == BluetoothConnectionState.connected ||
            (event.connectionState == BluetoothConnectionState.disconnected &&
                event.device.disconnectReason != null &&
                event.device.disconnectReason!.code != 23789258))
        .asyncMap((event) async {
      if (event.connectionState == BluetoothConnectionState.connected) {
        _log.info("Connection state stream: Connected");
        try {
          return await BrilliantBluetooth._enableServices(event.device);
        } catch (error) {
          _log.warning("Connection state stream: Invalid due to $error");
          return Future.error(BrilliantBluetoothException(error.toString()));
        }
      }
      _log.info(
          "Connection state stream: Disconnected due to ${event.device.disconnectReason!.description}");
      if (Platform.isAndroid) {
        event.device.connect(timeout: const Duration(days: 365));
      }
      return BrilliantDevice(
        state: BrilliantConnectionState.disconnected,
        device: event.device,
      );
    });
  }

  Stream<String> get stringResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] != 0x01)
        .map((event) {
      if (event.value[0] != 0x02) {
        _log.info("Received string: ${utf8.decode(event.value)}");
      }
      return utf8.decode(event.value);
    });
  }

  Stream<List<int>> get dataResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] == 0x01)
        .map((event) {
      _log.fine("Received data: ${event.value.sublist(1)}");
      return event.value.sublist(1);
    });
  }

  Future<void> disconnect() async {
    _log.info("Disconnecting");
    try {
      await device.disconnect();
    } catch (_) {}
  }

  Future<void> sendBreakSignal() async {
    _log.info("Sending break signal");
    await sendString("\x03", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<void> sendResetSignal() async {
    _log.info("Sending reset signal");
    await sendString("\x04", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<String?> sendString(
    String string, {
    bool awaitResponse = true,
    bool log = true,
  }) async {
    try {
      if (log) {
        _log.info("Sending string: $string");
      }

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (string.length > maxStringLength!) {
        throw ("Payload exceeds allowed length of $maxStringLength");
      }

      await _txChannel!.write(utf8.encode(string), withoutResponse: true);

      if (awaitResponse == false) {
        return null;
      }

      final response = await _rxChannel!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return utf8.decode(response);
    } catch (error) {
      _log.warning("Couldn't send string. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> sendData(List<int> data) async {
    try {
      _log.info("Sending ${data.length} bytes of plain data");
      _log.fine(data);

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (data.length > maxDataLength!) {
        throw ("Payload exceeds allowed length of $maxDataLength");
      }

      var finalData = data.toList()..insert(0, 0x01);

      await _txChannel!.write(finalData, withoutResponse: true);
    } catch (error) {
      _log.warning("Couldn't send data. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> uploadScript(String fileName, String filePath) async {
    try {
      _log.info("Uploading script: $fileName");

      String file = await rootBundle.loadString(filePath);

      file = file.replaceAll('\\', '\\\\');
      file = file.replaceAll("\r\n", "\\n");
      file = file.replaceAll("\n", "\\n");
      file = file.replaceAll("'", "\\'");
      file = file.replaceAll('"', '\\"');

      var resp = await sendString(
          "f=frame.file.open('$fileName', 'w');print('\x02')",
          log: false);

      if (resp != "\x02") {
        throw ("Error opening file: $resp");
      }

      int index = 0;
      int chunkSize = maxStringLength! - 22;

      while (index < file.length) {
        // Don't go over the end of the string
        if (index + chunkSize > file.length) {
          chunkSize = file.length - index;
        }

        // Don't split on an escape character
        while (file[index + chunkSize - 1] == '\\') {
          chunkSize -= 1;
        }

        String chunk = file.substring(index, index + chunkSize);

        resp = await sendString("f:write('$chunk');print('\x02')", log: false);

        if (resp != "\x02") {
          throw ("Error writing file: $resp");
        }

        index += chunkSize;
      }

      resp = await sendString("f:close();print('\x02')", log: false);

      if (resp != "\x02") {
        throw ("Error closing file: $resp");
      }
    } catch (error) {
      _log.warning("Couldn't upload script. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> updateFirmware(String filePath) async* {
    try {
      yield 0;

      _log.info("Starting firmware update");

      if (state != BrilliantConnectionState.dfuConnected) {
        throw ("DFU device is not connected");
      }

      if (_dfuControl == null || _dfuPacket == null) {
        throw ("Device is not in DFU mode");
      }

      final updateZipFile = await rootBundle.load(filePath);
      final zip = ZipDecoder().decodeBytes(updateZipFile.buffer.asUint8List());

      final initFile = zip.firstWhere((file) => file.name.endsWith(".dat"));
      final imageFile = zip.firstWhere((file) => file.name.endsWith(".bin"));

      await for (var _ in _transferDfuFile(initFile.content, true)) {}
      await Future.delayed(const Duration(milliseconds: 500));
      await for (var value in _transferDfuFile(imageFile.content, false)) {
        yield value;
      }

      _log.info("Firmware update completed");
    } catch (error) {
      _log.warning("Couldn't complete firmware update. $error");
      yield* Stream.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> _transferDfuFile(Uint8List file, bool isInitFile) async* {
    Uint8List response;

    try {
      if (isInitFile) {
        _log.fine("Uploading DFU init file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x01]));
      } else {
        _log.fine("Uploading DFU image file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x02]));
      }
    } catch (_) {
      throw ("Couldn't create DFU file on device");
    }

    final maxSize = ByteData.view(response.buffer).getUint32(3, Endian.little);
    var offset = ByteData.view(response.buffer).getUint32(7, Endian.little);
    final crc = ByteData.view(response.buffer).getUint32(11, Endian.little);

    _log.fine("Received allowed size: $maxSize, offset: $offset, CRC: $crc");

    while (offset < file.length) {
      final chunkSize = min(maxSize, file.length - offset);
      final chunkCrc = getCrc32(file.sublist(0, offset + chunkSize));

      // Create command with size
      final chunkSizeAsBytes = [
        chunkSize & 0xFF,
        chunkSize >> 8 & 0xFF,
        chunkSize >> 16 & 0xff,
        chunkSize >> 24 & 0xff
      ];

      try {
        if (isInitFile) {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x01, ...chunkSizeAsBytes]));
        } else {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x02, ...chunkSizeAsBytes]));
        }
      } catch (_) {
        throw ("Couldn't issue DFU create command");
      }

      // Split chunk into packets of MTU size
      final packetSize = device.mtuNow - 3;
      final packets = (chunkSize / packetSize).ceil();

      for (var p = 0; p < packets; p++) {
        final fileStart = offset + p * packetSize;
        var fileEnd = fileStart + packetSize;

        // The last packet could be smaller
        if (fileEnd - offset > maxSize) {
          fileEnd -= fileEnd - offset - maxSize;
        }

        // The last part of the file could also be smaller
        if (fileEnd > file.length) {
          fileEnd = file.length;
        }

        final fileSlice = file.sublist(fileStart, fileEnd);

        final percentDone = (100 / file.length) * offset;
        yield percentDone;

        _log.fine(
            "Sending ${fileSlice.length} bytes of packet data. ${percentDone.toInt()}% Complete");

        await _dfuSendPacketData(fileSlice)
            .onError((_, __) => throw ("Couldn't send DFU data"));
      }

      // Calculate CRC
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x03]));
      } catch (_) {
        throw ("Couldn't get CRC from device");
      }
      offset = ByteData.view(response.buffer).getUint32(3, Endian.little);
      final returnedCrc =
          ByteData.view(response.buffer).getUint32(7, Endian.little);

      if (returnedCrc != chunkCrc) {
        throw ("CRC mismatch after sending this chunk");
      }

      // Execute command (The last command may disconnect which is normal)
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x04]));
      } catch (_) {}
    }

    _log.fine("DFU file sent");
  }

  Future<Uint8List> _dfuSendControlData(Uint8List data) async {
    try {
      _log.fine("Sending ${data.length} bytes of DFU control data: $data");

      _dfuControl!.write(data, timeout: 1);

      final response = await _dfuControl!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return Uint8List.fromList(response);
    } catch (error) {
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> _dfuSendPacketData(Uint8List data) async {
    await _dfuPacket!.write(data, withoutResponse: true);
  }
}

class BrilliantBluetooth {
  static Future<void> requestPermission() async {
    try {
      await FlutterBluePlus.startScan();
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't obtain Bluetooth permission. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Stream<BrilliantScannedDevice> scan() async* {
    try {
      _log.info("Starting to scan for devices");

      await FlutterBluePlus.startScan(
        withServices: [
          Guid('7a230001-5475-a6a4-654c-8431f6ad49c4'),
          Guid('fe59'),
        ],
        continuousUpdates: true,
        removeIfGone: const Duration(seconds: 2),
      );
    } catch (error) {
      _log.warning("Scanning failed. $error");
      throw BrilliantBluetoothException(error.toString());
    }

    yield* FlutterBluePlus.scanResults
        .where((results) => results.isNotEmpty)
        // TODO filter by name: "Frame", "Frame Update", "Monocle" & "DFUTarg"
        .map((results) {
      ScanResult nearestDevice = results[0];
      for (int i = 0; i < results.length; i++) {
        if (results[i].rssi > nearestDevice.rssi) {
          nearestDevice = results[i];
        }
      }

      _log.fine(
          "Found ${nearestDevice.device.advName} rssi: ${nearestDevice.rssi}");

      return BrilliantScannedDevice(
        device: nearestDevice.device,
        rssi: nearestDevice.rssi,
      );
    });
  }

  static Future<void> stopScan() async {
    try {
      _log.info("Stopping scan for devices");
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't stop scanning. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> connect(BrilliantScannedDevice scanned) async {
    try {
      _log.info("Connecting");

      await FlutterBluePlus.stopScan();

      await scanned.device.connect(
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      );

      final connectionState = await scanned.device.connectionState
          .firstWhere((event) => event == BluetoothConnectionState.connected)
          .timeout(const Duration(seconds: 3));

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(scanned.device);
      }

      throw ("${scanned.device.disconnectReason?.description}");
    } catch (error) {
      await scanned.device.disconnect();
      _log.warning("Couldn't connect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> reconnect(String uuid) async {
    try {
      _log.info("Will re-connect to device: $uuid once found");

      BluetoothDevice device = BluetoothDevice.fromId(uuid);

      await device.connect(
        timeout: const Duration(days: 365),
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      ); // TODO Should wait but it throws an error on Android after some time

      final connectionState = await device.connectionState.firstWhere((state) =>
          state == BluetoothConnectionState.connected ||
          (state == BluetoothConnectionState.disconnected &&
              device.disconnectReason != null));

      _log.info("Found reconnectable device: $uuid");

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(device);
      }

      throw ("${device.disconnectReason?.description}");
    } catch (error) {
      _log.warning("Couldn't reconnect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> _enableServices(BluetoothDevice device) async {
    if (Platform.isAndroid) {
      await device.requestMtu(512);
    }

    BrilliantDevice finalDevice = BrilliantDevice(
      device: device,
      state: BrilliantConnectionState.disconnected,
    );

    List<BluetoothService> services = await device.discoverServices();

    for (var service in services) {
      // If Frame
      if (service.serviceUuid == Guid('7a230001-5475-a6a4-654c-8431f6ad49c4')) {
        _log.fine("Found Frame service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('7a230002-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame TX characteristic");
            finalDevice._txChannel = characteristic;
          }
          if (characteristic.characteristicUuid ==
              Guid('7a230003-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame RX characteristic");
            finalDevice._rxChannel = characteristic;

            await characteristic.setNotifyValue(true);
            _log.fine("Enabled RX notifications");

            finalDevice.maxStringLength = device.mtuNow - 3;
            finalDevice.maxDataLength = device.mtuNow - 4;
            _log.fine("Max string length: ${finalDevice.maxStringLength}");
            _log.fine("Max data length: ${finalDevice.maxDataLength}");
          }
        }
      }

      // If DFU
      if (service.serviceUuid == Guid('fe59')) {
        _log.fine("Found DFU service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('8ec90001-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU control characteristic");
            finalDevice._dfuControl = characteristic;
            await characteristic.setNotifyValue(true);
            _log.fine("Enabled DFU control notifications");
          }
          if (characteristic.characteristicUuid ==
              Guid('8ec90002-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU packet characteristic");
            finalDevice._dfuPacket = characteristic;
          }
        }
      }
    }

    if (finalDevice._txChannel != null && finalDevice._rxChannel != null) {
      finalDevice.state = BrilliantConnectionState.connected;
      return finalDevice;
    }

    if (finalDevice._dfuControl != null && finalDevice._dfuPacket != null) {
      finalDevice.state = BrilliantConnectionState.dfuConnected;
      return finalDevice;
    }

    throw ("Incomplete set of services found");
  }
}



----- Class: BrilliantBluetooth -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'dart:math';
import 'dart:typed_data';
import 'package:archive/archive_io.dart';
import 'package:flutter_blue_plus/flutter_blue_plus.dart';
import 'package:flutter/services.dart';
import 'package:logging/logging.dart';

final _log = Logger("Bluetooth");

class BrilliantBluetoothException implements Exception {
  final String msg;
  const BrilliantBluetoothException(this.msg);
  @override
  String toString() => 'BrilliantBluetoothException: $msg';
}

enum BrilliantConnectionState {
  connected,
  dfuConnected,
  disconnected,
}

class BrilliantScannedDevice {
  BluetoothDevice device;
  int? rssi;

  BrilliantScannedDevice({
    required this.device,
    required this.rssi,
  });
}

class BrilliantDevice {
  BluetoothDevice device;
  BrilliantConnectionState state;
  int? maxStringLength;
  int? maxDataLength;

  BluetoothCharacteristic? _txChannel;
  BluetoothCharacteristic? _rxChannel;
  BluetoothCharacteristic? _dfuControl;
  BluetoothCharacteristic? _dfuPacket;

  BrilliantDevice({
    required this.state,
    required this.device,
    this.maxStringLength,
    this.maxDataLength,
  });

  Stream<BrilliantDevice> get connectionState {
    return FlutterBluePlus.events.onConnectionStateChanged
        .where((event) =>
            event.connectionState == BluetoothConnectionState.connected ||
            (event.connectionState == BluetoothConnectionState.disconnected &&
                event.device.disconnectReason != null &&
                event.device.disconnectReason!.code != 23789258))
        .asyncMap((event) async {
      if (event.connectionState == BluetoothConnectionState.connected) {
        _log.info("Connection state stream: Connected");
        try {
          return await BrilliantBluetooth._enableServices(event.device);
        } catch (error) {
          _log.warning("Connection state stream: Invalid due to $error");
          return Future.error(BrilliantBluetoothException(error.toString()));
        }
      }
      _log.info(
          "Connection state stream: Disconnected due to ${event.device.disconnectReason!.description}");
      if (Platform.isAndroid) {
        event.device.connect(timeout: const Duration(days: 365));
      }
      return BrilliantDevice(
        state: BrilliantConnectionState.disconnected,
        device: event.device,
      );
    });
  }

  Stream<String> get stringResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] != 0x01)
        .map((event) {
      if (event.value[0] != 0x02) {
        _log.info("Received string: ${utf8.decode(event.value)}");
      }
      return utf8.decode(event.value);
    });
  }

  Stream<List<int>> get dataResponse {
    return FlutterBluePlus.events.onCharacteristicReceived
        .where((event) => event.value[0] == 0x01)
        .map((event) {
      _log.fine("Received data: ${event.value.sublist(1)}");
      return event.value.sublist(1);
    });
  }

  Future<void> disconnect() async {
    _log.info("Disconnecting");
    try {
      await device.disconnect();
    } catch (_) {}
  }

  Future<void> sendBreakSignal() async {
    _log.info("Sending break signal");
    await sendString("\x03", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<void> sendResetSignal() async {
    _log.info("Sending reset signal");
    await sendString("\x04", awaitResponse: false, log: false);
    await Future.delayed(const Duration(milliseconds: 100));
  }

  Future<String?> sendString(
    String string, {
    bool awaitResponse = true,
    bool log = true,
  }) async {
    try {
      if (log) {
        _log.info("Sending string: $string");
      }

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (string.length > maxStringLength!) {
        throw ("Payload exceeds allowed length of $maxStringLength");
      }

      await _txChannel!.write(utf8.encode(string), withoutResponse: true);

      if (awaitResponse == false) {
        return null;
      }

      final response = await _rxChannel!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return utf8.decode(response);
    } catch (error) {
      _log.warning("Couldn't send string. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> sendData(List<int> data) async {
    try {
      _log.info("Sending ${data.length} bytes of plain data");
      _log.fine(data);

      if (state != BrilliantConnectionState.connected) {
        throw ("Device is not connected");
      }

      if (data.length > maxDataLength!) {
        throw ("Payload exceeds allowed length of $maxDataLength");
      }

      var finalData = data.toList()..insert(0, 0x01);

      await _txChannel!.write(finalData, withoutResponse: true);
    } catch (error) {
      _log.warning("Couldn't send data. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> uploadScript(String fileName, String filePath) async {
    try {
      _log.info("Uploading script: $fileName");

      String file = await rootBundle.loadString(filePath);

      file = file.replaceAll('\\', '\\\\');
      file = file.replaceAll("\r\n", "\\n");
      file = file.replaceAll("\n", "\\n");
      file = file.replaceAll("'", "\\'");
      file = file.replaceAll('"', '\\"');

      var resp = await sendString(
          "f=frame.file.open('$fileName', 'w');print('\x02')",
          log: false);

      if (resp != "\x02") {
        throw ("Error opening file: $resp");
      }

      int index = 0;
      int chunkSize = maxStringLength! - 22;

      while (index < file.length) {
        // Don't go over the end of the string
        if (index + chunkSize > file.length) {
          chunkSize = file.length - index;
        }

        // Don't split on an escape character
        while (file[index + chunkSize - 1] == '\\') {
          chunkSize -= 1;
        }

        String chunk = file.substring(index, index + chunkSize);

        resp = await sendString("f:write('$chunk');print('\x02')", log: false);

        if (resp != "\x02") {
          throw ("Error writing file: $resp");
        }

        index += chunkSize;
      }

      resp = await sendString("f:close();print('\x02')", log: false);

      if (resp != "\x02") {
        throw ("Error closing file: $resp");
      }
    } catch (error) {
      _log.warning("Couldn't upload script. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> updateFirmware(String filePath) async* {
    try {
      yield 0;

      _log.info("Starting firmware update");

      if (state != BrilliantConnectionState.dfuConnected) {
        throw ("DFU device is not connected");
      }

      if (_dfuControl == null || _dfuPacket == null) {
        throw ("Device is not in DFU mode");
      }

      final updateZipFile = await rootBundle.load(filePath);
      final zip = ZipDecoder().decodeBytes(updateZipFile.buffer.asUint8List());

      final initFile = zip.firstWhere((file) => file.name.endsWith(".dat"));
      final imageFile = zip.firstWhere((file) => file.name.endsWith(".bin"));

      await for (var _ in _transferDfuFile(initFile.content, true)) {}
      await Future.delayed(const Duration(milliseconds: 500));
      await for (var value in _transferDfuFile(imageFile.content, false)) {
        yield value;
      }

      _log.info("Firmware update completed");
    } catch (error) {
      _log.warning("Couldn't complete firmware update. $error");
      yield* Stream.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Stream<double> _transferDfuFile(Uint8List file, bool isInitFile) async* {
    Uint8List response;

    try {
      if (isInitFile) {
        _log.fine("Uploading DFU init file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x01]));
      } else {
        _log.fine("Uploading DFU image file. Size: ${file.length}");
        response = await _dfuSendControlData(Uint8List.fromList([0x06, 0x02]));
      }
    } catch (_) {
      throw ("Couldn't create DFU file on device");
    }

    final maxSize = ByteData.view(response.buffer).getUint32(3, Endian.little);
    var offset = ByteData.view(response.buffer).getUint32(7, Endian.little);
    final crc = ByteData.view(response.buffer).getUint32(11, Endian.little);

    _log.fine("Received allowed size: $maxSize, offset: $offset, CRC: $crc");

    while (offset < file.length) {
      final chunkSize = min(maxSize, file.length - offset);
      final chunkCrc = getCrc32(file.sublist(0, offset + chunkSize));

      // Create command with size
      final chunkSizeAsBytes = [
        chunkSize & 0xFF,
        chunkSize >> 8 & 0xFF,
        chunkSize >> 16 & 0xff,
        chunkSize >> 24 & 0xff
      ];

      try {
        if (isInitFile) {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x01, ...chunkSizeAsBytes]));
        } else {
          await _dfuSendControlData(
              Uint8List.fromList([0x01, 0x02, ...chunkSizeAsBytes]));
        }
      } catch (_) {
        throw ("Couldn't issue DFU create command");
      }

      // Split chunk into packets of MTU size
      final packetSize = device.mtuNow - 3;
      final packets = (chunkSize / packetSize).ceil();

      for (var p = 0; p < packets; p++) {
        final fileStart = offset + p * packetSize;
        var fileEnd = fileStart + packetSize;

        // The last packet could be smaller
        if (fileEnd - offset > maxSize) {
          fileEnd -= fileEnd - offset - maxSize;
        }

        // The last part of the file could also be smaller
        if (fileEnd > file.length) {
          fileEnd = file.length;
        }

        final fileSlice = file.sublist(fileStart, fileEnd);

        final percentDone = (100 / file.length) * offset;
        yield percentDone;

        _log.fine(
            "Sending ${fileSlice.length} bytes of packet data. ${percentDone.toInt()}% Complete");

        await _dfuSendPacketData(fileSlice)
            .onError((_, __) => throw ("Couldn't send DFU data"));
      }

      // Calculate CRC
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x03]));
      } catch (_) {
        throw ("Couldn't get CRC from device");
      }
      offset = ByteData.view(response.buffer).getUint32(3, Endian.little);
      final returnedCrc =
          ByteData.view(response.buffer).getUint32(7, Endian.little);

      if (returnedCrc != chunkCrc) {
        throw ("CRC mismatch after sending this chunk");
      }

      // Execute command (The last command may disconnect which is normal)
      try {
        response = await _dfuSendControlData(Uint8List.fromList([0x04]));
      } catch (_) {}
    }

    _log.fine("DFU file sent");
  }

  Future<Uint8List> _dfuSendControlData(Uint8List data) async {
    try {
      _log.fine("Sending ${data.length} bytes of DFU control data: $data");

      _dfuControl!.write(data, timeout: 1);

      final response = await _dfuControl!.onValueReceived
          .timeout(const Duration(seconds: 1))
          .first;

      return Uint8List.fromList(response);
    } catch (error) {
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  Future<void> _dfuSendPacketData(Uint8List data) async {
    await _dfuPacket!.write(data, withoutResponse: true);
  }
}

class BrilliantBluetooth {
  static Future<void> requestPermission() async {
    try {
      await FlutterBluePlus.startScan();
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't obtain Bluetooth permission. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Stream<BrilliantScannedDevice> scan() async* {
    try {
      _log.info("Starting to scan for devices");

      await FlutterBluePlus.startScan(
        withServices: [
          Guid('7a230001-5475-a6a4-654c-8431f6ad49c4'),
          Guid('fe59'),
        ],
        continuousUpdates: true,
        removeIfGone: const Duration(seconds: 2),
      );
    } catch (error) {
      _log.warning("Scanning failed. $error");
      throw BrilliantBluetoothException(error.toString());
    }

    yield* FlutterBluePlus.scanResults
        .where((results) => results.isNotEmpty)
        // TODO filter by name: "Frame", "Frame Update", "Monocle" & "DFUTarg"
        .map((results) {
      ScanResult nearestDevice = results[0];
      for (int i = 0; i < results.length; i++) {
        if (results[i].rssi > nearestDevice.rssi) {
          nearestDevice = results[i];
        }
      }

      _log.fine(
          "Found ${nearestDevice.device.advName} rssi: ${nearestDevice.rssi}");

      return BrilliantScannedDevice(
        device: nearestDevice.device,
        rssi: nearestDevice.rssi,
      );
    });
  }

  static Future<void> stopScan() async {
    try {
      _log.info("Stopping scan for devices");
      await FlutterBluePlus.stopScan();
    } catch (error) {
      _log.warning("Couldn't stop scanning. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> connect(BrilliantScannedDevice scanned) async {
    try {
      _log.info("Connecting");

      await FlutterBluePlus.stopScan();

      await scanned.device.connect(
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      );

      final connectionState = await scanned.device.connectionState
          .firstWhere((event) => event == BluetoothConnectionState.connected)
          .timeout(const Duration(seconds: 3));

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(scanned.device);
      }

      throw ("${scanned.device.disconnectReason?.description}");
    } catch (error) {
      await scanned.device.disconnect();
      _log.warning("Couldn't connect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> reconnect(String uuid) async {
    try {
      _log.info("Will re-connect to device: $uuid once found");

      BluetoothDevice device = BluetoothDevice.fromId(uuid);

      await device.connect(
        timeout: const Duration(days: 365),
        autoConnect: Platform.isIOS ? true : false,
        mtu: null,
      ); // TODO Should wait but it throws an error on Android after some time

      final connectionState = await device.connectionState.firstWhere((state) =>
          state == BluetoothConnectionState.connected ||
          (state == BluetoothConnectionState.disconnected &&
              device.disconnectReason != null));

      _log.info("Found reconnectable device: $uuid");

      if (connectionState == BluetoothConnectionState.connected) {
        return await _enableServices(device);
      }

      throw ("${device.disconnectReason?.description}");
    } catch (error) {
      _log.warning("Couldn't reconnect. $error");
      return Future.error(BrilliantBluetoothException(error.toString()));
    }
  }

  static Future<BrilliantDevice> _enableServices(BluetoothDevice device) async {
    if (Platform.isAndroid) {
      await device.requestMtu(512);
    }

    BrilliantDevice finalDevice = BrilliantDevice(
      device: device,
      state: BrilliantConnectionState.disconnected,
    );

    List<BluetoothService> services = await device.discoverServices();

    for (var service in services) {
      // If Frame
      if (service.serviceUuid == Guid('7a230001-5475-a6a4-654c-8431f6ad49c4')) {
        _log.fine("Found Frame service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('7a230002-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame TX characteristic");
            finalDevice._txChannel = characteristic;
          }
          if (characteristic.characteristicUuid ==
              Guid('7a230003-5475-a6a4-654c-8431f6ad49c4')) {
            _log.fine("Found Frame RX characteristic");
            finalDevice._rxChannel = characteristic;

            await characteristic.setNotifyValue(true);
            _log.fine("Enabled RX notifications");

            finalDevice.maxStringLength = device.mtuNow - 3;
            finalDevice.maxDataLength = device.mtuNow - 4;
            _log.fine("Max string length: ${finalDevice.maxStringLength}");
            _log.fine("Max data length: ${finalDevice.maxDataLength}");
          }
        }
      }

      // If DFU
      if (service.serviceUuid == Guid('fe59')) {
        _log.fine("Found DFU service");
        for (var characteristic in service.characteristics) {
          if (characteristic.characteristicUuid ==
              Guid('8ec90001-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU control characteristic");
            finalDevice._dfuControl = characteristic;
            await characteristic.setNotifyValue(true);
            _log.fine("Enabled DFU control notifications");
          }
          if (characteristic.characteristicUuid ==
              Guid('8ec90002-f315-4f60-9fb8-838830daea50')) {
            _log.fine("Found DFU packet characteristic");
            finalDevice._dfuPacket = characteristic;
          }
        }
      }
    }

    if (finalDevice._txChannel != null && finalDevice._rxChannel != null) {
      finalDevice.state = BrilliantConnectionState.connected;
      return finalDevice;
    }

    if (finalDevice._dfuControl != null && finalDevice._dfuPacket != null) {
      finalDevice.state = BrilliantConnectionState.dfuConnected;
      return finalDevice;
    }

    throw ("Incomplete set of services found");
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\main.dart =====
----- Class: MainApp -----
import 'package:audio_session/audio_session.dart';
import 'package:flutter_dotenv/flutter_dotenv.dart';
import 'package:flutter_foreground_task/flutter_foreground_task.dart';
import 'package:flutter_riverpod/flutter_riverpod.dart';
import 'package:flutter/material.dart';
import 'package:noa/bluetooth.dart';
import 'package:noa/pages/splash.dart';
import 'package:noa/util/app_log.dart';
import 'package:noa/util/foreground_service.dart';
import 'package:noa/util/location.dart';

final globalPageStorageBucket = PageStorageBucket();

void main() async {
  // Load environment variables
  await dotenv.load();

  // Start logging
  final container = ProviderContainer();
  container.read(appLog);

  // Set up Android foreground service
  initializeForegroundService();

  // Request bluetooth permission
  BrilliantBluetooth.requestPermission();

  // Start location stream
  Location.startLocationStream();
  
  _setupAudioSession();

  runApp(UncontrolledProviderScope(
    container: container,
    child: const MainApp(),
  ));
}

void _setupAudioSession() {
  AudioSession.instance.then((audioSession) async {
    await audioSession.configure(const AudioSessionConfiguration(
      avAudioSessionCategory: AVAudioSessionCategory.playback,
      avAudioSessionCategoryOptions:
          AVAudioSessionCategoryOptions.mixWithOthers,
      avAudioSessionMode: AVAudioSessionMode.spokenAudio,
      avAudioSessionRouteSharingPolicy:
          AVAudioSessionRouteSharingPolicy.defaultPolicy,
      avAudioSessionSetActiveOptions: AVAudioSessionSetActiveOptions.none,
      androidAudioAttributes: AndroidAudioAttributes(
        contentType: AndroidAudioContentType.speech,
        flags: AndroidAudioFlags.none,
        usage: AndroidAudioUsage.assistant,
      ),
      androidAudioFocusGainType: AndroidAudioFocusGainType.gain,
      androidWillPauseWhenDucked: true,
    ));
    audioSession.setActive(true);
  });
}

class MainApp extends StatelessWidget {
  const MainApp({super.key});

  @override
  Widget build(BuildContext context) {
    startForegroundService();
    return const WithForegroundTask(
        child: MaterialApp(
      debugShowCheckedModeBanner: false,
      home: SplashPage(),
    ));
  }
}





===== File: C:\Users\jonat\OneDrive\Desktop\ar_project\Ar-Frame-Control\lib\deps\noa-flutter-main\lib\noa_api.dart =====
----- Class: NoaApiServerException -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:image/image.dart';
import 'package:just_audio/just_audio.dart';
import 'package:logging/logging.dart';
import 'package:noa/util/bytes_to_wav.dart';
import 'package:noa/util/location.dart';
import 'package:path_provider/path_provider.dart';

final _log = Logger("Noa API");

class NoaApiServerException implements Exception {
  String reason;
  int statusCode;

  NoaApiServerException({
    required this.reason,
    required this.statusCode,
  });

  @override
  String toString() {
    return "NoaApiServerException: $statusCode: $reason";
  }
}

enum NoaApiAuthProvider {
  google('google'),
  apple('apple'),
  discord('discord');

  const NoaApiAuthProvider(this.value);
  final String value;
}

class NoaUser {
  late String email;
  late String plan;
  late int creditsUsed;
  late int maxCredits;

  NoaUser({
    String? email,
    String? plan,
    int? creditsUsed,
    int? maxCredits,
  }) {
    this.email = email ?? "Not logged in";
    this.plan = plan ?? "";
    this.creditsUsed = creditsUsed ?? 0;
    this.maxCredits = maxCredits ?? 0;
  }
}

// Noa messaging class
enum NoaRole {
  system('system'),
  user('user'),
  noa('noa');

  const NoaRole(this.value);
  final String value;
}

class NoaMessage {
  String message;
  NoaRole from;
  DateTime time;
  Uint8List? image;
  bool exclude = false;
  bool topicChanged = false;

  NoaMessage({
    required this.message,
    required this.from,
    required this.time,
    this.image,
    this.exclude = false,
    this.topicChanged = false,
  });

  Map<String, dynamic> toJson() {
    return {
      "role": from == NoaRole.noa ? "assistant" : "user",
      "content": message,
    };
  }
}

// All API endpoint features
class NoaApi {
  static Future<String> signIn(
    String id,
    NoaApiAuthProvider provider,
  ) async {
    _log.info("Signing in to Noa");
    _log.fine("Provider: $provider, ID token: $id");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signin'),
        body: {
          'id_token': id,
          'provider': provider.value,
        },
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final decoded = jsonDecode(response.body);

      return decoded['token'];
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> signOut(
    String userAuthToken,
  ) async {
    _log.info("Signing out");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signout'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<NoaUser> getUser(String userAuthToken) async {
    _log.info("Getting user info");
    try {
      final response = await http.get(
        Uri.parse('https://api.brilliant.xyz/noa/user'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final body = jsonDecode(response.body);
      final email = body['user']['email'];
      final plan = body['user']['plan'];
      final creditsUsed = body['user']['credit_used'];
      final maxCredits = body['user']['credit_total'];

      _log.info(
          "Got user account info: Email: $email, plan: $plan, credits: $creditsUsed/$maxCredits");

      return NoaUser(
        email: email,
        plan: plan,
        creditsUsed: creditsUsed,
        maxCredits: maxCredits,
      );
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> deleteUser(
    String userAuthToken,
  ) async {
    _log.info("Deleting user");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/delete'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getMessage(
    String userAuthToken,
    Uint8List audio,
    Uint8List image,
    String systemRole,
    double temperature,
    List<NoaMessage> noaHistory,
    bool textToSpeech,
    String apiEndpoint,
    String apiToken,
    String apiHeader,
    bool isCustomServerEnabled,
    bool promptless,
  ) async {
    try {
      String endPoint = 'https://api.brilliant.xyz/noa';
      String token = userAuthToken;
      String header = "Authorization";

      if (apiEndpoint.isEmpty && isCustomServerEnabled) {
        throw NoaApiServerException(
          reason: "Custom server enabled but no endpoint provided",
          statusCode: 400,
        );
      }
      if (isCustomServerEnabled) {
        endPoint = apiEndpoint;
        token = apiToken;
        header = apiHeader;
      }
      
      var request = http.MultipartRequest(
        'POST',
        Uri.parse(endPoint),
      );

      request.headers.addAll({header: token});

      request.files.add(http.MultipartFile.fromBytes(
        'audio',
        bytesToWav(audio, 8, 8000),
        filename: 'audio.wav',
      ));

      try {
        image = encodeJpg(copyRotate(decodeJpg(image)!, angle: -90));

        request.files.add(http.MultipartFile.fromBytes(
          'image',
          image,
          filename: 'image.jpg',
        ));
      } catch (error) {
        _log.warning(error);
      }
      noaHistory = noaHistory.where((msg) => !msg.exclude).toList();
      if (!isCustomServerEnabled) {
        request.fields['noa_system_prompt'] = systemRole;
        request.fields['temperature'] = temperature.toString();
        request.fields['tts'] = textToSpeech ? "1" : "0";
        request.fields['promptless'] = promptless ? "1" : "0";
      }
      request.fields['messages'] = jsonEncode(noaHistory);
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();

      _log.info(
          "Sending message request: audio[${audio.length}], image[${image.length}], ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));
      List<NoaMessage> response = List.empty(growable: true);
      final topicChanged = body["debug"]['topic_changed']??false;

      response.add(NoaMessage(
        message: body['user_prompt'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.user,
        time: DateTime.now(),
        image: kReleaseMode ? null : image,
        topicChanged: topicChanged
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
        image: body['image'] != null ? base64.decode(body['image']) : null,
      ));

      _log.info(
          "Received response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getWildcardMessage(
    String userAuthToken,
    String systemRole,
    double temperature,
    bool textToSpeech,
  ) async {
    try {
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('https://api.brilliant.xyz/noa/wildcard'),
      );

      request.headers.addAll({HttpHeaders.authorizationHeader: userAuthToken});

      request.fields['noa_system_prompt'] = systemRole;
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();
      request.fields['temperature'] = temperature.toString();
      request.fields['tts'] = textToSpeech ? "1" : "0";

      _log.info("Sending wildcard request: ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));

      List<NoaMessage> response = List.empty(growable: true);

      response.add(NoaMessage(
        message: "Wildcard ",
        from: NoaRole.user,
        time: DateTime.now(),
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
      ));

      _log.info(
          "Received wildcard response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static void _playAudio(Uint8List audio) async {
    _log.info("Playing ${audio.length} bytes of audio");

    final tempDir = await getTemporaryDirectory();
    File file = await File('${tempDir.path}/audio.mp3').create();
    file.writeAsBytesSync(audio);

    try {
      AudioPlayer player = AudioPlayer(handleAudioSessionActivation: false);
      await player.setAudioSource(AudioSource.file(file.path));
      await player.play();
      await player.dispose();
    } catch (error) {
      _log.warning("Error playing audio. $error");
    }
  }
}


----- Class: NoaUser -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:image/image.dart';
import 'package:just_audio/just_audio.dart';
import 'package:logging/logging.dart';
import 'package:noa/util/bytes_to_wav.dart';
import 'package:noa/util/location.dart';
import 'package:path_provider/path_provider.dart';

final _log = Logger("Noa API");

class NoaApiServerException implements Exception {
  String reason;
  int statusCode;

  NoaApiServerException({
    required this.reason,
    required this.statusCode,
  });

  @override
  String toString() {
    return "NoaApiServerException: $statusCode: $reason";
  }
}

enum NoaApiAuthProvider {
  google('google'),
  apple('apple'),
  discord('discord');

  const NoaApiAuthProvider(this.value);
  final String value;
}

class NoaUser {
  late String email;
  late String plan;
  late int creditsUsed;
  late int maxCredits;

  NoaUser({
    String? email,
    String? plan,
    int? creditsUsed,
    int? maxCredits,
  }) {
    this.email = email ?? "Not logged in";
    this.plan = plan ?? "";
    this.creditsUsed = creditsUsed ?? 0;
    this.maxCredits = maxCredits ?? 0;
  }
}

// Noa messaging class
enum NoaRole {
  system('system'),
  user('user'),
  noa('noa');

  const NoaRole(this.value);
  final String value;
}

class NoaMessage {
  String message;
  NoaRole from;
  DateTime time;
  Uint8List? image;
  bool exclude = false;
  bool topicChanged = false;

  NoaMessage({
    required this.message,
    required this.from,
    required this.time,
    this.image,
    this.exclude = false,
    this.topicChanged = false,
  });

  Map<String, dynamic> toJson() {
    return {
      "role": from == NoaRole.noa ? "assistant" : "user",
      "content": message,
    };
  }
}

// All API endpoint features
class NoaApi {
  static Future<String> signIn(
    String id,
    NoaApiAuthProvider provider,
  ) async {
    _log.info("Signing in to Noa");
    _log.fine("Provider: $provider, ID token: $id");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signin'),
        body: {
          'id_token': id,
          'provider': provider.value,
        },
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final decoded = jsonDecode(response.body);

      return decoded['token'];
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> signOut(
    String userAuthToken,
  ) async {
    _log.info("Signing out");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signout'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<NoaUser> getUser(String userAuthToken) async {
    _log.info("Getting user info");
    try {
      final response = await http.get(
        Uri.parse('https://api.brilliant.xyz/noa/user'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final body = jsonDecode(response.body);
      final email = body['user']['email'];
      final plan = body['user']['plan'];
      final creditsUsed = body['user']['credit_used'];
      final maxCredits = body['user']['credit_total'];

      _log.info(
          "Got user account info: Email: $email, plan: $plan, credits: $creditsUsed/$maxCredits");

      return NoaUser(
        email: email,
        plan: plan,
        creditsUsed: creditsUsed,
        maxCredits: maxCredits,
      );
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> deleteUser(
    String userAuthToken,
  ) async {
    _log.info("Deleting user");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/delete'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getMessage(
    String userAuthToken,
    Uint8List audio,
    Uint8List image,
    String systemRole,
    double temperature,
    List<NoaMessage> noaHistory,
    bool textToSpeech,
    String apiEndpoint,
    String apiToken,
    String apiHeader,
    bool isCustomServerEnabled,
    bool promptless,
  ) async {
    try {
      String endPoint = 'https://api.brilliant.xyz/noa';
      String token = userAuthToken;
      String header = "Authorization";

      if (apiEndpoint.isEmpty && isCustomServerEnabled) {
        throw NoaApiServerException(
          reason: "Custom server enabled but no endpoint provided",
          statusCode: 400,
        );
      }
      if (isCustomServerEnabled) {
        endPoint = apiEndpoint;
        token = apiToken;
        header = apiHeader;
      }
      
      var request = http.MultipartRequest(
        'POST',
        Uri.parse(endPoint),
      );

      request.headers.addAll({header: token});

      request.files.add(http.MultipartFile.fromBytes(
        'audio',
        bytesToWav(audio, 8, 8000),
        filename: 'audio.wav',
      ));

      try {
        image = encodeJpg(copyRotate(decodeJpg(image)!, angle: -90));

        request.files.add(http.MultipartFile.fromBytes(
          'image',
          image,
          filename: 'image.jpg',
        ));
      } catch (error) {
        _log.warning(error);
      }
      noaHistory = noaHistory.where((msg) => !msg.exclude).toList();
      if (!isCustomServerEnabled) {
        request.fields['noa_system_prompt'] = systemRole;
        request.fields['temperature'] = temperature.toString();
        request.fields['tts'] = textToSpeech ? "1" : "0";
        request.fields['promptless'] = promptless ? "1" : "0";
      }
      request.fields['messages'] = jsonEncode(noaHistory);
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();

      _log.info(
          "Sending message request: audio[${audio.length}], image[${image.length}], ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));
      List<NoaMessage> response = List.empty(growable: true);
      final topicChanged = body["debug"]['topic_changed']??false;

      response.add(NoaMessage(
        message: body['user_prompt'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.user,
        time: DateTime.now(),
        image: kReleaseMode ? null : image,
        topicChanged: topicChanged
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
        image: body['image'] != null ? base64.decode(body['image']) : null,
      ));

      _log.info(
          "Received response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getWildcardMessage(
    String userAuthToken,
    String systemRole,
    double temperature,
    bool textToSpeech,
  ) async {
    try {
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('https://api.brilliant.xyz/noa/wildcard'),
      );

      request.headers.addAll({HttpHeaders.authorizationHeader: userAuthToken});

      request.fields['noa_system_prompt'] = systemRole;
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();
      request.fields['temperature'] = temperature.toString();
      request.fields['tts'] = textToSpeech ? "1" : "0";

      _log.info("Sending wildcard request: ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));

      List<NoaMessage> response = List.empty(growable: true);

      response.add(NoaMessage(
        message: "Wildcard ",
        from: NoaRole.user,
        time: DateTime.now(),
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
      ));

      _log.info(
          "Received wildcard response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static void _playAudio(Uint8List audio) async {
    _log.info("Playing ${audio.length} bytes of audio");

    final tempDir = await getTemporaryDirectory();
    File file = await File('${tempDir.path}/audio.mp3').create();
    file.writeAsBytesSync(audio);

    try {
      AudioPlayer player = AudioPlayer(handleAudioSessionActivation: false);
      await player.setAudioSource(AudioSource.file(file.path));
      await player.play();
      await player.dispose();
    } catch (error) {
      _log.warning("Error playing audio. $error");
    }
  }
}


----- Class: enum -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:image/image.dart';
import 'package:just_audio/just_audio.dart';
import 'package:logging/logging.dart';
import 'package:noa/util/bytes_to_wav.dart';
import 'package:noa/util/location.dart';
import 'package:path_provider/path_provider.dart';

final _log = Logger("Noa API");

class NoaApiServerException implements Exception {
  String reason;
  int statusCode;

  NoaApiServerException({
    required this.reason,
    required this.statusCode,
  });

  @override
  String toString() {
    return "NoaApiServerException: $statusCode: $reason";
  }
}

enum NoaApiAuthProvider {
  google('google'),
  apple('apple'),
  discord('discord');

  const NoaApiAuthProvider(this.value);
  final String value;
}

class NoaUser {
  late String email;
  late String plan;
  late int creditsUsed;
  late int maxCredits;

  NoaUser({
    String? email,
    String? plan,
    int? creditsUsed,
    int? maxCredits,
  }) {
    this.email = email ?? "Not logged in";
    this.plan = plan ?? "";
    this.creditsUsed = creditsUsed ?? 0;
    this.maxCredits = maxCredits ?? 0;
  }
}

// Noa messaging class
enum NoaRole {
  system('system'),
  user('user'),
  noa('noa');

  const NoaRole(this.value);
  final String value;
}

class NoaMessage {
  String message;
  NoaRole from;
  DateTime time;
  Uint8List? image;
  bool exclude = false;
  bool topicChanged = false;

  NoaMessage({
    required this.message,
    required this.from,
    required this.time,
    this.image,
    this.exclude = false,
    this.topicChanged = false,
  });

  Map<String, dynamic> toJson() {
    return {
      "role": from == NoaRole.noa ? "assistant" : "user",
      "content": message,
    };
  }
}

// All API endpoint features
class NoaApi {
  static Future<String> signIn(
    String id,
    NoaApiAuthProvider provider,
  ) async {
    _log.info("Signing in to Noa");
    _log.fine("Provider: $provider, ID token: $id");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signin'),
        body: {
          'id_token': id,
          'provider': provider.value,
        },
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final decoded = jsonDecode(response.body);

      return decoded['token'];
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> signOut(
    String userAuthToken,
  ) async {
    _log.info("Signing out");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signout'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<NoaUser> getUser(String userAuthToken) async {
    _log.info("Getting user info");
    try {
      final response = await http.get(
        Uri.parse('https://api.brilliant.xyz/noa/user'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final body = jsonDecode(response.body);
      final email = body['user']['email'];
      final plan = body['user']['plan'];
      final creditsUsed = body['user']['credit_used'];
      final maxCredits = body['user']['credit_total'];

      _log.info(
          "Got user account info: Email: $email, plan: $plan, credits: $creditsUsed/$maxCredits");

      return NoaUser(
        email: email,
        plan: plan,
        creditsUsed: creditsUsed,
        maxCredits: maxCredits,
      );
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> deleteUser(
    String userAuthToken,
  ) async {
    _log.info("Deleting user");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/delete'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getMessage(
    String userAuthToken,
    Uint8List audio,
    Uint8List image,
    String systemRole,
    double temperature,
    List<NoaMessage> noaHistory,
    bool textToSpeech,
    String apiEndpoint,
    String apiToken,
    String apiHeader,
    bool isCustomServerEnabled,
    bool promptless,
  ) async {
    try {
      String endPoint = 'https://api.brilliant.xyz/noa';
      String token = userAuthToken;
      String header = "Authorization";

      if (apiEndpoint.isEmpty && isCustomServerEnabled) {
        throw NoaApiServerException(
          reason: "Custom server enabled but no endpoint provided",
          statusCode: 400,
        );
      }
      if (isCustomServerEnabled) {
        endPoint = apiEndpoint;
        token = apiToken;
        header = apiHeader;
      }
      
      var request = http.MultipartRequest(
        'POST',
        Uri.parse(endPoint),
      );

      request.headers.addAll({header: token});

      request.files.add(http.MultipartFile.fromBytes(
        'audio',
        bytesToWav(audio, 8, 8000),
        filename: 'audio.wav',
      ));

      try {
        image = encodeJpg(copyRotate(decodeJpg(image)!, angle: -90));

        request.files.add(http.MultipartFile.fromBytes(
          'image',
          image,
          filename: 'image.jpg',
        ));
      } catch (error) {
        _log.warning(error);
      }
      noaHistory = noaHistory.where((msg) => !msg.exclude).toList();
      if (!isCustomServerEnabled) {
        request.fields['noa_system_prompt'] = systemRole;
        request.fields['temperature'] = temperature.toString();
        request.fields['tts'] = textToSpeech ? "1" : "0";
        request.fields['promptless'] = promptless ? "1" : "0";
      }
      request.fields['messages'] = jsonEncode(noaHistory);
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();

      _log.info(
          "Sending message request: audio[${audio.length}], image[${image.length}], ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));
      List<NoaMessage> response = List.empty(growable: true);
      final topicChanged = body["debug"]['topic_changed']??false;

      response.add(NoaMessage(
        message: body['user_prompt'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.user,
        time: DateTime.now(),
        image: kReleaseMode ? null : image,
        topicChanged: topicChanged
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
        image: body['image'] != null ? base64.decode(body['image']) : null,
      ));

      _log.info(
          "Received response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getWildcardMessage(
    String userAuthToken,
    String systemRole,
    double temperature,
    bool textToSpeech,
  ) async {
    try {
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('https://api.brilliant.xyz/noa/wildcard'),
      );

      request.headers.addAll({HttpHeaders.authorizationHeader: userAuthToken});

      request.fields['noa_system_prompt'] = systemRole;
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();
      request.fields['temperature'] = temperature.toString();
      request.fields['tts'] = textToSpeech ? "1" : "0";

      _log.info("Sending wildcard request: ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));

      List<NoaMessage> response = List.empty(growable: true);

      response.add(NoaMessage(
        message: "Wildcard ",
        from: NoaRole.user,
        time: DateTime.now(),
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
      ));

      _log.info(
          "Received wildcard response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static void _playAudio(Uint8List audio) async {
    _log.info("Playing ${audio.length} bytes of audio");

    final tempDir = await getTemporaryDirectory();
    File file = await File('${tempDir.path}/audio.mp3').create();
    file.writeAsBytesSync(audio);

    try {
      AudioPlayer player = AudioPlayer(handleAudioSessionActivation: false);
      await player.setAudioSource(AudioSource.file(file.path));
      await player.play();
      await player.dispose();
    } catch (error) {
      _log.warning("Error playing audio. $error");
    }
  }
}


----- Class: NoaMessage -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:image/image.dart';
import 'package:just_audio/just_audio.dart';
import 'package:logging/logging.dart';
import 'package:noa/util/bytes_to_wav.dart';
import 'package:noa/util/location.dart';
import 'package:path_provider/path_provider.dart';

final _log = Logger("Noa API");

class NoaApiServerException implements Exception {
  String reason;
  int statusCode;

  NoaApiServerException({
    required this.reason,
    required this.statusCode,
  });

  @override
  String toString() {
    return "NoaApiServerException: $statusCode: $reason";
  }
}

enum NoaApiAuthProvider {
  google('google'),
  apple('apple'),
  discord('discord');

  const NoaApiAuthProvider(this.value);
  final String value;
}

class NoaUser {
  late String email;
  late String plan;
  late int creditsUsed;
  late int maxCredits;

  NoaUser({
    String? email,
    String? plan,
    int? creditsUsed,
    int? maxCredits,
  }) {
    this.email = email ?? "Not logged in";
    this.plan = plan ?? "";
    this.creditsUsed = creditsUsed ?? 0;
    this.maxCredits = maxCredits ?? 0;
  }
}

// Noa messaging class
enum NoaRole {
  system('system'),
  user('user'),
  noa('noa');

  const NoaRole(this.value);
  final String value;
}

class NoaMessage {
  String message;
  NoaRole from;
  DateTime time;
  Uint8List? image;
  bool exclude = false;
  bool topicChanged = false;

  NoaMessage({
    required this.message,
    required this.from,
    required this.time,
    this.image,
    this.exclude = false,
    this.topicChanged = false,
  });

  Map<String, dynamic> toJson() {
    return {
      "role": from == NoaRole.noa ? "assistant" : "user",
      "content": message,
    };
  }
}

// All API endpoint features
class NoaApi {
  static Future<String> signIn(
    String id,
    NoaApiAuthProvider provider,
  ) async {
    _log.info("Signing in to Noa");
    _log.fine("Provider: $provider, ID token: $id");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signin'),
        body: {
          'id_token': id,
          'provider': provider.value,
        },
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final decoded = jsonDecode(response.body);

      return decoded['token'];
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> signOut(
    String userAuthToken,
  ) async {
    _log.info("Signing out");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signout'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<NoaUser> getUser(String userAuthToken) async {
    _log.info("Getting user info");
    try {
      final response = await http.get(
        Uri.parse('https://api.brilliant.xyz/noa/user'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final body = jsonDecode(response.body);
      final email = body['user']['email'];
      final plan = body['user']['plan'];
      final creditsUsed = body['user']['credit_used'];
      final maxCredits = body['user']['credit_total'];

      _log.info(
          "Got user account info: Email: $email, plan: $plan, credits: $creditsUsed/$maxCredits");

      return NoaUser(
        email: email,
        plan: plan,
        creditsUsed: creditsUsed,
        maxCredits: maxCredits,
      );
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> deleteUser(
    String userAuthToken,
  ) async {
    _log.info("Deleting user");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/delete'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getMessage(
    String userAuthToken,
    Uint8List audio,
    Uint8List image,
    String systemRole,
    double temperature,
    List<NoaMessage> noaHistory,
    bool textToSpeech,
    String apiEndpoint,
    String apiToken,
    String apiHeader,
    bool isCustomServerEnabled,
    bool promptless,
  ) async {
    try {
      String endPoint = 'https://api.brilliant.xyz/noa';
      String token = userAuthToken;
      String header = "Authorization";

      if (apiEndpoint.isEmpty && isCustomServerEnabled) {
        throw NoaApiServerException(
          reason: "Custom server enabled but no endpoint provided",
          statusCode: 400,
        );
      }
      if (isCustomServerEnabled) {
        endPoint = apiEndpoint;
        token = apiToken;
        header = apiHeader;
      }
      
      var request = http.MultipartRequest(
        'POST',
        Uri.parse(endPoint),
      );

      request.headers.addAll({header: token});

      request.files.add(http.MultipartFile.fromBytes(
        'audio',
        bytesToWav(audio, 8, 8000),
        filename: 'audio.wav',
      ));

      try {
        image = encodeJpg(copyRotate(decodeJpg(image)!, angle: -90));

        request.files.add(http.MultipartFile.fromBytes(
          'image',
          image,
          filename: 'image.jpg',
        ));
      } catch (error) {
        _log.warning(error);
      }
      noaHistory = noaHistory.where((msg) => !msg.exclude).toList();
      if (!isCustomServerEnabled) {
        request.fields['noa_system_prompt'] = systemRole;
        request.fields['temperature'] = temperature.toString();
        request.fields['tts'] = textToSpeech ? "1" : "0";
        request.fields['promptless'] = promptless ? "1" : "0";
      }
      request.fields['messages'] = jsonEncode(noaHistory);
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();

      _log.info(
          "Sending message request: audio[${audio.length}], image[${image.length}], ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));
      List<NoaMessage> response = List.empty(growable: true);
      final topicChanged = body["debug"]['topic_changed']??false;

      response.add(NoaMessage(
        message: body['user_prompt'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.user,
        time: DateTime.now(),
        image: kReleaseMode ? null : image,
        topicChanged: topicChanged
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
        image: body['image'] != null ? base64.decode(body['image']) : null,
      ));

      _log.info(
          "Received response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getWildcardMessage(
    String userAuthToken,
    String systemRole,
    double temperature,
    bool textToSpeech,
  ) async {
    try {
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('https://api.brilliant.xyz/noa/wildcard'),
      );

      request.headers.addAll({HttpHeaders.authorizationHeader: userAuthToken});

      request.fields['noa_system_prompt'] = systemRole;
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();
      request.fields['temperature'] = temperature.toString();
      request.fields['tts'] = textToSpeech ? "1" : "0";

      _log.info("Sending wildcard request: ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));

      List<NoaMessage> response = List.empty(growable: true);

      response.add(NoaMessage(
        message: "Wildcard ",
        from: NoaRole.user,
        time: DateTime.now(),
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
      ));

      _log.info(
          "Received wildcard response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static void _playAudio(Uint8List audio) async {
    _log.info("Playing ${audio.length} bytes of audio");

    final tempDir = await getTemporaryDirectory();
    File file = await File('${tempDir.path}/audio.mp3').create();
    file.writeAsBytesSync(audio);

    try {
      AudioPlayer player = AudioPlayer(handleAudioSessionActivation: false);
      await player.setAudioSource(AudioSource.file(file.path));
      await player.play();
      await player.dispose();
    } catch (error) {
      _log.warning("Error playing audio. $error");
    }
  }
}


----- Class: NoaApi -----
import 'dart:async';
import 'dart:convert';
import 'dart:io';
import 'package:flutter/foundation.dart';
import 'package:http/http.dart' as http;
import 'package:image/image.dart';
import 'package:just_audio/just_audio.dart';
import 'package:logging/logging.dart';
import 'package:noa/util/bytes_to_wav.dart';
import 'package:noa/util/location.dart';
import 'package:path_provider/path_provider.dart';

final _log = Logger("Noa API");

class NoaApiServerException implements Exception {
  String reason;
  int statusCode;

  NoaApiServerException({
    required this.reason,
    required this.statusCode,
  });

  @override
  String toString() {
    return "NoaApiServerException: $statusCode: $reason";
  }
}

enum NoaApiAuthProvider {
  google('google'),
  apple('apple'),
  discord('discord');

  const NoaApiAuthProvider(this.value);
  final String value;
}

class NoaUser {
  late String email;
  late String plan;
  late int creditsUsed;
  late int maxCredits;

  NoaUser({
    String? email,
    String? plan,
    int? creditsUsed,
    int? maxCredits,
  }) {
    this.email = email ?? "Not logged in";
    this.plan = plan ?? "";
    this.creditsUsed = creditsUsed ?? 0;
    this.maxCredits = maxCredits ?? 0;
  }
}

// Noa messaging class
enum NoaRole {
  system('system'),
  user('user'),
  noa('noa');

  const NoaRole(this.value);
  final String value;
}

class NoaMessage {
  String message;
  NoaRole from;
  DateTime time;
  Uint8List? image;
  bool exclude = false;
  bool topicChanged = false;

  NoaMessage({
    required this.message,
    required this.from,
    required this.time,
    this.image,
    this.exclude = false,
    this.topicChanged = false,
  });

  Map<String, dynamic> toJson() {
    return {
      "role": from == NoaRole.noa ? "assistant" : "user",
      "content": message,
    };
  }
}

// All API endpoint features
class NoaApi {
  static Future<String> signIn(
    String id,
    NoaApiAuthProvider provider,
  ) async {
    _log.info("Signing in to Noa");
    _log.fine("Provider: $provider, ID token: $id");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signin'),
        body: {
          'id_token': id,
          'provider': provider.value,
        },
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final decoded = jsonDecode(response.body);

      return decoded['token'];
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> signOut(
    String userAuthToken,
  ) async {
    _log.info("Signing out");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/signout'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<NoaUser> getUser(String userAuthToken) async {
    _log.info("Getting user info");
    try {
      final response = await http.get(
        Uri.parse('https://api.brilliant.xyz/noa/user'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }

      final body = jsonDecode(response.body);
      final email = body['user']['email'];
      final plan = body['user']['plan'];
      final creditsUsed = body['user']['credit_used'];
      final maxCredits = body['user']['credit_total'];

      _log.info(
          "Got user account info: Email: $email, plan: $plan, credits: $creditsUsed/$maxCredits");

      return NoaUser(
        email: email,
        plan: plan,
        creditsUsed: creditsUsed,
        maxCredits: maxCredits,
      );
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<void> deleteUser(
    String userAuthToken,
  ) async {
    _log.info("Deleting user");
    try {
      final response = await http.post(
        Uri.parse('https://api.brilliant.xyz/noa/user/delete'),
        headers: {"Authorization": userAuthToken},
      );

      if (response.statusCode != 200) {
        throw NoaApiServerException(
          reason: response.body,
          statusCode: response.statusCode,
        );
      }
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getMessage(
    String userAuthToken,
    Uint8List audio,
    Uint8List image,
    String systemRole,
    double temperature,
    List<NoaMessage> noaHistory,
    bool textToSpeech,
    String apiEndpoint,
    String apiToken,
    String apiHeader,
    bool isCustomServerEnabled,
    bool promptless,
  ) async {
    try {
      String endPoint = 'https://api.brilliant.xyz/noa';
      String token = userAuthToken;
      String header = "Authorization";

      if (apiEndpoint.isEmpty && isCustomServerEnabled) {
        throw NoaApiServerException(
          reason: "Custom server enabled but no endpoint provided",
          statusCode: 400,
        );
      }
      if (isCustomServerEnabled) {
        endPoint = apiEndpoint;
        token = apiToken;
        header = apiHeader;
      }
      
      var request = http.MultipartRequest(
        'POST',
        Uri.parse(endPoint),
      );

      request.headers.addAll({header: token});

      request.files.add(http.MultipartFile.fromBytes(
        'audio',
        bytesToWav(audio, 8, 8000),
        filename: 'audio.wav',
      ));

      try {
        image = encodeJpg(copyRotate(decodeJpg(image)!, angle: -90));

        request.files.add(http.MultipartFile.fromBytes(
          'image',
          image,
          filename: 'image.jpg',
        ));
      } catch (error) {
        _log.warning(error);
      }
      noaHistory = noaHistory.where((msg) => !msg.exclude).toList();
      if (!isCustomServerEnabled) {
        request.fields['noa_system_prompt'] = systemRole;
        request.fields['temperature'] = temperature.toString();
        request.fields['tts'] = textToSpeech ? "1" : "0";
        request.fields['promptless'] = promptless ? "1" : "0";
      }
      request.fields['messages'] = jsonEncode(noaHistory);
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();

      _log.info(
          "Sending message request: audio[${audio.length}], image[${image.length}], ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));
      List<NoaMessage> response = List.empty(growable: true);
      final topicChanged = body["debug"]['topic_changed']??false;

      response.add(NoaMessage(
        message: body['user_prompt'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.user,
        time: DateTime.now(),
        image: kReleaseMode ? null : image,
        topicChanged: topicChanged
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
        image: body['image'] != null ? base64.decode(body['image']) : null,
      ));

      _log.info(
          "Received response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static Future<List<NoaMessage>> getWildcardMessage(
    String userAuthToken,
    String systemRole,
    double temperature,
    bool textToSpeech,
  ) async {
    try {
      var request = http.MultipartRequest(
        'POST',
        Uri.parse('https://api.brilliant.xyz/noa/wildcard'),
      );

      request.headers.addAll({HttpHeaders.authorizationHeader: userAuthToken});

      request.fields['noa_system_prompt'] = systemRole;
      request.fields['location'] = await Location.getAddress();
      request.fields['time'] = DateTime.now().toString();
      request.fields['temperature'] = temperature.toString();
      request.fields['tts'] = textToSpeech ? "1" : "0";

      _log.info("Sending wildcard request: ${request.fields.toString()}");

      var streamedResponse = await request.send();

      if (streamedResponse.statusCode != 200) {
        throw NoaApiServerException(
          reason: streamedResponse.reasonPhrase ?? "",
          statusCode: streamedResponse.statusCode,
        );
      }

      List<int> serverResponse = List.empty(growable: true);
      await streamedResponse.stream
          .forEach((element) => serverResponse += element);
      var body = jsonDecode(utf8.decode(serverResponse));

      List<NoaMessage> response = List.empty(growable: true);

      response.add(NoaMessage(
        message: "Wildcard ",
        from: NoaRole.user,
        time: DateTime.now(),
      ));

      response.add(NoaMessage(
        message: body['message'].toString().replaceAll(RegExp(r''), '-'),
        from: NoaRole.noa,
        time: DateTime.now(),
      ));

      _log.info(
          "Received wildcard response. User: \"${body['user_prompt']}\". Noa: \"${body['message']}\". Debug: ${body['debug']}");

      if (textToSpeech && body['audio'] != null) {
        _playAudio(base64.decode(body['audio']));
      }

      return response;
    } catch (error) {
      _log.warning(error);
      return Future.error(error);
    }
  }

  static void _playAudio(Uint8List audio) async {
    _log.info("Playing ${audio.length} bytes of audio");

    final tempDir = await getTemporaryDirectory();
    File file = await File('${tempDir.path}/audio.mp3').create();
    file.writeAsBytesSync(audio);

    try {
      AudioPlayer player = AudioPlayer(handleAudioSessionActivation: false);
      await player.setAudioSource(AudioSource.file(file.path));
      await player.play();
      await player.dispose();
    } catch (error) {
      _log.warning("Error playing audio. $error");
    }
  }
}




