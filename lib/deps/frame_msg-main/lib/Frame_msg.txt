
===== Directory Structure =====
Folder PATH listing for volume Windows-SSD
Volume serial number is 92D4-B028
C:\USERS\JONAT\DOWNLOADS\FRAME_MSG-MAIN\FRAME_MSG-MAIN\LIB
|   DartFilesContent.txt
|   frame_msg.dart
|   tx_msg.dart
|   
+---lua
|       battery.lua
|       battery.min.lua
|       camera.lua
|       camera.min.lua
|       code.lua
|       code.min.lua
|       data.lua
|       data.min.lua
|       image_sprite_block.lua
|       image_sprite_block.min.lua
|       imu.lua
|       imu.min.lua
|       plain_text.lua
|       plain_text.min.lua
|       sprite.lua
|       sprite.min.lua
|       text_sprite_block.lua
|       text_sprite_block.min.lua
|       
+---rx
|       audio.dart
|       auto_exp_result.dart
|       imu.dart
|       metering_data.dart
|       photo.dart
|       tap.dart
|       
\---tx
        auto_exp_settings.dart
        capture_settings.dart
        code.dart
        image_sprite_block.dart
        manual_exp_settings.dart
        plain_text.dart
        sprite.dart
        text_sprite_block.dart
        

===== End of Directory Structure =====


===== File: frame_msg.dart =====
library frame_msg;

export 'tx_msg.dart';

export 'rx/audio.dart';
export 'rx/imu.dart';
export 'rx/photo.dart';
export 'rx/tap.dart';

export 'tx/auto_exp_settings.dart';
export 'tx/capture_settings.dart';
export 'tx/code.dart';
export 'tx/image_sprite_block.dart';
export 'tx/manual_exp_settings.dart';
export 'tx/plain_text.dart';
export 'tx/sprite.dart';
export 'tx/text_sprite_block.dart';


===== End of File: frame_msg.dart =====


===== File: tx_msg.dart =====
import 'dart:typed_data';

/// The base class for all Tx (transmit phone to Frame) messages that can be sent using sendMessage()
/// which performs splitting across multiple MTU-sized packets
/// an assembled automatically frameside by the data handler.
abstract class TxMsg {

  /// pack() should produce a message data payload that can be parsed by a corresponding
  /// parser in the frameside application (Lua)
  /// The 0x01 (raw user data marker) byte and the msgCode byte are
  /// prepended to each bluetooth write() call by the Frame BLE sendDataRaw() method,
  /// followed by the maximum amount of payload data that will fit until the whole message is sent.
  Uint8List pack();
}


===== End of File: tx_msg.dart =====


===== File: rx\audio.dart =====
import 'dart:async';
import 'dart:collection';
import 'dart:typed_data';
import 'package:logging/logging.dart';

final _log = Logger("RxAudio");

class RxAudio {

  // Frame to Phone flags
  final int nonFinalChunkFlag;
  final int finalChunkFlag;
  final bool streaming;
  StreamController<Uint8List>? _controller;

  RxAudio({
    this.nonFinalChunkFlag = 0x05,
    this.finalChunkFlag = 0x06,
    this.streaming = false
  });

  /// Attach this RxAudio to the Frame's dataResponse characteristic stream.
  /// If this RxAudio was created with `streaming: true` then the returned
  /// broadcast Stream will produce elements continuously, otherwise it will
  /// be a single subscription stream that produces a single Uint8List element
  /// containing the entire audio clip received.
  /// Both types of Stream are Done when the finalChunkFlag is received from
  /// Frame indicating the end of the audio feed
  Stream<Uint8List> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAudio etc?
    // might be possible though after a clean close(), do I want to prevent it?
    return streaming ?
      _audioDataStreamResponse(dataResponse) :
      _audioDataResponse(dataResponse);
  }

  /// Audio data stream with a single element of a raw audio clip
  Stream<Uint8List> _audioDataResponse(Stream<List<int>> dataResponse) {

    // the audio data as a list of bytes that accumulates with each packet
    BytesBuilder audioData = BytesBuilder(copy: false);
    int rawOffset = 0;

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw data into audio (as bytes)
    _controller = StreamController();

    _controller!.onListen = () {
      _log.fine('stream subscribed');
      dataResponseSubs = dataResponse
          .where(
              (data) => data[0] == nonFinalChunkFlag || data[0] == finalChunkFlag)
          .listen((data) {
        if (data[0] == nonFinalChunkFlag) {
          _log.finer(() => 'Non-final: ${data.length}');
          audioData.add(UnmodifiableListView(data.skip(1)));
          rawOffset += data.length - 1;
        }
        // the last chunk has a first byte of 8 so stop after this
        else if (data[0] == finalChunkFlag) {
          _log.finer(() => 'Final: ${data.length}');
          audioData.add(UnmodifiableListView(data.skip(1)));
          rawOffset += data.length - 1;

          // When full audio data is received, emit it and clear the buffer
          _controller!.add(audioData.takeBytes());
          rawOffset = 0;

          // and close the stream
          _controller!.close();
        }
        _log.finer(() => 'Chunk size: ${data.length - 1}, rawOffset: $rawOffset');
      }, onDone: _controller!.close, onError: _controller!.addError);
    };

    _controller!.onCancel = () {
      _log.fine('stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }

  /// Real-time Audio data stream
  /// A listener can subscribe and unsubscribe and resubscribe to the returned broadcast Stream
  /// multiple times. The Stream only is Done when the final chunk message code is sent
  /// from Frame
  Stream<Uint8List> _audioDataStreamResponse(Stream<List<int>> dataResponse) {

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw data into audio (as bytes)
    // It needs to be a broadcast stream so users can subscribe, unsubscribe, then resubscribe
    // to the same stream
    _controller = StreamController.broadcast();

    _controller!.onListen = () {
      _log.fine('stream subscribed');
      dataResponseSubs?.cancel();
      dataResponseSubs = dataResponse
        .where(
            (data) => data[0] == nonFinalChunkFlag || data[0] == finalChunkFlag)
        .listen((data) {
          // start or middle of an audio stream
          if (data[0] == nonFinalChunkFlag) {
            _log.finer(() => 'Non-final: ${data.length}');
            assert(data.length % 2 == 1); // whole 16-bit pcm samples only (plus msgCode in data[0] makes it odd)
            _controller!.add(Uint8List.fromList(data.skip(1).toList()));
          }
          // the last chunk has a first byte of finalChunkFlag so stop after this
          else if (data[0] == finalChunkFlag) {

            _log.finer(() => 'Final: ${data.length}');

            if (data.length > 1) {
              _controller!.add(Uint8List.fromList(data.skip(1).toList()));
            }

            // upstream is done so close the downstream
            _log.fine('About to close stream');
            _controller!.close();
            _log.fine('stream closed');
          }
          // close or pass on errors if the upstream dataResponse closes/errors
        }, onDone: _controller!.close, onError: _controller!.addError);
    };

    _controller!.onCancel = () {
      _log.fine('stream unsubscribed');
      // unsubscribe from upstream dataResponse
      dataResponseSubs?.cancel();

      // don't close the controller, if the client re-listens to the returned Stream
      // then we re-subscribe to dataResponse in onListen and continue sending data
    };

    return _controller!.stream;
  }

  /// Detaches the RxAudio from the Frame dataResponse Stream permanently.
  /// For `streaming==false` RxAudios, this has no effect because the controller
  /// of the Stream closes when the single clip is completely received.
  /// For `streaming==true` RxAudios, after the RxAudio has been attached to
  /// dataResponse, the client can call listen() and cancel() many times and
  /// the controller for the stream will not be closed. But when finished, it
  /// can be closed with detach and cannot be listened to again.
  void detach() {
    _controller?.close();
  }

  /// Create the contents of a WAV files corresponding to the provided pcmData
  static Uint8List toWavBytes({required Uint8List pcmData, int sampleRate = 8000, int bitsPerSample = 16, int channels = 1}) {
    int byteRate = sampleRate * channels * bitsPerSample ~/ 8;
    int dataSize = pcmData.length;
    int fileSize = 36 + dataSize;

    // WAV Header
    List<int> header = [
      // "RIFF" chunk descriptor
      0x52, 0x49, 0x46, 0x46, // "RIFF" in ASCII
      fileSize & 0xff, (fileSize >> 8) & 0xff, (fileSize >> 16) & 0xff, (fileSize >> 24) & 0xff, // Chunk size
      0x57, 0x41, 0x56, 0x45, // "WAVE" in ASCII

      // "fmt " sub-chunk
      0x66, 0x6d, 0x74, 0x20, // "fmt " in ASCII
      16, 0x00, 0x00, 0x00,   // Subchunk1Size (16 for PCM)
      0x01, 0x00,             // AudioFormat (1 for PCM)
      channels & 0xff, 0x00,   // NumChannels
      sampleRate & 0xff, (sampleRate >> 8) & 0xff, (sampleRate >> 16) & 0xff, (sampleRate >> 24) & 0xff, // SampleRate
      byteRate & 0xff, (byteRate >> 8) & 0xff, (byteRate >> 16) & 0xff, (byteRate >> 24) & 0xff, // ByteRate
      (channels * bitsPerSample ~/ 8) & 0xff, 0x00, // BlockAlign
      bitsPerSample & 0xff, 0x00, // BitsPerSample

      // "data" sub-chunk
      0x64, 0x61, 0x74, 0x61, // "data" in ASCII
      dataSize & 0xff, (dataSize >> 8) & 0xff, (dataSize >> 16) & 0xff, (dataSize >> 24) & 0xff, // Subchunk2Size
    ];

    // Combine header and PCM data
    return Uint8List.fromList(header + pcmData);
  }

}

===== End of File: rx\audio.dart =====


===== File: rx\auto_exp_result.dart =====
import 'dart:async';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxAutoExpResult");

/// Receive handler for auto exposure and white balance data from the auto exposure algorithm
class RxAutoExpResult {

  // Frame to Phone flags
  final int autoExpFlag;
  StreamController<AutoExpResult>? _controller;

  RxAutoExpResult({
    this.autoExpFlag = 0x11,
  });

  /// Attach this RxAutoExpResult to the Frame's dataResponse characteristic stream.
  Stream<AutoExpResult> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxAutoExpResult etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == autoExpFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('auto exposure result detected');

          // Ensure the data length is sufficient
          if (data.length < 65) {
            _log.warning('Insufficient data length for AutoExpResult: ${data.length}');
            return;
          }

          // Extract the relevant data (bytes 1 to 65)
          List<int> relevantData = data.sublist(1, 65);

          // Create a ByteData object from the relevant data
          ByteData byteData = ByteData.sublistView(Uint8List.fromList(relevantData));

          // Unpack the data as 16 float32 values
          List<double> unpacked = List.generate(16, (i) => byteData.getFloat32(i * 4, Endian.little));

          _controller!.add(AutoExpResult(
            error: unpacked[0],
            shutter: unpacked[1],
            analogGain: unpacked[2],
            redGain: unpacked[3],
            greenGain: unpacked[4],
            blueGain: unpacked[5],
            brightness: Brightness(
              centerWeightedAverage: unpacked[6],
              scene: unpacked[7],
              matrix: Matrix(
                r: unpacked[8],
                g: unpacked[9],
                b: unpacked[10],
                average: unpacked[11],
              ),
              spot: Spot(
                r: unpacked[12],
                g: unpacked[13],
                b: unpacked[14],
                average: unpacked[15],
              ),
            ),
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('AutoExposureResultDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('AutoExposureResultDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class AutoExpResult {
  final double error;
  final double shutter;
  final double analogGain;
  final double redGain;
  final double greenGain;
  final double blueGain;
  final Brightness brightness;

  AutoExpResult({
    required this.error,
    required this.shutter,
    required this.analogGain,
    required this.redGain,
    required this.greenGain,
    required this.blueGain,
    required this.brightness,
  });
}

class Brightness {
  final double centerWeightedAverage;
  final double scene;
  final Matrix matrix;
  final Spot spot;

  Brightness({
    required this.centerWeightedAverage,
    required this.scene,
    required this.matrix,
    required this.spot,
  });
}

class Matrix {
  final double r;
  final double g;
  final double b;
  final double average;

  Matrix({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}

class Spot {
  final double r;
  final double g;
  final double b;
  final double average;

  Spot({
    required this.r,
    required this.g,
    required this.b,
    required this.average,
  });
}


===== End of File: rx\auto_exp_result.dart =====


===== File: rx\imu.dart =====
import 'dart:async';
import 'dart:math';
import 'dart:typed_data';

import 'package:logging/logging.dart';

final _log = Logger("RxIMU");

/// Buffer class to allow us to provide a smoothed moving average of samples
class SensorBuffer {
  final int maxSize;
  final List<(int x, int y, int z)> _buffer = [];

  SensorBuffer(this.maxSize);

  void add((int x, int y, int z) value) {
    _buffer.add(value);
    if (_buffer.length > maxSize) {
      _buffer.removeAt(0);
    }
  }

  (int x, int y, int z) get average {
    if (_buffer.isEmpty) return (0, 0, 0);

    int sumX = 0, sumY = 0, sumZ = 0;
    for (var value in _buffer) {
      sumX += value.$1;
      sumY += value.$2;
      sumZ += value.$3;
    }
    return (
      (sumX ~/ _buffer.length),
      (sumY ~/ _buffer.length),
      (sumZ ~/ _buffer.length)
    );
  }
}

/// IMU data stream, returns raw 3-axis magnetometer and 3-axis accelerometer data
/// and optionally computes derived values
/// Note, a proper calculation of Heading requires magnetometer calibration,
/// tilt compensation (which we can do here from the accelerometer), and magnetic
/// declination adjustment (which is lat-long and time-dependent).
/// Magnetometer calibration and declination adjustments need to be done outside this class.
class RxIMU {
  final int _smoothingSamples;

  // Frame to Phone flags
  final int imuFlag;
  StreamController<IMUData>? _controller;

  // Buffers for smoothing
  late final SensorBuffer _compassBuffer;
  late final SensorBuffer _accelBuffer;

  RxIMU({
    this.imuFlag = 0x0A,
    int smoothingSamples = 1,
  }) : _smoothingSamples = smoothingSamples {
    _compassBuffer = SensorBuffer(_smoothingSamples);
    _accelBuffer = SensorBuffer(_smoothingSamples);
  }

  /// Attach this RxIMU to the Frame's dataResponse characteristic stream.
  Stream<IMUData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxIMU etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms the dataResponse elements into IMUData events
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == imuFlag)
        .listen((data) {
          Uint8List bytes = Uint8List.fromList(data);
          // reinterpret the bytes after offset 2 as signed 16-bit integers
          Int16List s16 = bytes.buffer.asInt16List(2);

          // Get raw values
          var rawCompass = (s16[0], s16[1], s16[2]);
          var rawAccel = (s16[3], s16[4], s16[5]);

          // Add to buffers
          _compassBuffer.add(rawCompass);
          _accelBuffer.add(rawAccel);

          _controller!.add(IMUData(
            compass: _compassBuffer.average,
            accel: _accelBuffer.average,
            raw: IMURawData(
              compass: rawCompass,
              accel: rawAccel,
            ),
          ));

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('ImuDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('ImuDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class IMURawData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;

  IMURawData({
    required this.compass,
    required this.accel,
  });
}

class IMUData {
  final (int x, int y, int z) compass;
  final (int x, int y, int z) accel;
  final IMURawData? raw;

  IMUData({
    required this.compass,
    required this.accel,
    this.raw,
  });

  double get pitch => atan2(accel.$2, accel.$3) * 180.0 / pi;
  double get roll => atan2(accel.$1, accel.$3) * 180.0 / pi;
}

===== End of File: rx\imu.dart =====


===== File: rx\metering_data.dart =====
import 'dart:async';

import 'package:logging/logging.dart';

final _log = Logger("RxMeteringData");

/// Receive handler for metering data from the camera sensor
class RxMeteringData {

  // Frame to Phone flags
  final int meteringFlag;
  StreamController<MeteringData>? _controller;

  RxMeteringData({
    this.meteringFlag = 0x12,
  });

  /// Attach this RxMeteringData to the Frame's dataResponse characteristic stream.
  Stream<MeteringData> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxMeteringData etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == meteringFlag)
        .listen((data) {
          // parse the metering data from the raw data
          _log.finer('metering data detected');
          _controller!.add(MeteringData(
            spotR: data[1],
            spotG: data[2],
            spotB: data[3],
            matrixR: data[4],
            matrixG: data[5],
            matrixB: data[6],
          ));
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('MeteringDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('MeteringDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

class MeteringData {
  final int spotR;
  final int spotG;
  final int spotB;
  final int matrixR;
  final int matrixG;
  final int matrixB;

  MeteringData({
    required this.spotR,
    required this.spotG,
    required this.spotB,
    required this.matrixR,
    required this.matrixG,
    required this.matrixB,
  });
}


===== End of File: rx\metering_data.dart =====


===== File: rx\photo.dart =====
import 'dart:async';
import 'dart:typed_data';

import 'package:image/image.dart' as image_lib;
import 'package:logging/logging.dart';

final _log = Logger("RxPhoto");

/// Returns a photo as a JPEG image from Frame.
/// Note: The camera sensor on Frame is rotated 90 degrees clockwise, so raw images are rotated, but by default
/// RxPhoto will correct this by rotating -90 degrees.
/// If you want to save the cost of copyRotate here you can specify upright=false in the constructor
/// since some ML packages allow for specifying the orientation of the image when passing it in.
/// Pairs with frame.camera.read_raw(), that is, jpeg header and footer
/// are not sent from Frame - only the content, using non-final and final message types
/// Jpeg header and footer are added in here on the client, so a quality level
/// must be provided to select the correct header. Returns a Stream with exactly one jpeg as bytes, then is Done
class RxPhoto {

  // Frame to Phone flags
  final int nonFinalChunkFlag;
  final int finalChunkFlag;

  /// Whether a raw image (without 623-byte jpeg header) will be returned from Frame, hence the corresponding header should be added
  /// Note that the first request for an image with a given resolution and quality level MUST be a complete image so the jpeg header can be saved
  /// and used for subsequent raw images of the same resolution and quality level
  final bool isRaw;

  /// The quality level of the jpeg image to be returned ['VERY_LOW', 'LOW', 'MEDIUM', 'HIGH', 'VERY_HIGH']
  final String quality;

  /// The resolution of the (square) raw image to be returned from Frame
  /// Must be an even number between 100 and 720 inclusive
  final int resolution;

  /// Whether to rotate the image 90 degrees counter-clockwise to make it upright before returning it
  final bool upright;

  StreamController<Uint8List>? _controller;

  /// A map of jpeg headers for each quality level which we fill as we receive the first image of each quality level/resolution
  /// Key format is 'quality_resolution' e.g. 'VERY_LOW_512'
  static final Map<String, Uint8List> jpegHeaderMap = {};
  static bool hasJpegHeader(String quality, int resolution) => jpegHeaderMap.containsKey('${quality}_$resolution');

  RxPhoto({
    this.nonFinalChunkFlag = 0x07,
    this.finalChunkFlag = 0x08,
    this.upright = true,
    this.isRaw = false,
    required this.quality,
    required this.resolution,
  });

  /// Attach this RxPhoto to the Frame's dataResponse characteristic stream.
  /// If `isRaw` is true, then quality and resolution must be specified and match the raw image requested from Frame
  /// so that the correct jpeg header can be prepended.
  Stream<Uint8List> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxPhoto etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the image data as a list of bytes that accumulates with each packet
    List<int> imageData = List.empty(growable: true);
    int rawOffset = 0;

    // if isRaw is true, a jpeg header must be prepended to the raw image data
    if (isRaw) {
      // fetch the jpeg header for this quality level and resolution
      String key = '${quality}_$resolution';

      if (!jpegHeaderMap.containsKey(key)) {
        throw Exception('No jpeg header found for quality level $quality and resolution $resolution - request full jpeg once before requesting raw');
      }

      // add the jpeg header bytes for this quality level (623 bytes)
      imageData.addAll(jpegHeaderMap[key]!);
    }

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw data into images (as bytes)
    _controller = StreamController();

    _controller!.onListen = () {
      _log.fine('ImageDataResponse stream subscribed');
      dataResponseSubs = dataResponse
          .where(
              (data) => data[0] == nonFinalChunkFlag || data[0] == finalChunkFlag)
          .listen((data) {
        if (data[0] == nonFinalChunkFlag) {
          imageData += data.sublist(1);
          rawOffset += data.length - 1;
        }
        // the last chunk has a first byte of finalChunkFlag so stop after this
        else if (data[0] == finalChunkFlag) {
          imageData += data.sublist(1);
          rawOffset += data.length - 1;

          Uint8List finalImageBytes = Uint8List.fromList(imageData);

          // if this image is a full jpeg, save the jpeg header for this quality level and resolution
          // so that it can be prepended to raw images of the same quality level and resolution
          if (!isRaw) {
            String key = '${quality}_$resolution';
            if (!jpegHeaderMap.containsKey(key)) {
              jpegHeaderMap[key] = finalImageBytes.sublist(0, 623);
            }
          }

          // When full image data is received,
          // rotate the image counter-clockwise 90 degrees to make it upright
          // unless requested otherwise (to save processing)
          if (upright) {
            image_lib.Image? im = image_lib.decodeJpg(finalImageBytes);
            im = image_lib.copyRotate(im!, angle: 270);
            // emit the rotated jpeg bytes
            _controller!.add(image_lib.encodeJpg(im));
          }
          else {
            // emit the original rotation jpeg bytes
            _controller!.add(finalImageBytes);
          }

          // clear the buffer
          imageData.clear();
          rawOffset = 0;

          // and close the stream
          _controller!.close();
        }
        _log.finer(() => 'Chunk size: ${data.length - 1}, rawOffset: $rawOffset');
      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('Controller being listened to');
    };

    _controller!.onCancel = () {
      _log.fine('ImageDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }
}

===== End of File: rx\photo.dart =====


===== File: rx\tap.dart =====
import 'dart:async';

import 'package:logging/logging.dart';

final _log = Logger("RxTap");

/// Multi-Tap data stream, returns the number of taps detected
class RxTap {

  // Frame to Phone flags
  final int tapFlag;
  final Duration threshold;
  StreamController<int>? _controller;

  RxTap({
    this.tapFlag = 0x09,
    this.threshold = const Duration(milliseconds: 300),
  });

  /// Attach this RxTap to the Frame's dataResponse characteristic stream.
  Stream<int> attach(Stream<List<int>> dataResponse) {
    // TODO check for illegal state - attach() already called on this RxTap etc?
    // might be possible though after a clean close(), do I want to prevent it?

    // the subscription to the underlying data stream
    StreamSubscription<List<int>>? dataResponseSubs;

    // Our stream controller that transforms/accumulates the raw tap events into multi-taps
    _controller = StreamController();

    // track state of multi-taps
    int lastTapTime = 0;
    int taps = 0;
    Timer? t;

    _controller!.onListen = () {
      dataResponseSubs = dataResponse
        .where((data) => data[0] == tapFlag)
        .listen((data) {
          int tapTime = DateTime.now().millisecondsSinceEpoch;
          // debounce taps that occur too close to the prior tap
          if (tapTime - lastTapTime < 40) {
            _log.finer('tap ignored - debouncing');
            lastTapTime = tapTime;
          }
          else {
            _log.finer('tap detected');
            lastTapTime = tapTime;

            taps++;
            t?.cancel();
            t = Timer(threshold, () {
              _controller!.add(taps);
              taps = 0;
            });
          }

      }, onDone: _controller!.close, onError: _controller!.addError);
      _log.fine('TapDataResponse stream subscribed');
    };

    _controller!.onCancel = () {
      _log.fine('TapDataResponse stream unsubscribed');
      dataResponseSubs?.cancel();
      _controller!.close();
    };

    return _controller!.stream;
  }


}

===== End of File: rx\tap.dart =====


===== File: tx\auto_exp_settings.dart =====
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a collection of camera settings suitable for requesting
/// the frameside app enable auto exposure and gain with the specified settings
class TxAutoExpSettings extends TxMsg {
  final int _meteringIndex;
  final double _exposure;
  final double _exposureSpeed;
  final int _shutterLimit;
  final int _analogGainLimit;
  final double _whiteBalanceSpeed;
  final int _rgbGainLimit;

  TxAutoExpSettings({
      int meteringIndex = 1, // ['SPOT', 'CENTER_WEIGHTED', 'AVERAGE'];
      double exposure = 0.1, // 0.0 <= val <= 1.0
      double exposureSpeed = 0.45, // 0.0 <= val <= 1.0
      int shutterLimit = 16383, // 4 <= val <= 16383
      int analogGainLimit = 16, // 0 <= val <= 248
      double whiteBalanceSpeed = 0.5, // 0.0 <= val <= 1.0
      int rgbGainLimit = 287, // 0 <= val <= 1023
      })
      : _meteringIndex = meteringIndex,
        _exposure = exposure,
        _exposureSpeed = exposureSpeed,
        _shutterLimit = shutterLimit,
        _analogGainLimit = analogGainLimit,
        _whiteBalanceSpeed = whiteBalanceSpeed,
        _rgbGainLimit = rgbGainLimit;

  @override
  Uint8List pack() {
    // several doubles in the range 0 to 1, so map that to an unsigned byte 0..255
    // by multiplying by 255 and rounding
    int intExp = (_exposure * 255).round() & 0xFF;
    int intExpSpeed = (_exposureSpeed * 255).round() & 0xFF;
    int intWhiteBalanceSpeed = (_whiteBalanceSpeed * 255).round() & 0xFF;

    // shutter limit has a range 4..16384 so just map it to a Uint16 over 2 bytes
    int intShutLimMsb = (_shutterLimit >> 8) & 0xFF;
    int intShutLimLsb = _shutterLimit & 0xFF;

    // RGB gain limit has a range 0..1023 so just map it to a Uint16 over 2 bytes
    int intRgbGainLimMsb = (_rgbGainLimit >> 8) & 0xFF;
    int intRgbGainLimLsb = _rgbGainLimit & 0xFF;

    // 9 bytes of auto exposure settings. sendMessage will prepend the data byte & msgCode to each packet
    // and the Uint16 payload length to the first packet
    return Uint8List.fromList([
      _meteringIndex & 0xFF,
      intExp,
      intExpSpeed,
      intShutLimMsb,
      intShutLimLsb,
      _analogGainLimit & 0xFF,
      intWhiteBalanceSpeed,
      intRgbGainLimMsb,
      intRgbGainLimLsb,
    ]);
  }
}


===== End of File: tx\auto_exp_settings.dart =====


===== File: tx\capture_settings.dart =====
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a collection of camera settings suitable for requesting
/// the frameside app to take a photo with the specified settings
class TxCaptureSettings extends TxMsg {
  final int _resolution;
  final int _qualityIndex;
  final int _pan;
  final bool _raw;

  TxCaptureSettings({
      int resolution = 512, // any even number between 100 and 720
      int qualityIndex = 4, // zero-based index into [VERY_LOW, LOW, MEDIUM, HIGH, VERY_HIGH]
      int pan = 0, // any number between -140 and 140, where 0 represents a centered image
      bool raw = false,
      })
      : _resolution = resolution,
        _qualityIndex = qualityIndex,
        _pan = pan,
        _raw = raw;

  @override
  Uint8List pack() {
    // resolution has a range 100..720 and must be even so just map resolution~/2 to a Uint16 over 2 bytes
    int halfRes = _resolution ~/ 2;
    int intHalfResolutionMsb = (halfRes >> 8) & 0xFF;
    int intHalfResolutionLsb = halfRes & 0xFF;

    // pan has a range -140..140 so add 140 and map it to a Uint16 over 2 bytes 0..280
    int panShifted = _pan + 140;
    int intPanShiftedMsb = (panShifted >> 8) & 0xFF;
    int intPanShiftedLsb = panShifted & 0xFF;

    // 6 bytes of camera capture settings. sendMessage will prepend the data byte, msgCode to each packet
    // and the Uint16 payload length to the first packet
    return Uint8List.fromList([
      _qualityIndex & 0xFF,
      intHalfResolutionMsb,
      intHalfResolutionLsb,
      intPanShiftedMsb,
      intPanShiftedLsb,
      _raw ? 0x01 : 0x00,
    ]);
  }
}


===== End of File: tx\capture_settings.dart =====


===== File: tx\code.dart =====
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing only a single optional byte
/// suitable for signalling the frameside app to take some action
/// (e.g. toggle streaming, take a photo with default parameters etc.)
class TxCode extends TxMsg {
  int value;

  TxCode({this.value = 0});

  @override
  Uint8List pack() {
    return Uint8List.fromList([value & 0xFF]);
  }
}


===== End of File: tx\code.dart =====


===== File: tx\image_sprite_block.dart =====
import 'dart:typed_data';

import 'package:image/image.dart' as img;
import '../tx_msg.dart';
import 'sprite.dart';

/// Represents an image of a specified size sliced into a number of "sprite lines" of the full width of the image, and the specified height,
/// and possibly a final sprite line of a different height.
/// When sending TxImageSpriteBlock to Frame, the sendMessage() will send the header with block dimensions and sprite line height,
/// and the user then sends each line[] as a TxSprite message with the same msgCode as the Block, and the frame app will use the line height
/// to place each line. By sending each line separately we can display them as they arrive, as well as reducing overall memory
/// requirement (each concat() call is smaller).
/// Sending an ImageSpriteBlock with no lines is not intended usage.
class TxImageSpriteBlock extends TxMsg {
  final TxSprite _image;
  int get width => _image.width;
  int get height => _image.height;
  final int _spriteLineHeight;
  int get spriteLineHeight => _spriteLineHeight;

  final List<TxSprite> _spriteLines = [];
  List<TxSprite> get spriteLines => _spriteLines;

  /// intent for the Lua side to render the sprite lines as they are received,
  /// or wait until the whole image can be drawn
  final bool _progressiveRender;

  /// whether subsequent sprite lines after the first set can be sent to override the corresponding
  /// sprite lines from the original image, resulting in an updatable, dynamic image
  /// (whether progressively rendered, or not)
  /// As long as a new block header is not sent
  final bool _updatable;

  /// After construction, an ImageSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be sent
  bool get isEmpty => _spriteLines.isEmpty;

  /// After construction, an ImageSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be sent
  bool get isNotEmpty => _spriteLines.isNotEmpty;

  TxImageSpriteBlock({
    required TxSprite image,
    required int spriteLineHeight,
    bool progressiveRender = true,
    bool updatable = true
    }) : _image = image,
         _spriteLineHeight = spriteLineHeight,
         _progressiveRender = progressiveRender,
         _updatable = updatable {
    // process the full-sized sprite lines
    for (int i = 0; i < image.height ~/ spriteLineHeight; i++) {
      _spriteLines.add(
        TxSprite(
          width: image.width,
          height: spriteLineHeight,
          numColors: image.numColors,
          paletteData: image.paletteData,
          pixelData: image.pixelData.buffer.asUint8List(i * spriteLineHeight * image.width, spriteLineHeight * image.width)));
    }

    // if there is some final, shorter sprite line, process it too
    int finalHeight  = image.height % spriteLineHeight;
    if (finalHeight > 0) {
      _spriteLines.add(
        TxSprite(
          width: image.width,
          height: finalHeight,
          numColors: image.numColors,
          paletteData: image.paletteData,
          pixelData: image.pixelData.buffer.asUint8List(_spriteLines.length * spriteLineHeight * image.width, finalHeight * image.width)));
    }
  }

  /// Convert TxImageSpriteBlock back to a single image for testing/verification
  /// startLine and endLine are inclusive
  Future<Uint8List> toPngBytes() async {
    if (_spriteLines.isEmpty) {
      throw Exception('_spriteLines is empty: no image to convert toPngBytes()');
    }

    // create an image for the whole block
    var preview = img.Image(width: width, height: height);

    // copy in each of the sprites
    for (int i = 0; i <= _spriteLines.length; i++) {
      img.compositeImage(preview, _spriteLines[i].toImage(),
          dstY: (i * spriteLineHeight).toInt());
    }

    return img.encodePng(preview);
  }

  /// Corresponding parser should be called from frame_app data handler
  @override
  Uint8List pack() {
    if (_spriteLines.isEmpty) {
      throw Exception('_spriteLines is empty: no image to pack()');
    }

    // pack the width and height of the image (Uint16 each)
    int widthMsb = width >> 8;
    int widthLsb = width & 0xFF;
    int heightMsb = height >> 8;
    int heightLsb = height & 0xFF;

    // store the spriteLineHeight (Uint16)
    int spriteLineHeightMsb = spriteLineHeight >> 8;
    int spriteLineHeightLsb = spriteLineHeight & 0xFF;

    // special marker for Block header 0xFF, width and height of the block, spriteLineHeight, progressive rendering flag, updatable flag
    return Uint8List.fromList([
      0xFF,
      widthMsb,
      widthLsb,
      heightMsb,
      heightLsb,
      spriteLineHeightMsb,
      spriteLineHeightLsb,
      _progressiveRender ? 1 : 0,
      _updatable ? 1 : 0,
    ]);
  }
}


===== End of File: tx\image_sprite_block.dart =====


===== File: tx\manual_exp_settings.dart =====
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a collection of camera settings suitable for requesting
/// the frameside app enable manual exposure and gain with the specified settings
class TxManualExpSettings extends TxMsg {
  final int _manualShutter;
  final int _manualAnalogGain;
  final int _manualRedGain;
  final int _manualGreenGain;
  final int _manualBlueGain;

  TxManualExpSettings({
      int manualShutter = 4096, // 4 <= val <= 16383
      int manualAnalogGain = 1, // 0 <= val <= 248
      int manualRedGain = 121, // 0 <= val <= 1023
      int manualGreenGain = 64, // 0 <= val <= 1023
      int manualBlueGain = 140, // 0 <= val <= 1023
      })
      : _manualShutter = manualShutter,
        _manualAnalogGain = manualAnalogGain,
        _manualRedGain = manualRedGain,
        _manualGreenGain = manualGreenGain,
        _manualBlueGain = manualBlueGain;

  @override
  Uint8List pack() {
    // manual shutter has a range 4..16384 so just map it to a Uint16 over 2 bytes
    int intManShutterMsb = (_manualShutter >> 8) & 0xFF;
    int intManShutterLsb = _manualShutter & 0xFF;

    // manual color gains have a range 0..1023 so just map them to a Uint16 over 2 bytes
    int intManRedGainMsb = (_manualRedGain >> 8) & 0x03;
    int intManRedGainLsb = _manualRedGain & 0xFF;
    int intManGreenGainMsb = (_manualGreenGain >> 8) & 0x03;
    int intManGreenGainLsb = _manualGreenGain & 0xFF;
    int intManBlueGainMsb = (_manualBlueGain >> 8) & 0x03;
    int intManBlueGainLsb = _manualBlueGain & 0xFF;

    // 9 bytes of manual exposure settings. sendMessage will prepend the data byte & msgCode to each packet
    // and the Uint16 payload length to the first packet
    return Uint8List.fromList([
      intManShutterMsb,
      intManShutterLsb,
      _manualAnalogGain & 0xFF,
      intManRedGainMsb,
      intManRedGainLsb,
      intManGreenGainMsb,
      intManGreenGainLsb,
      intManBlueGainMsb,
      intManBlueGainLsb,
    ]);
  }
}


===== End of File: tx\manual_exp_settings.dart =====


===== File: tx\plain_text.dart =====
import 'dart:convert';
import 'dart:typed_data';

import '../tx_msg.dart';

/// A message containing a String of plain text,
/// plus optional top-left corner position coordinates for the
/// text to be printed in the Frame display (Lua/1-based, i.e. [1,1] to [640,400])
/// plus an optional palette offset (1..15, 0/'VOID' is invalid), plus optional character spacing
class TxPlainText extends TxMsg {
  final String _text;
  final int _x, _y;
  final int _paletteOffset;
  final int _spacing;

  TxPlainText({required String text, int x = 1, int y = 1, int paletteOffset = 1, int spacing = 4}) : _text = text, _x = x, _y = y, _paletteOffset = paletteOffset, _spacing = spacing;

  @override
  Uint8List pack() {
    final stringBytes = utf8.encode(_text);
    final strlen = stringBytes.length;

    Uint8List bytes = Uint8List(6 + strlen);
    bytes[0] = _x >> 8;   // x msb
    bytes[1] = _x & 0xFF; // x lsb
    bytes[2] = _y >> 8;   // y msb
    bytes[3] = _y & 0xFF; // y lsb
    bytes[4] = _paletteOffset & 0x0F; // 1..15
    bytes[5] = _spacing & 0xFF;
    bytes.setRange(6, strlen + 6, stringBytes);

    return bytes;
  }
}


===== End of File: tx\plain_text.dart =====


===== File: tx\sprite.dart =====
import 'dart:math';
import 'dart:typed_data';

import 'package:image/image.dart' as img;
import 'package:logging/logging.dart';
import '../tx_msg.dart';

final _log = Logger("TxSprite");

class TxSprite extends TxMsg {
  late final int _width;
  int get width => _width;
  late final int _height;
  int get height => _height;
  late final int _numColors;
  int get numColors => _numColors;
  late final Uint8List _paletteData;
  Uint8List get paletteData => _paletteData;
  late final Uint8List _pixelData;
  Uint8List get pixelData => _pixelData;

  /// Create a sprite with the specified size, palette data and pixel data, identified by the specified message code (the identifier used on the Lua side to label this sprite)
  /// width(Uint16), height(Uint16), bpp(Uint8), numColors(Uint8), palette (Uint8 r, Uint8 g, Uint8 b)*numColors, data (length: width x height bytes content: palette index)
  TxSprite({
    required int width,
    required int height,
    required int numColors,
    required Uint8List paletteData,
    required Uint8List pixelData})
    : _width = width,
      _height = height,
      _numColors = numColors,
      _paletteData = paletteData,
      _pixelData = pixelData;

  /// Create a TxSprite from any image bytes that can be decoded by img.decode()
  /// If it's an indexed image, quantize down to 14 colors if larger
  /// (plus black, white as palette entries 0 and 1.)
  /// If it's an RGB image, also quantize to 14 colors (then prepend black and white)
  /// Scale to 640x400 preserving aspect ratio for 1- or 2-bit images
  /// Scale to ~128k pixels preserving aspect ratio for 4-bit images
  /// TODO improve quantization - quality, speed
  /// If quantizing, since neuralNet seems to give the black in entry 0 and white in the last entry
  /// We just leave 0 (black) and swap palette entries 1 and 15 (and remap those pixels)
  TxSprite.fromImageBytes({required Uint8List imageBytes}) {
    var image = img.decodeImage(imageBytes);

    if (image == null) throw Exception('Unable to decode image file');

    // the number of colors in the image (after optional quantization), must be 16 or fewer
    final int numColors;
    bool quantized = false;

    if ((image.hasPalette && image.palette!.numColors > 16) || !image.hasPalette) {
      _log.fine('quantizing image');
      // note, even though we ask for only numberOfColors here, neuralNet gives us back a palette of 256
      // with only the first numberOfColors populated, ordered by increasing luminance (TODO and always containing black, then colors, then white last)
      // we'll trim that palette array down to 16*3 later
      image = img.quantize(image, numberOfColors: 16, method: img.QuantizeMethod.neuralNet, dither: img.DitherKernel.none);
      numColors = 16;
      quantized = true;
    }
    else {
      _log.fine('16 or fewer colors in an indexed image, no quantizing required');
      numColors = image.palette!.numColors;
    }

    if (image.width > 640 || image.height > 400) {
      _log.fine('scaling down oversized image');

      if (image.palette!.numColors <= 4) {
        _log.fine('Low bit depth image, scale to 640x400');
        // 1- or 2-bit images can take as much of 640x400 as needed, preserving aspect ratio
        // use nearest interpolation, we can't use any interpolation that averages colors
        image = img.copyResize(image,
            width: 640,
            height: 400,
            maintainAspect: true,
            interpolation: img.Interpolation.nearest);
      }
      else {
        _log.fine('4-bit image, scale to max 128k pixels');
        // 4-bit images need to be smaller or else we run out of memory. Limit to 64kb, or 128k pixels
        int numSrcPixels = image.height * image.width;

        if (numSrcPixels > 128000) {
          double scaleFactor = sqrt(128000 / numSrcPixels);
          _log.fine(() => 'scaling down by $scaleFactor');

          image = img.copyResize(image,
              width: (image.width * scaleFactor).toInt().clamp(1, 640),
              height: (image.height * scaleFactor).toInt().clamp(1, 400),
              maintainAspect: true,
              interpolation: img.Interpolation.nearest);
        }
        else {
          _log.fine('small 4-bit image, no need to scale down pixels, just max extent in height or width');
          // TODO does this scale up if the image is smaller? It doesn't need to do this.
          image = img.copyResize(image,
              width: 640,
              height: 400,
              maintainAspect: true,
              interpolation: img.Interpolation.nearest);
        }
      }
    }

    _width = image.width;
    _height = image.height;
    _pixelData = image.data!.toUint8List();
    // use a temporary palette in case we need to expand it to add VOID at the start
    Uint8List? initialPalette;

    // we can process RGB or RGBA format palettes, but any others we just exclude here
    if (image.palette!.numChannels == 3) {
      _log.fine('3-channel palette');
      // take the sublist because neuralNet quantized images have the number of colors we want
      // but packaged in a length 256 palette (a bug)
      initialPalette = image.palette!.toUint8List().sublist(0, 3 * numColors);
    }
    else if (image.palette!.numChannels == 4) {
      _log.fine('4-channel palette');
      // strip out the alpha channel from the palette
      // take the sublist because neuralNet quantized images have the number of colors we want
      // but packaged in a length 256 palette (a bug)
      initialPalette = _extractRGB(image.palette!.toUint8List().sublist(0, 4 * numColors));
    }
    else {
      throw Exception('Image colors must have 3 or 4 channels to be converted to a sprite');
    }

    // Frame uses palette entry 0 for VOID.
    // If we can fit another color, we can add VOID at the start and shift every pixel up by one.
    // If we can't fit any more colors, for now just set 0 to black (otherwise the rest of the display
    // will be lit)
    // We move the white palette index to 1 so that regular white text displays OK
    // TODO in future we could:
    // - find an alpha color from the palette (if it exists), and swap it with the color in 0
    // - find black from the palette (if it exists), and swap it with the color in 0
    // - find the darkest luminance color and swap it with the color in 0
    // - neuralNet quantizer seems to set 0 to black and max color to white.
    if (image.palette!.numColors < 16) {
      _log.fine('fewer than 16 colors');

      // if the first RGB color of the palette is not black/void, we need to
      // insert another color (which may promote the image to 2-bit or 4-bit)
      // but no need to if the palette already has black at the start
      if (initialPalette[0] != 0 || initialPalette[1] != 0 || initialPalette[2] != 0) {
        // TODO consider checking for whether we can move/add white to the #1 slot without
        // increasing the palette size to the next bitness
        _log.fine('insert black at the front of the palette');
        _numColors = image.palette!.numColors + 1;

        _paletteData = Uint8List(initialPalette.length + 3);
        _paletteData.setAll(3, initialPalette);
        _log.fine(initialPalette);
        _log.fine(_paletteData);

        // update all the pixels to refer to the new palette index
        for (int i=0; i<_pixelData.length; i++) {
          _pixelData[i] += 1;
        }
      }
      else {
        // palette already has black at the start, just copy it over
        _log.fine('black already at the start of the palette');
        _numColors = image.palette!.numColors;
        _paletteData = initialPalette;
      }
    }
    else {
      _log.fine('exactly 16 colors');

      if (!quantized) {
        // 16 colors in palette set by user's file, might not have black in slot 0
        _log.fine('16 colors exactly, make sure 0 is set to black');
        _numColors = image.palette!.numColors;
        // can't fit any more colors, set entry 0 to black
        _paletteData = initialPalette;
        _paletteData[0] = 0;
        _paletteData[1] = 0;
        _paletteData[2] = 0;
        _log.fine(initialPalette);
        _log.fine(_paletteData);
      }
      else {
        _log.fine('16 colors coming from quantizer');

        _numColors = 16;
        _paletteData = initialPalette;
        _log.fine(initialPalette);
        // black is already in #0 [0, 1, 2]

        // swap color in #1 [3, 4, 5] with white, which is in #15 [45, 46, 47]
        var swapR = _paletteData[3];
        var swapG = _paletteData[4];
        var swapB = _paletteData[5];
        _paletteData[3] = 255;
        _paletteData[4] = 255;
        _paletteData[5] = 255;
        _paletteData[45] = swapR;
        _paletteData[46] = swapG;
        _paletteData[47] = swapB;

        _log.fine(_paletteData);

        // update all the pixels to swap the palette index for white and the color that was in #1
        for (int i=0; i<_pixelData.length; i++) {
          if (_pixelData[i] == 1) {
            _pixelData[i] = 15;
          }
          else if (_pixelData[i] == 15) {
            _pixelData[i] = 1;
          }
        }
      }

      _log.fine(() => 'Sprite: $_width x $_height, $_numColors cols, ${pack().length} bytes');
    }
  }

  /// Create a TxSprite from an indexed PNG
  /// Sprites should be PNGs with palettes of up to 2, 4, or 16 colors (1-, 2-, or 4-bit indexed palettes)
  /// Alpha channel (4th-RGBA), if present, is dropped before sending to Frame (RGB only, but color 0 is VOID)
  /// Scale to 640x400 if larger, preserving aspect ratio
  TxSprite.fromPngBytes({required Uint8List pngBytes}) {
    var imgPng = img.PngDecoder().decode(pngBytes);

    if (imgPng != null &&
        imgPng.hasPalette &&
        imgPng.palette!.numColors <= 16) {
      // resize the image if it's too big - we really shouldn't have to do this for project sprites, just user-picked images
      if (imgPng.width > 640 || imgPng.height > 400) {
        // use nearest interpolation, we can't use any interpolation that averages colors
        imgPng = img.copyResize(imgPng,
            width: 640,
            height: 400,
            maintainAspect: true,
            interpolation: img.Interpolation.nearest);
      }

      _width = imgPng.width;
      _height = imgPng.height;
      _numColors = imgPng.palette!.numColors;
      _pixelData = imgPng.data!.toUint8List();

      // we can process RGB or RGBA format palettes, but any others we just exclude here
      if (imgPng.palette!.numChannels == 3 ||
          imgPng.palette!.numChannels == 4) {
        if (imgPng.palette!.numChannels == 3) {
          _paletteData = imgPng.palette!.toUint8List();
        }
        else if (imgPng.palette!.numChannels == 4) {
          // strip out the alpha channel from the palette
          _paletteData = _extractRGB(imgPng.palette!.toUint8List());
        }

        //_log.fine('Sprite: ${imgPng.width} x ${imgPng.height}, ${imgPng.palette!.numColors} cols, ${sprite.pack().length} bytes');
      } else {
        throw Exception(
            'PNG colors must have 3 or 4 channels to be converted to a sprite');
      }
    } else {
      throw Exception(
          'PNG must be a valid PNG image with a palette (indexed color) and 16 colors or fewer to be converted to a sprite');
    }
  }

  /// Strips the Alpha byte out of a list of RGBA colors
  /// Takes a Uint8List of length 4n made of RGBA bytes, and takes the first 3 bytes out of each 4 (RGB)
  Uint8List _extractRGB(Uint8List rgba) {
    _log.fine('extracting RGB from RGBA');
    // The output list will have 3/4 the length of the input list
    Uint8List rgb = Uint8List((rgba.length * 3) ~/ 4);

    int rgbIndex = 0;
    for (int i = 0; i < rgba.length; i += 4) {
      rgb[rgbIndex++] = rgba[i]; // R
      rgb[rgbIndex++] = rgba[i + 1]; // G
      rgb[rgbIndex++] = rgba[i + 2]; // B
    }

    return rgb;
  }

  /// Corresponding parser should be called from frame_app.lua data_handler()
  @override
  Uint8List pack() {
    int widthMsb = _width >> 8;
    int widthLsb = _width & 0xFF;
    int heightMsb = _height >> 8;
    int heightLsb = _height & 0xFF;
    int bpp = 0;
    Uint8List packed;
    switch (_numColors) {
      case <= 2:
        bpp = 1;
        packed = pack1Bit(_pixelData);
        break;
      case <= 4:
        bpp = 2;
        packed = pack2Bit(_pixelData);
        break;
      case <= 16:
        bpp = 4;
        packed = pack4Bit(_pixelData);
        break;
      default:
        throw Exception(
            'Image must have 16 or fewer colors. Actual: $_numColors');
    }

    // preallocate the list of bytes to send - sprite header, palette, pixel data
    // (packed.length already adds the extra byte if WxH is not divisible by 8)
    Uint8List payload =
        Uint8List.fromList(List.filled(6 + _numColors * 3 + packed.length, 0));

    // NB: palette data could be numColors=12 x 3 (RGB) bytes even if bpp is 4 (max 16 colors)
    // hence we provide both numColors and bpp here.
    // sendMessage will prepend the data byte, msgCode to each packet
    // and the Uint16 payload length to the first packet
    payload
        .setAll(0, [widthMsb, widthLsb, heightMsb, heightLsb, bpp, _numColors]);
    payload.setAll(6, _paletteData);
    payload.setAll(6 + _numColors * 3, packed);

    return payload;
  }

  static Uint8List pack1Bit(Uint8List bpp1) {
    int byteLength =
        (bpp1.length + 7) ~/ 8; // Calculate the required number of bytes
    Uint8List packed =
        Uint8List(byteLength); // Create the Uint8List to hold packed bytes

    for (int i = 0; i < bpp1.length; i++) {
      int byteIndex = i ~/ 8;
      int bitIndex = i % 8;
      packed[byteIndex] |= (bpp1[i] & 0x01) << (7 - bitIndex);
    }

    return packed;
  }

  static Uint8List pack2Bit(Uint8List bpp2) {
    int byteLength =
        (bpp2.length + 3) ~/ 4; // Calculate the required number of bytes
    Uint8List packed =
        Uint8List(byteLength); // Create the Uint8List to hold packed bytes

    for (int i = 0; i < bpp2.length; i++) {
      int byteIndex = i ~/ 4;
      int bitOffset = (3 - (i % 4)) * 2;
      packed[byteIndex] |= (bpp2[i] & 0x03) << bitOffset;
    }

    return packed;
  }

  static Uint8List pack4Bit(Uint8List bpp4) {
    int byteLength =
        (bpp4.length + 1) ~/ 2; // Calculate the required number of bytes
    Uint8List packed =
        Uint8List(byteLength); // Create the Uint8List to hold packed bytes

    for (int i = 0; i < bpp4.length; i++) {
      int byteIndex = i ~/ 2;
      int bitOffset = (1 - (i % 2)) * 4;
      packed[byteIndex] |= (bpp4[i] & 0x0F) << bitOffset;
    }

    return packed;
  }

  /// Convert TxSprite back to an image for testing/verification
  img.Image toImage() {
    // set up the indexed palette
    img.PaletteUint8 pal = img.PaletteUint8(_numColors, 3);
    pal.buffer.asUint8List().setAll(0, _paletteData);

    // TODO Image.palette() doesn't seem to correctly create indexed image.
    // instead, expand out the image to RGB pixels since this is just for phoneside display
    var data = img.ImageDataUint8(_width, _height, 3);
    int pixNum = 0;

    for (var palEntry in _pixelData) {
      data.setPixelRgb(
          pixNum % _width,
          pixNum ~/ _width,
          _paletteData[palEntry * 3],
          _paletteData[palEntry * 3 + 1],
          _paletteData[palEntry * 3 + 2]);

      pixNum++;
    }

    return img.Image.fromBytes(
        width: _width, height: _height, bytes: data.buffer, numChannels: 3);
  }
}


===== End of File: tx\sprite.dart =====


===== File: tx\text_sprite_block.dart =====
import 'dart:typed_data';
import 'dart:ui' as ui;
import 'dart:ui';

import 'package:image/image.dart' as img;
import '../tx_msg.dart';
import 'sprite.dart';

/// Represents an (optionally) multi-line block of text of a specified width and number of visible rows at a specified lineHeight
/// If the supplied text string is longer, only the last `displayRows` will be shown rendered and sent to Frame.
/// If the supplied text string has fewer than or equal to `displayRows`, only the number of actual rows will be rendered and sent to Frame
/// If any given line of text is shorter than width, the text Sprite will be set to the actual width required.
/// When sending TxTextSpriteBlock to Frame, the sendMessage() will send the header with block dimensions and line-by-line offsets
/// and the user then sends each line[] as a TxSprite message with the same msgCode as the Block, and the frame app will use the offsets
/// to place each line. By sending each line separately we can display them as they arrive, as well as reducing overall memory
/// requirement (each concat() call is smaller).
/// After calling the constructor, check `isNotEmpty` before calling `rasterize()` and sending the header or the sprites.
/// Sending a TextSpriteBlock with no lines is not intended usage.
/// `text` is trimmed (leading and trailing whitespace) before laying out the paragraph, but any blank lines
/// within the range of displayed rows will be sent as an empty (1px) TxSprite
class TxTextSpriteBlock extends TxMsg {
  final int _width;
  int get width => _width;
  final int _fontSize;
  int get fontSize => _fontSize;
  final int _maxDisplayRows;
  int get maxDisplayRows => _maxDisplayRows;
  final List<TxSprite> _sprites = [];
  List<TxSprite> get rasterizedSprites => _sprites;

  late final ui.Paragraph _paragraph;
  late final List<ui.LineMetrics> _lineMetrics;
  int get numLines => _lineMetrics.length;

  static img.PaletteUint8? monochromePal;

  /// return a 2-color, 3-channel palette (just black then white)
  static img.PaletteUint8 _getPalette() {
    if (monochromePal == null) {
      monochromePal = img.PaletteUint8(2, 3);
      monochromePal!.setRgb(0, 0, 0, 0);
      monochromePal!.setRgb(1, 255, 255, 255);
    }

    return monochromePal!;
  }

  /// After construction, a TextSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be rasterized nor sent
  bool get isEmpty => _lineMetrics.isEmpty;

  /// After construction, a TextSpriteBlock should be tested that it has a non-zero number of
  /// sprite lines to send, otherwise it should not be rasterized nor sent
  bool get isNotEmpty => _lineMetrics.isNotEmpty;

  TxTextSpriteBlock({
      required int width,
      required int fontSize,
      required int maxDisplayRows,
      String? fontFamily,
      ui.TextAlign textAlign = ui.TextAlign.left,
      ui.TextDirection textDirection = ui.TextDirection.ltr,
      required String text})
      : _width = width,
        _fontSize = fontSize,
        _maxDisplayRows = maxDisplayRows {
    final paragraphBuilder = ui.ParagraphBuilder(ui.ParagraphStyle(
      textAlign: textAlign,
      textDirection: textDirection,
      fontFamily: fontFamily, // gets platform default if null
      fontSize: _fontSize.toDouble(), // Adjust font size as needed
    ));

    paragraphBuilder.addText(text);
    _paragraph = paragraphBuilder.build();

    _paragraph.layout(ui.ParagraphConstraints(width: width.toDouble()));

    // work out height using metrics after paragraph.layout() call
    _lineMetrics = _paragraph.computeLineMetrics();
  }

  /// Since the Paragraph rasterizing to the Canvas, and the getting of the Image bytes
  /// are async functions, there needs to be an async function not just the constructor.
  /// Plus we want the caller to decide how many lines of a long paragraph to rasterize, and when.
  /// Text lines as TxSprites are accumulated in this object.
  /// startLine and endLine are inclusive
  Future<void> rasterize({required int startLine, required int endLine}) async {
    if (isNotEmpty) {

      if (startLine < 0 || startLine > _lineMetrics.length - 1) throw Exception('startLine must be > 0 and < ${_lineMetrics.length}');
      if (endLine < startLine || endLine > _lineMetrics.length - 1) throw Exception('endLine must be >= startLine and < ${_lineMetrics.length}');

      // Calculate the top and bottom boundaries for the selected lines
      double topBoundary = 0;
      double bottomBoundary = 0;

      // work out a clip rectangle so we only draw the lines between startLine and endLine
      topBoundary = _lineMetrics[startLine].baseline - _lineMetrics[startLine].ascent;
      bottomBoundary = _lineMetrics[endLine].baseline + _lineMetrics[endLine].descent;

      // Define the area to clip: a window over the selected lines
      final clipRect = Rect.fromLTWH(
        0, // Start from the left edge of the canvas
        topBoundary, // Start clipping from the top of the startLine
        width.toDouble(), // Full width of the paragraph
        bottomBoundary - topBoundary, // Height of the selected lines
      );

      final pictureRecorder = ui.PictureRecorder();
      final canvas = ui.Canvas(pictureRecorder);
      canvas.clipRect(clipRect);

      canvas.drawParagraph(_paragraph, ui.Offset.zero);
      final ui.Picture picture = pictureRecorder.endRecording();

      final int totalHeight = (bottomBoundary - topBoundary).toInt();
      final int topOffset = topBoundary.toInt();

      final ui.Image image = await picture.toImage(_width, totalHeight);

      var byteData =
          (await image.toByteData(format: ui.ImageByteFormat.rawUnmodified))!;

      // loop over each requested line of text in the paragraph and create a TxSprite
      for (var line in _lineMetrics.sublist(startLine, endLine + 1)) {
        final int tlX = line.left.toInt();
        final int tlY = (line.baseline - line.ascent).toInt();
        final int tlyShifted = tlY - topOffset;
        int lineWidth = line.width.toInt();
        int lineHeight = (line.ascent + line.descent).toInt();

        // check for non-blank lines
        if (lineWidth > 0 && lineHeight > 0) {
          var linePixelData = Uint8List(lineWidth * lineHeight);

          for (int i = 0; i < lineHeight; i++) {
            // take one row of the source image byteData, remembering it's in RGBA so 4 bytes per pixel
            // and remembering the origin of the image is the top of the startLine, so we need to
            // shift all the top-left Ys by that first Y offset.
            var sourceRow = byteData.buffer
                .asUint8List(((tlyShifted + i) * _width + tlX) * 4, lineWidth * 4);

            for (int j = 0; j < lineWidth; j++) {
              // take only every 4th byte because the source buffer is RGBA
              // and map it to palette index 1 if it's 128 or bigger (monochrome palette only, and text rendering will be anti-aliased)
              linePixelData[i * lineWidth + j] = sourceRow[4 * j] >= 128 ? 1 : 0;
            }
          }

          // make a Sprite out of the line and add to the list
          _sprites.add(TxSprite(
            width: lineWidth,
            height: lineHeight,
            numColors: 2,
            paletteData: _getPalette().data,
            pixelData: linePixelData
          ));
        }
        else {
          // zero-width line, a blank line in the text block
          // so we make a 1x1 px sprite in the void color
          _sprites.add(TxSprite(
            width: 1,
            height: 1,
            numColors: 2,
            paletteData: _getPalette().data,
            pixelData: Uint8List(1)
          ));
        }
      }
    }
  }

  /// Convert TxTextSpriteBlock back to a single image for testing/verification
  /// startLine and endLine are inclusive
  Future<Uint8List> toPngBytes({required int startLine, required int endLine}) async {
    if (_sprites.isEmpty) {
      throw Exception('_sprites is empty: call rasterize() before toPngBytes()');
    }

    // work out which range of lines we're drawing, and shift up by topOffset in Y
    final double topBoundary = _lineMetrics[startLine].baseline - _lineMetrics[startLine].ascent;
    final double bottomBoundary = _lineMetrics[endLine].baseline + _lineMetrics[endLine].descent;
    final int totalHeight = (bottomBoundary - topBoundary).toInt();
    final int topOffset = topBoundary.toInt();

    // create an image for the whole block
    var preview = img.Image(width: width, height: totalHeight);

    // copy in each of the sprites
    for (int i = startLine; i <= endLine; i++) {
      img.compositeImage(preview, rasterizedSprites[i].toImage(),
          dstY: (_lineMetrics[i].baseline - _lineMetrics[i].ascent - topOffset).toInt());
    }

    return img.encodePng(preview);
  }

  /// Corresponding parser should be called from frame_app data handler
  @override
  Uint8List pack() {
    if (_sprites.isEmpty) {
      throw Exception('_sprites is empty: call rasterize() before pack()');
    }

    int widthMsb = _width >> 8;
    int widthLsb = _width & 0xFF;

    // store the x (16-bit) and y (16-bit) offsets as pairs for each of the lines
    Uint8List offsets = Uint8List(_lineMetrics.length * 4);

    for (int i = 0; i < _lineMetrics.length; i++) {
      var lm = _lineMetrics[i];
      int xOffset = lm.left.toInt();
      int yOffset = (lm.baseline - lm.ascent).toInt();
      offsets[4 * i] = xOffset >> 8;
      offsets[4 * i + 1] = xOffset & 0xFF;
      offsets[4 * i + 2] = yOffset >> 8;
      offsets[4 * i + 3] = yOffset & 0xFF;
    }

    // special marker for Block header 0xFF, width of the block, max display rows, num lines, offsets within block for each line
    return Uint8List.fromList([
      0xFF,
      widthMsb,
      widthLsb,
      _maxDisplayRows & 0xFF,
      _sprites.length & 0xFF,
      ...offsets
    ]);
  }
}


===== End of File: tx\text_sprite_block.dart =====


